[{"content":" # Apache Seata Seata 是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的分布式事务服务。在 Seata 开源之前，其内部版本在阿里系内部一直扮演着应用架构层数据一致性的中间件角色，帮助经济体平稳的度过历年的双11，对上层业务进行了有力的技术支撑。经过多年沉淀与积累，其商业化产品先后在阿里云、金融云上售卖。2019.1 为了打造更加完善的技术生态和普惠技术成果，Seata 正式宣布对外开源，未来 Seata 将以社区共建的形式帮助用户快速落地分布式事务解决方案。\n本文将从源码的角度分析一下AT模式下Client端启动流程。\n所谓的Client端，即业务应用放。分布式事务分为三个模块：TC、TM、RM。其中TC位于server端，而TM、RM通过SDK的方式运行在client端。\n下面展示了一个分布式场景的Demo，分为几个微服务，共同实现一个订单、扣库存、扣余额的分布式事务：\nBusinessService： 业务服务，下单服务的入口 StorageService： 库存微服务，用于扣减商品库存 OrderService： 订单微服务，创建订单 AccountService： 账户微服务，扣减用户账户的余额 从上图也可以看出，在AT模式下Seata Client端主要通过如下三个模块来实现分布式事务：\nGlobalTransactionScanner： GlobalTransactionScanner负责初始TM、RM模块，并为添加分布式事务注解的方法添加拦截器，拦截器负责全局事务的开启、提交或回滚 DatasourceProxy： DatasourceProxy为DataSource添加拦截，拦截器会拦截所有SQL执行，并作为RM事务参与方的角色参与分布式事务执行。 Rpc Interceptor： Rpc Interceptor的职责就是负责在多个微服务之间传播事务。 # seata-spring-boot-starter 引用seata分布式事务SDK有两种方式，依赖seata-all或者seata-spring-boot-starter，推荐使用seata-spring-boot-starter，因为该starter已经自动注入了上面提到的三个模块，用户只要添加相应的配置，在业务代码添加全局分布式事务注解即可。下面从seata-spring-boot-starter项目中的代码入手：\n这里的话提供了集中集中不同启动client 的方式，详细内容可以看一眼注释，下面的话选择SteataAutoConfiguration进行查看，已说明对应的启动流程\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 /** * The type Seata auto configuration * */ @ConditionalOnProperty(prefix = SEATA_PREFIX, name = \u0026#34;enabled\u0026#34;, havingValue = \u0026#34;true\u0026#34;, matchIfMissing = true) @AutoConfigureAfter({SeataCoreAutoConfiguration.class}) public class SeataAutoConfiguration { // Logger private static final Logger LOGGER = LoggerFactory.getLogger(SeataAutoConfiguration.class); @Bean(BEAN_NAME_FAILURE_HANDLER) @ConditionalOnMissingBean(FailureHandler.class) public FailureHandler failureHandler() { return new DefaultFailureHandlerImpl(); } // GlobalTransactionScanner负责添加GlobalTransactionScanner注解的方法添加拦截器，并且负责初始化RM、TM @Bean @DependsOn({BEAN_NAME_SPRING_APPLICATION_CONTEXT_PROVIDER, BEAN_NAME_FAILURE_HANDLER}) @ConditionalOnMissingBean(GlobalTransactionScanner.class) public static GlobalTransactionScanner globalTransactionScanner(SeataProperties seataProperties, FailureHandler failureHandler, ConfigurableListableBeanFactory beanFactory, @Autowired(required = false) List\u0026lt;ScannerChecker\u0026gt; scannerCheckers) { if (LOGGER.isInfoEnabled()) { LOGGER.info(\u0026#34;Automatically configure Seata\u0026#34;); } //下面的话使用一些了配置文件的属性，比如applicationId、txServiceGroup、scanPackages、excludesForScanning、accessKey、secretKey //然后用户可以自己设置对应的属性。 // set bean factory GlobalTransactionScanner.setBeanFactory(beanFactory); // add checkers // \u0026#39;/META-INF/services/org.apache.seata.spring.annotation.ScannerChecker\u0026#39; GlobalTransactionScanner.addScannerCheckers(EnhancedServiceLoader.loadAll(ScannerChecker.class)); // spring beans GlobalTransactionScanner.addScannerCheckers(scannerCheckers); // add scannable packages GlobalTransactionScanner.addScannablePackages(seataProperties.getScanPackages()); // add excludeBeanNames GlobalTransactionScanner.addScannerExcludeBeanNames(seataProperties.getExcludesForScanning()); //set accessKey and secretKey GlobalTransactionScanner.setAccessKey(seataProperties.getAccessKey()); GlobalTransactionScanner.setSecretKey(seataProperties.getSecretKey()); // create global transaction scanner return new GlobalTransactionScanner(seataProperties.getApplicationId(), seataProperties.getTxServiceGroup(), seataProperties.isExposeProxy(), failureHandler); } } 可以看到，在进行拦截的时候，使用到了一个类，为GlobalTransactionScanner，下面详细的查看这个类。\n# GlobalTransactionScanner GlobalTransactionScanner继承于AbstractAutoProxyCreator，AbstractAutoProxyCreator可以用来判断是否需要实现对应的动态代理，下面重点查看字段和拦截代理的核心方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 public class GlobalTransactionScanner extends AbstractAutoProxyCreator implements CachedConfigurationChangeListener, InitializingBean, ApplicationContextAware, DisposableBean { // PROXYED_SET存储已经代理过的实例，防止重复处理 private static final Set\u0026lt;String\u0026gt; PROXYED_SET = new HashSet\u0026lt;\u0026gt;(); private static final Set\u0026lt;String\u0026gt; EXCLUDE_BEAN_NAME_SET = new HashSet\u0026lt;\u0026gt;(); private static final Set\u0026lt;ScannerChecker\u0026gt; SCANNER_CHECKER_SET = new LinkedHashSet\u0026lt;\u0026gt;(); private static ConfigurableListableBeanFactory beanFactory; // interceptor字段是对应一个代理对象的拦截器， // 可以认为是一个临时变量，有效期是一个被代理对象 private MethodInterceptor interceptor; // applicationId是一个服务的唯一标识，对应springcloud项目中的spring.application.name private final String applicationId; // 事务的分组标识，参考文章wiki：https://seata.apache.org/zh-cn/docs/user/txgroup/transaction-group/ private final String txServiceGroup; /** * The following will be scanned, and added corresponding interceptor: * 将扫描以下内容，并添加相应的拦截器： * \u0026lt;p\u0026gt; * 首先是TM模式，这种模式下尝试 * TM: * * @see org.apache.seata.spring.annotation.GlobalTransactional // TM annotation * Corresponding interceptor:org.apache.seata.integration.tx.api.interceptor.handler.GlobalTransactionalInterceptorHandler * @see GlobalTransactionalInterceptorHandler#handleGlobalTransaction(InvocationWrapper, AspectTransactional) // TM handler * \u0026lt;p\u0026gt; * GlobalLock: * @see org.apache.seata.spring.annotation.GlobalLock // GlobalLock annotation * Corresponding interceptor: * @see GlobalTransactionalInterceptorHandler#handleGlobalLock(InvocationWrapper, GlobalLock) // GlobalLock handler * \u0026lt;p\u0026gt; * TCC mode: * @see org.apache.seata.rm.tcc.api.LocalTCC // TCC annotation on interface * @see org.apache.seata.rm.tcc.api.TwoPhaseBusinessAction // TCC annotation on try method * @see org.apache.seata.integration.tx.api.remoting.RemotingParser // Remote TCC service parser * Corresponding interceptor: * @see org.apache.seata.rm.tcc.interceptor.TccActionInterceptorHandler // the interceptor of TCC mode */ @Override protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) { // do checkers if (!doCheckers(bean, beanName)) { return bean; } try { //这部分加上synchronized，具体功能可能还需要进行查看 // TODO：这里的synchronized是为了保证PROXYED_SET和NEED_ENHANCE_BEAN_NAME_SET的一致性，但是这里的逻辑还是需要进一步查看 synchronized (PROXYED_SET) { if (PROXYED_SET.contains(beanName)) { return bean; } if (!NEED_ENHANCE_BEAN_NAME_SET.contains(beanName)) { return bean; } // 每次处理一个被代理对象时先把interceptor置为null，所以interceptor的 // 生命周期是一个被代理对象，由于是在另外一个方法getAdvicesAndAdvisorsForBean // 中使用interceptor，所以该interceptor要定义为一个类变量 interceptor = null; //判定对应的十五类型，主要判定依据是方法上是否有对应的注解 ProxyInvocationHandler proxyInvocationHandler = DefaultInterfaceParser.get().parserInterfaceToProxy(bean, beanName); if (proxyInvocationHandler == null) { return bean; } // 创建对应的事务 interceptor = new AdapterSpringSeataInterceptor(proxyInvocationHandler); LOGGER.info(\u0026#34;Bean [{}] with name [{}] would use interceptor [{}]\u0026#34;, bean.getClass().getName(), beanName, interceptor.toString()); if (!AopUtils.isAopProxy(bean)) { // 如果bean本身不是Proxy对象，则直接调用父类的wrapIfNecessary生成代理对象即可 // 在父类中会调用getAdvicesAndAdvisorsForBean获取到上面定义的interceptor bean = super.wrapIfNecessary(bean, beanName, cacheKey); } else { // 如果该bean已经是代理对象了，则直接在代理对象的拦截调用链AdvisedSupport // 上直接添加新的interceptor即可。 AdvisedSupport advised = SpringProxyUtils.getAdvisedSupport(bean); Advisor[] advisor = buildAdvisors(beanName, getAdvicesAndAdvisorsForBean(null, null, null)); int pos; for (Advisor avr : advisor) { // Find the position based on the advisor\u0026#39;s order, and add to advisors by pos pos = findAddSeataAdvisorPosition(advised, avr); advised.addAdvisor(pos, avr); } } // 标识该beanName已经处理过了 PROXYED_SET.add(beanName); return bean; } } catch (Exception exx) { throw new RuntimeException(exx); } } } 当调用被@GlobalTransactional或@GlobalLock注解修饰的方法时，会调到代理对象，而增强逻辑在GlobalTransactionalInterceptor类的invoke方法里。而具体是如何增强的以及事务时如何执行的放在另一篇专门讲解。\n# 初始化TM和BM GlobalTransactionScanner还实现了InitializingBean接口，所以在初始化阶段还会调用afterPropertiesSet方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Override public void afterPropertiesSet() { if (disableGlobalTransaction) { if (LOGGER.isInfoEnabled()) { LOGGER.info(\u0026#34;Global transaction is disabled.\u0026#34;); } ConfigurationFactory.getInstance().addConfigListener(ConfigurationKeys.DISABLE_GLOBAL_TRANSACTION, (CachedConfigurationChangeListener) this); return; } // 如果seata客户端还未初始化，则进行初始化 if (initialized.compareAndSet(false, true)) { initClient(); } this.findBusinessBeanNamesNeededEnhancement(); } 这里会对TM和RM进行初始化，本质上都是创建一个netty客户端，然后向tc注册\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 protected void initClient() { if (LOGGER.isInfoEnabled()) { LOGGER.info(\u0026#34;Initializing Global Transaction Clients ... \u0026#34;); } if (DEFAULT_TX_GROUP_OLD.equals(txServiceGroup)) { LOGGER.warn(\u0026#34;the default value of seata.tx-service-group: {} has already changed to {} since Seata 1.5, \u0026#34; + \u0026#34;please change your default configuration as soon as possible \u0026#34; + \u0026#34;and we don\u0026#39;t recommend you to use default tx-service-group\u0026#39;s value provided by seata\u0026#34;, DEFAULT_TX_GROUP_OLD, DEFAULT_TX_GROUP); } if (StringUtils.isNullOrEmpty(applicationId) || StringUtils.isNullOrEmpty(txServiceGroup)) { throw new IllegalArgumentException(String.format(\u0026#34;applicationId: %s, txServiceGroup: %s\u0026#34;, applicationId, txServiceGroup)); } //init TM // 初始化 TM，本质就是创建一个tm的netty客户端，然后向tc注册 TMClient.init(applicationId, txServiceGroup, accessKey, secretKey); if (LOGGER.isInfoEnabled()) { LOGGER.info(\u0026#34;Transaction Manager Client is initialized. applicationId[{}] txServiceGroup[{}]\u0026#34;, applicationId, txServiceGroup); } //init RM // 初始化 RM，本质就是创建一个rm的netty客户端，然后向tc注册 //TODO:不出意外改造的就是这里，改造的目的是为了支持多Client的模式 RMClient.init(applicationId, txServiceGroup); if (LOGGER.isInfoEnabled()) { LOGGER.info(\u0026#34;Resource Manager is initialized. applicationId[{}] txServiceGroup[{}]\u0026#34;, applicationId, txServiceGroup); } if (LOGGER.isInfoEnabled()) { LOGGER.info(\u0026#34;Global Transaction Clients are initialized. \u0026#34;); } registerSpringShutdownHook(); } 初始化 TM\n1 2 3 4 5 6 public static void init(String applicationId, String transactionServiceGroup, String accessKey, String secretKey) { // 获取TM客户端实例 TmNettyRemotingClient tmNettyRemotingClient = TmNettyRemotingClient.getInstance(applicationId, transactionServiceGroup, accessKey, secretKey); // 初始化TM的netty客户端 tmNettyRemotingClient.init(); } 在获取TM客户端实例时，会创建netty客户端，但还未启动\n1 2 3 4 5 6 7 8 9 @Override public void init() { // 注册相关处理器 registerProcessor(); if (initialized.compareAndSet(false, true)) { // 调用父类初始化方法 super.init(); } } 注册两个处理器，用来处理TC返回给TM的响应\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 private void registerProcessor() { // 1.registry TC response processor // 注册Seata-Server返回的Response的处理Processor，用于Client主动发起Request， // Seata-Server返回的Response ClientOnResponseProcessor onResponseProcessor = new ClientOnResponseProcessor(mergeMsgMap, super.getFutures(), getTransactionMessageHandler()); super.registerProcessor(MessageType.TYPE_SEATA_MERGE_RESULT, onResponseProcessor, null); super.registerProcessor(MessageType.TYPE_GLOBAL_BEGIN_RESULT, onResponseProcessor, null); super.registerProcessor(MessageType.TYPE_GLOBAL_COMMIT_RESULT, onResponseProcessor, null); super.registerProcessor(MessageType.TYPE_GLOBAL_REPORT_RESULT, onResponseProcessor, null); super.registerProcessor(MessageType.TYPE_GLOBAL_ROLLBACK_RESULT, onResponseProcessor, null); super.registerProcessor(MessageType.TYPE_GLOBAL_STATUS_RESULT, onResponseProcessor, null); super.registerProcessor(MessageType.TYPE_REG_CLT_RESULT, onResponseProcessor, null); super.registerProcessor(MessageType.TYPE_BATCH_RESULT_MSG, onResponseProcessor, null); // 2.registry heartbeat message processor // ClientOnResponseProcessor负责把Client发送的Request和Seata-Server // 返回的Response对应起来，从而实现Rpc ClientHeartbeatProcessor clientHeartbeatProcessor = new ClientHeartbeatProcessor(); super.registerProcessor(MessageType.TYPE_HEARTBEAT_MSG, clientHeartbeatProcessor, null); } 在父类AbstractNettyRemotingClient中启动TM的netty客户端，这里的话暂时按下不表。下面简单分析RM的init方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Override public void init() { // 定时重新发送 RegisterTMRequest（RM 客户端会发送 RegisterRMRequest）请求尝试连接服务端 timerExecutor.scheduleAtFixedRate(new Runnable() { @Override public void run() { clientChannelManager.reconnect(getTransactionServiceGroup()); } }, SCHEDULE_DELAY_MILLS, SCHEDULE_INTERVAL_MILLS, TimeUnit.MILLISECONDS); if (NettyClientConfig.isEnableClientBatchSendRequest()) { mergeSendExecutorService = new ThreadPoolExecutor(MAX_MERGE_SEND_THREAD, MAX_MERGE_SEND_THREAD, KEEP_ALIVE_TIME, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;\u0026gt;(), new NamedThreadFactory(getThreadPrefix(), MAX_MERGE_SEND_THREAD)); mergeSendExecutorService.submit(new MergedSendRunnable()); } super.init(); // 启动netty 客户端 clientBootstrap.start(); } 初始化RM 初始化过程跟TM一样，下面只贴出相关代码\n1 2 3 4 5 6 7 8 9 public static void init(String applicationId, String transactionServiceGroup) { // 创建RM的netty客户端 RmNettyRemotingClient rmNettyRemotingClient = RmNettyRemotingClient.getInstance(applicationId, transactionServiceGroup); // 设置RM进去 rmNettyRemotingClient.setResourceManager(DefaultResourceManager.get()); rmNettyRemotingClient.setTransactionMessageHandler(DefaultRMHandler.get()); // 初始化 rmNettyRemotingClient.init(); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public void init() { // 注册处理器 registerProcessor(); if (initialized.compareAndSet(false, true)) { super.init(); // Found one or more resources that were registered before initialization if (resourceManager != null \u0026amp;\u0026amp; !resourceManager.getManagedResources().isEmpty() \u0026amp;\u0026amp; StringUtils.isNotBlank(transactionServiceGroup)) { getClientChannelManager().reconnect(transactionServiceGroup); } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 private void registerProcessor() { // 1.registry rm client handle branch commit processor // 注册Seata-Server发起branchCommit的处理Processor RmBranchCommitProcessor rmBranchCommitProcessor = new RmBranchCommitProcessor(getTransactionMessageHandler(), this); super.registerProcessor(MessageType.TYPE_BRANCH_COMMIT, rmBranchCommitProcessor, messageExecutor); // 2.registry rm client handle branch commit processor // 注册Seata-Server发起branchRollback的处理Processor RmBranchRollbackProcessor rmBranchRollbackProcessor = new RmBranchRollbackProcessor(getTransactionMessageHandler(), this); super.registerProcessor(MessageType.TYPE_BRANCH_ROLLBACK, rmBranchRollbackProcessor, messageExecutor); // 3.registry rm handler undo log processor // 注册Seata-Server发起删除undoLog的处理Processor RmUndoLogProcessor rmUndoLogProcessor = new RmUndoLogProcessor(getTransactionMessageHandler()); super.registerProcessor(MessageType.TYPE_RM_DELETE_UNDOLOG, rmUndoLogProcessor, messageExecutor); // 4.registry TC response processor // 注册Seata-Server返回Response的处理Processor，用于处理由Client主动发起Request， // Seata-Server返回的Response。 // ClientOnResponseProcessor负责把Client发送的Request和Seata-Server // 返回的Response对应起来，从而实现Rpc ClientOnResponseProcessor onResponseProcessor = new ClientOnResponseProcessor(mergeMsgMap, super.getFutures(), getTransactionMessageHandler()); super.registerProcessor(MessageType.TYPE_SEATA_MERGE_RESULT, onResponseProcessor, null); super.registerProcessor(MessageType.TYPE_BRANCH_REGISTER_RESULT, onResponseProcessor, null); super.registerProcessor(MessageType.TYPE_BRANCH_STATUS_REPORT_RESULT, onResponseProcessor, null); super.registerProcessor(MessageType.TYPE_GLOBAL_LOCK_QUERY_RESULT, onResponseProcessor, null); super.registerProcessor(MessageType.TYPE_REG_RM_RESULT, onResponseProcessor, null); // 5.registry heartbeat message processor // 处理Seata-Server返回的心跳消息 ClientHeartbeatProcessor clientHeartbeatProcessor = new ClientHeartbeatProcessor(); super.registerProcessor(MessageType.TYPE_HEARTBEAT_MSG, clientHeartbeatProcessor, null); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Override public void init() { // 定时重新发送 RegisterTMRequest（RM 客户端会发送 RegisterRMRequest）请求尝试连接服务端 timerExecutor.scheduleAtFixedRate(new Runnable() { @Override public void run() { clientChannelManager.reconnect(getTransactionServiceGroup()); } }, SCHEDULE_DELAY_MILLS, SCHEDULE_INTERVAL_MILLS, TimeUnit.MILLISECONDS); if (NettyClientConfig.isEnableClientBatchSendRequest()) { mergeSendExecutorService = new ThreadPoolExecutor(MAX_MERGE_SEND_THREAD, MAX_MERGE_SEND_THREAD, KEEP_ALIVE_TIME, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;\u0026gt;(), new NamedThreadFactory(getThreadPrefix(), MAX_MERGE_SEND_THREAD)); mergeSendExecutorService.submit(new MergedSendRunnable()); } super.init(); // 启动netty 客户端 clientBootstrap.start(); } 总结来说初始化TM和RM做的事就是分别注册几个处理器以及启动各自的Netty客户端。\n# 数据源代理 SeataDataSourceAutoConfiguration\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @ConditionalOnBean(DataSource.class) @ConditionalOnExpression(\u0026#34;${seata.enabled:true} \u0026amp;\u0026amp; ${seata.enableAutoDataSourceProxy:true} \u0026amp;\u0026amp; ${seata.enable-auto-data-source-proxy:true}\u0026#34;) @AutoConfigureOrder(Ordered.LOWEST_PRECEDENCE) @AutoConfigureAfter(value = {SeataCoreAutoConfiguration.class}, name = \u0026#34;org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration\u0026#34;) public class SeataDataSourceAutoConfiguration { /** * The bean seataAutoDataSourceProxyCreator. */ /** * 负责为Spring中的所有DataSource生成代理对象，从而拦截SQL的执行，在SQL执行前后实现seata的逻辑 */ @Bean(BEAN_NAME_SEATA_AUTO_DATA_SOURCE_PROXY_CREATOR) @ConditionalOnMissingBean(SeataAutoDataSourceProxyCreator.class) public static SeataAutoDataSourceProxyCreator seataAutoDataSourceProxyCreator(SeataProperties seataProperties) { return new SeataAutoDataSourceProxyCreator(seataProperties.isUseJdkProxy(), seataProperties.getExcludesForAutoProxying(), seataProperties.getDataSourceProxyMode()); } } 该配置类要生效的条件是${seata.enable:true} \u0026amp;\u0026amp; ${seata.enableAutoDataSourceProxy:true} \u0026amp;\u0026amp; ${seata.enable-auto-data-source-proxy:true}这几个配置都为true，但是我在配置文件中都设置为true后也没生效，不知道哪里问题，所以我换一种方式，在启动类上添加@EnableAutoDataSourceProxy注解。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Import(AutoDataSourceProxyRegistrar.class) @Documented public @interface EnableAutoDataSourceProxy { /** * Whether use JDK proxy instead of CGLIB proxy * * @return useJdkProxy */ boolean useJdkProxy() default false; /** * Specifies which datasource bean are not eligible for auto-proxying * * @return excludes */ String[] excludes() default {}; /** * Data source proxy mode, AT or XA * * @return dataSourceProxyMode */ String dataSourceProxyMode() default \u0026#34;AT\u0026#34;; } 该注解上导入了另一个类AutoDataSourceProxyRegistrar\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public class AutoDataSourceProxyRegistrar implements ImportBeanDefinitionRegistrar { private static final String ATTRIBUTE_KEY_USE_JDK_PROXY = \u0026#34;useJdkProxy\u0026#34;; private static final String ATTRIBUTE_KEY_EXCLUDES = \u0026#34;excludes\u0026#34;; private static final String ATTRIBUTE_KEY_DATA_SOURCE_PROXY_MODE = \u0026#34;dataSourceProxyMode\u0026#34;; public static final String BEAN_NAME_SEATA_DATA_SOURCE_BEAN_POST_PROCESSOR = \u0026#34;seataDataSourceBeanPostProcessor\u0026#34;; public static final String BEAN_NAME_SEATA_AUTO_DATA_SOURCE_PROXY_CREATOR = \u0026#34;seataAutoDataSourceProxyCreator\u0026#34;; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { Map\u0026lt;String, Object\u0026gt; annotationAttributes = importingClassMetadata.getAnnotationAttributes(EnableAutoDataSourceProxy.class.getName()); boolean useJdkProxy = Boolean.parseBoolean(annotationAttributes.get(ATTRIBUTE_KEY_USE_JDK_PROXY).toString()); String[] excludes = (String[]) annotationAttributes.get(ATTRIBUTE_KEY_EXCLUDES); String dataSourceProxyMode = (String) annotationAttributes.get(ATTRIBUTE_KEY_DATA_SOURCE_PROXY_MODE); //register seataDataSourceBeanPostProcessor bean def if (!registry.containsBeanDefinition(BEAN_NAME_SEATA_DATA_SOURCE_BEAN_POST_PROCESSOR)) { AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder .genericBeanDefinition(SeataDataSourceBeanPostProcessor.class) .addConstructorArgValue(excludes) .addConstructorArgValue(dataSourceProxyMode) .getBeanDefinition(); registry.registerBeanDefinition(BEAN_NAME_SEATA_DATA_SOURCE_BEAN_POST_PROCESSOR, beanDefinition); } //register seataAutoDataSourceProxyCreator bean def if (!registry.containsBeanDefinition(BEAN_NAME_SEATA_AUTO_DATA_SOURCE_PROXY_CREATOR)) { AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder .genericBeanDefinition(SeataAutoDataSourceProxyCreator.class) .addConstructorArgValue(useJdkProxy) .addConstructorArgValue(excludes) .addConstructorArgValue(dataSourceProxyMode) .getBeanDefinition(); registry.registerBeanDefinition(BEAN_NAME_SEATA_AUTO_DATA_SOURCE_PROXY_CREATOR, beanDefinition); } } } AutoDataSourceProxyRegistrar实现了ImportBeanDefinitionRegistrar接口，这样我们就知道该类额外注册了BeanDefinition。通过源码可知，该类注册了两个bean，分别是SeataDataSourceBeanPostProcessor和SeataAutoDataSourceProxyCreator。\n# SeataDataSourceBeanPostProcessor 该类是一个BeanPostProcessor，主要就是用来生成数据源代理的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 public class SeataDataSourceBeanPostProcessor implements BeanPostProcessor { private static final Logger LOGGER = LoggerFactory.getLogger(SeataDataSourceBeanPostProcessor.class); private final List\u0026lt;String\u0026gt; excludes; private final BranchType dataSourceProxyMode; public SeataDataSourceBeanPostProcessor(String[] excludes, String dataSourceProxyMode) { this.excludes = Arrays.asList(excludes); this.dataSourceProxyMode = BranchType.XA.name().equalsIgnoreCase(dataSourceProxyMode) ? BranchType.XA : BranchType.AT; } @Override public Object postProcessBeforeInitialization(Object bean, String beanName) { return bean; } @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { if (bean instanceof DataSource) { //When not in the excludes, put and init proxy. if (!excludes.contains(bean.getClass().getName())) { // 这里只是生成代理，并不返回代理，返回的还是真实数据源， // 毕竟不是每个sql都需要代理，在需要使用代理的时候再取出来 DataSourceProxyHolder.get().putDataSource((DataSource) bean, dataSourceProxyMode); } // 如果是代理数据源，则返回真实数据源 if (bean instanceof SeataDataSourceProxy) { LOGGER.info(\u0026#34;Unwrap the bean of the data source,\u0026#34; + \u0026#34; and return the original data source to replace the data source proxy.\u0026#34;); return ((SeataDataSourceProxy) bean).getTargetDataSource(); } } return bean; } } DataSourceProxyHolder是用来存放代理数据源的，如果当前bean是DataSource，则会为该DataSource生成一个代理DataSource。在putDataSource方法中，会进行数据源代理类的创建，当然，该方法除了创建数据源代理，获取数据源代理也是调用这个方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public SeataDataSourceProxy putDataSource(DataSource dataSource, BranchType dataSourceProxyMode) { DataSource originalDataSource; // 如果已经是代理数据源并且事务模式也跟想要的一样，则直接返回了 if (dataSource instanceof SeataDataSourceProxy) { SeataDataSourceProxy dataSourceProxy = (SeataDataSourceProxy) dataSource; // 就是想要的代理类就直接返回了 if (dataSourceProxyMode == dataSourceProxy.getBranchType()) { return (SeataDataSourceProxy) dataSource; } // 获取原数据源，下面根据该数据源创建或获取数据源代理类 originalDataSource = dataSourceProxy.getTargetDataSource(); } else { originalDataSource = dataSource; } // 从缓存中获取真实数据源对应的代理 SeataDataSourceProxy dsProxy = dataSourceProxyMap.get(originalDataSource); if (dsProxy == null) { synchronized (dataSourceProxyMap) { dsProxy = dataSourceProxyMap.get(originalDataSource); if (dsProxy == null) { // 没获取到就根据事务模式和真实数据源创建一个代理 dsProxy = createDsProxyByMode(dataSourceProxyMode, originalDataSource); // 放进缓存 dataSourceProxyMap.put(originalDataSource, dsProxy); } } } return dsProxy; } XA模式就创建DataSourceProxyXA，其他模式创建DataSourceProx。\n1 2 3 private SeataDataSourceProxy createDsProxyByMode(BranchType mode, DataSource originDs) { return BranchType.XA == mode ? new DataSourceProxyXA(originDs) : new DataSourceProxy(originDs); } # SeataAutoDataSourceProxyCreator 上面为每个数据源生成了seata的代理对象，但是该代理对象并不能通过AOP切入，所以还是需要一个AOP代理对象。SeataAutoDataSourceProxyCreator也是继承了AbstractAutoProxyCreator类，继承该类就可以对指定的bean生成AOP代理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class SeataAutoDataSourceProxyCreator extends AbstractAutoProxyCreator { private static final Logger LOGGER = LoggerFactory.getLogger(SeataAutoDataSourceProxyCreator.class); private final List\u0026lt;String\u0026gt; excludes; private final Advisor advisor; public SeataAutoDataSourceProxyCreator(boolean useJdkProxy, String[] excludes, String dataSourceProxyMode) { this.excludes = Arrays.asList(excludes); this.advisor = new DefaultIntroductionAdvisor(new SeataAutoDataSourceProxyAdvice(dataSourceProxyMode)); setProxyTargetClass(!useJdkProxy); } @Override protected Object[] getAdvicesAndAdvisorsForBean(Class\u0026lt;?\u0026gt; beanClass, String beanName, TargetSource customTargetSource) throws BeansException { if (LOGGER.isInfoEnabled()) { LOGGER.info(\u0026#34;Auto proxy of [{}]\u0026#34;, beanName); } return new Object[]{advisor}; } @Override protected boolean shouldSkip(Class\u0026lt;?\u0026gt; beanClass, String beanName) { // 这个类只对DataSource生成代理 return !DataSource.class.isAssignableFrom(beanClass) || SeataProxy.class.isAssignableFrom(beanClass) || excludes.contains(beanClass.getName()); } } 从shouldSkip方法可知，只会对DataSource生成代理，而它添加的增强逻辑在SeataAutoDataSourceProxyAdvice内。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 /** * 对DataSource进行增强，代理DataSource中的方法 * * @author xingfudeshi@gmail.com */ public class SeataAutoDataSourceProxyAdvice implements MethodInterceptor, IntroductionInfo { private final BranchType dataSourceProxyMode; private final Class\u0026lt;? extends SeataDataSourceProxy\u0026gt; dataSourceProxyClazz; public SeataAutoDataSourceProxyAdvice(String dataSourceProxyMode) { if (BranchType.AT.name().equalsIgnoreCase(dataSourceProxyMode)) { this.dataSourceProxyMode = BranchType.AT; this.dataSourceProxyClazz = DataSourceProxy.class; } else if (BranchType.XA.name().equalsIgnoreCase(dataSourceProxyMode)) { this.dataSourceProxyMode = BranchType.XA; this.dataSourceProxyClazz = DataSourceProxyXA.class; } else { throw new IllegalArgumentException(\u0026#34;Unknown dataSourceProxyMode: \u0026#34; + dataSourceProxyMode); } //Set the default branch type in the RootContext. RootContext.setDefaultBranchType(this.dataSourceProxyMode); } @Override public Object invoke(MethodInvocation invocation) throws Throwable { // 如果不是在@GlobalLock方法或事务模式跟当前的不匹配，则直接调用原方法 if (!RootContext.requireGlobalLock() \u0026amp;\u0026amp; dataSourceProxyMode != RootContext.getBranchType()) { return invocation.proceed(); } Method method = invocation.getMethod(); Object[] args = invocation.getArguments(); Method m = BeanUtils.findDeclaredMethod(dataSourceProxyClazz, method.getName(), method.getParameterTypes()); if (m != null \u0026amp;\u0026amp; DataSource.class.isAssignableFrom(method.getDeclaringClass())) { // 获取seata创建的代理数据源，调用代理数据源的方法 SeataDataSourceProxy dataSourceProxy = DataSourceProxyHolder.get().putDataSource((DataSource) invocation.getThis(), dataSourceProxyMode); return m.invoke(dataSourceProxy, args); } else { return invocation.proceed(); } } @Override public Class\u0026lt;?\u0026gt;[] getInterfaces() { return new Class[]{SeataProxy.class}; } } 当调用DataSource的方法时，就会通过AOP代理对象调用到SeataDataSourceProxy实现类的方法，即seata的代理。\n# Web MVC代理 这个的话比较简单，直接贴上相关代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 /** * Auto bean add for spring webmvc if in springboot env. * */ @Configuration(proxyBeanMethods = false) @ConditionalOnWebApplication @ConditionalOnMissingBean(SeataWebMvcConfigurer.class) @ConditionalOnProperty(prefix = HTTP_PREFIX, name = \u0026#34;interceptor-enabled\u0026#34;, havingValue = \u0026#34;true\u0026#34;, matchIfMissing = true) @AutoConfigureOrder(Ordered.LOWEST_PRECEDENCE) public class SeataHttpAutoConfiguration { /** * The Jakarta seata web mvc configurer. * * @return the seata web mvc configurer */ @Bean @ConditionalOnClass(name = \u0026#34;jakarta.servlet.http.HttpServletRequest\u0026#34;) public JakartaSeataWebMvcConfigurer jakartaSeataWebMvcConfigurer() { return new JakartaSeataWebMvcConfigurer(); } /** * The Javax seata web mvc configurer. * * @return the seata web mvc configurer */ @Bean @ConditionalOnMissingBean(JakartaSeataWebMvcConfigurer.class) public SeataWebMvcConfigurer seataWebMvcConfigurer() { return new SeataWebMvcConfigurer(); } } 然后接着往里面看：\n1 2 3 4 5 6 7 8 9 10 11 /** * The Seata Web Mvc Configurer * */ public class SeataWebMvcConfigurer implements WebMvcConfigurerAdapter { @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(new TransactionPropagationInterceptor()); } } WebMvcConfigurerAdapter可以以灵活的方式扩展和定制 Spring MVC 的配置，然后的话看TransactionPropagationInterceptor\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 public class TransactionPropagationInterceptor implements HandlerInterceptorAdapter { private static final Logger LOGGER = LoggerFactory.getLogger(TransactionPropagationInterceptor.class); @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) { String rpcXid = request.getHeader(RootContext.KEY_XID); return this.bindXid(rpcXid); } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { if (RootContext.inGlobalTransaction()) { String rpcXid = request.getHeader(RootContext.KEY_XID); this.cleanXid(rpcXid); } } protected boolean bindXid(String rpcXid) { String xid = RootContext.getXID(); if (LOGGER.isDebugEnabled()) { LOGGER.debug(\u0026#34;xid in RootContext[{}] xid in HttpContext[{}]\u0026#34;, xid, rpcXid); } if (StringUtils.isBlank(xid) \u0026amp;\u0026amp; StringUtils.isNotBlank(rpcXid)) { RootContext.bind(rpcXid); if (LOGGER.isDebugEnabled()) { LOGGER.debug(\u0026#34;bind[{}] to RootContext\u0026#34;, rpcXid); } } return true; } protected void cleanXid(String rpcXid) { XidResource.cleanXid(rpcXid); } } 这个方法就相当于创建对应的适配器，通过获取对应的xid，从而进行适配。\n","date":"2024-07-04T22:35:24+08:00","image":"https://seata.apache.org/img/seata_logo.png","permalink":"https://runqizhao.cn/p/seata-client%E7%AB%AF%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/","title":"Seata Client端启动流程"},{"content":" # SSO介绍 # 概念 SSO 英文全称 Single Sign On，单点登录。SSO 是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。\n# 好处 用户角度 :用户能够做到一次登录多次使用，无需记录多套用户名和密码，省心。\n系统管理员角度 : 管理员只需维护好一个统一的账号中心就可以了，方便。\n新系统开发角度: 新系统开发时只需直接对接统一的账号中心即可，简化开发流程，省时\n# 实现方式 设计方式：\n# 用户登录状态的存储与校验 常见的 Web 框架对于 Session 的实现都是生成一个 SessionId 存储在浏览器 Cookie 中。然后将 Session 内容存储在服务器端内存中。\n用户登录成功之后，生成 AuthToken 交给客户端保存。如果是浏览器，就保存在 Cookie 中。如果是手机 App 就保存在 App 本地缓存中。本篇主要探讨基于 Web 站点的 SSO。\n用户在浏览需要登录的页面时，客户端将 AuthToken 提交给 SSO 服务校验登录状态/获取用户登录信息\n对于登录信息的存储，建议采用 Redis，使用 Redis 集群来存储登录信息，既可以保证高可用，又可以线性扩充。同时也可以让 SSO 服务满足负载均衡/可伸缩的需求。\n对象 说明 AuthToken 直接使用 UUID/GUID 即可，如果有验证 AuthToken 合法性需求，可以将 UserName+时间戳加密生成，服务端解密之后验证合法性 登录信息 通常是将 UserId，UserName 缓存起来 # 用户登录/登录校验 登陆时序图\n按照上图，用户登录后 AuthToken 保存在 Cookie 中。 domain=test.comopen in new window 浏览器会将 domain 设置成 .test.com，\n这样访问所有 *.test.com 的 web 站点，都会将 AuthToken 携带到服务器端。然后通过 SSO 服务，完成对用户状态的校验/用户登录信息的获取\n登录信息获取/登录状态校验\n# 用户登出 用户登出时要做的事情很简单：\n服务端清除缓存（Redis）中的登录状态 客户端清除存储的 AuthToken 登出时序图\n# 跨域登录、登出 前面提到过，核心思路是客户端存储 AuthToken，服务器端通过 Redis 存储登录信息。由于客户端是将 AuthToken 存储在 Cookie 中的。所以跨域要解决的问题，就是如何解决 Cookie 的跨域读写问题。\n解决跨域的核心思路就是：\n登录完成之后通过回调的方式，将 AuthToken 传递给主域名之外的站点，该站点自行将 AuthToken 保存在当前域下的 Cookie 中。 登出完成之后通过回调的方式，调用非主域名站点的登出页面，完成设置 Cookie 中的 AuthToken 过期的操作。 跨域登录（主域名已登录）\n跨域登录（主域名未登录）\n跨域登出\n","date":"2024-05-13T08:34:23+08:00","permalink":"https://runqizhao.cn/p/sso%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95/","title":"SSO单点登录"},{"content":" # 什么是JWT JWT （JSON Web Token） 是目前最流行的跨域认证解决方案，是一种基于 Token 的认证授权机制。 从 JWT 的全称可以看出，JWT 本身也是 Token，一种规范化之后的 JSON 结构的 Token。\nJWT 自身包含了身份验证所需要的所有信息，因此，我们的服务器不需要存储 Session 信息。这显然增加了系统的可用性和伸缩性，大大减轻了服务端的压力。\nJWT 更符合设计 RESTful API 时的「Stateless（无状态）」原则 。\n# JWT由哪些部分组成 如下图所示：\nJWT 本质上就是一组字串，通过（.）切分成三个为 Base64 编码的部分：\nHeader : 描述 JWT 的元数据，定义了生成签名的算法以及 Token 的类型。 Payload : 用来存放实际需要传递的数据 Signature（签名）：服务器通过 Payload、Header 和一个密钥(Secret)使用 Header 里面指定的签名算法（默认是 HMAC SHA256）生成。 JWT 通常是这样的：xxxxx.yyyyy.zzzzz。\n下面分别讲解每个部分。\n# Header Header 通常由两部分组成：\ntyp（Type）：令牌类型，也就是 JWT。 alg（Algorithm）：签名算法，比如 HS256。 # Payload Payload 也是 JSON 格式数据，其中包含了 Claims(声明，包含 JWT 的相关信息)。\nClaims 分为三种类型：\nRegistered Claims（注册声明）：预定义的一些声明，建议使用，但不是强制性的。 Public Claims（公有声明）：JWT 签发方可以自定义的声明，但是为了避免冲突，应该在 IANA JSON Web Token Registryopen in new window 中定义它们。 Private Claims（私有声明）：JWT 签发方因为项目需要而自定义的声明，更符合实际项目场景使用。 下面是一些常见的注册声明：\niss（issuer）：JWT 签发方。 iat（issued at time）：JWT 签发时间。 sub（subject）：JWT 主题。 aud（audience）：JWT 接收方。 exp（expiration time）：JWT 的过期时间。 nbf（not before time）：JWT 生效时间，早于该定义的时间的 JWT 不能被接受处理。 jti（JWT ID）：JWT 唯一标识。 Playload是没有加密的，一定不要将隐私信息存放在 Payload 当中！！！\n# Signature Signature 部分是对前两部分的签名，作用是防止 JWT（主要是 payload） 被篡改。\n这个签名的生成需要用到：\nHeader + Payload。 存放在服务端的密钥(一定不要泄露出去)。 签名算法。 签名的计算公式如下：\n1 2 3 4 HMACSHA256( base64UrlEncode(header) + \u0026#34;.\u0026#34; + base64UrlEncode(payload), secret) # JWT使用 在基于 JWT 进行身份验证的的应用程序中，服务器通过 Payload、Header 和 Secret(密钥)创建 JWT 并将 JWT 发送给客户端。客户端接收到 JWT 之后，会将其保存在 Cookie 或者 localStorage 里面，以后客户端发出的所有请求都会携带这个令牌。\n简化后的步骤如下：\n用户向服务器发送用户名、密码以及验证码用于登陆系统。 如果用户用户名、密码以及验证码校验正确的话，服务端会返回已经签名的 Token，也就是 JWT。 用户以后每次向后端发请求都在 Header 中带上这个 JWT 。 服务端检查 JWT 并从中获取用户相关信息。 两点建议：\n建议将 JWT 存放在 localStorage 中，放在 Cookie 中会有 CSRF 风险。 请求服务端并携带 JWT 的常见做法是将其放在 HTTP Header 的 Authorization 字段中（Authorization: Bearer Token）。 # 如何防止JWT被篡改 有了签名之后，服务端拿到JWT，会解析出其中包含的Header、Payload以及Signature。服务端会根据Header、Payload、密钥再次生成一个Signature。拿新生成Signature和JWT中的Signature进行对比，如果一样说明Header和Payload没有被修改。\n因此，密钥一定一定要保护好，JWT的安全核心在于签名，签名安全的核心在密钥。\n# 如何加强JWT的安全性 使用安全系数高的加密算法。 使用成熟的开源库，没必要造轮子。 JWT 存放在 localStorage 中而不是 Cookie 中，避免 CSRF 风险。 一定不要将隐私信息存放在 Payload 当中。 密钥一定保管好，一定不要泄露出去。JWT 安全的核心在于签名，签名安全的核心在密钥。 Payload 要加入 exp （JWT 的过期时间），永久有效的 JWT 不合理。并且，JWT 的过期时间不易过长。 # JWT的优点 有下面4个优势：\n# 无状态 JWT 自身包含了身份验证所需要的所有信息，因此，我们的服务器不需要存储 Session 信息。这显然增加了系统的可用性和伸缩性，大大减轻了服务端的压力。\n不过，也正是由于 JWT 的无状态，也导致了它最大的缺点：不可控！\n就比如说，我们想要在 JWT 有效期内废弃一个 JWT 或者更改它的权限的话，并不会立即生效，通常需要等到有效期过后才可以。再比如说，当用户 Logout 的话，JWT 也还有效。除非，我们在后端增加额外的处理逻辑比如将失效的 JWT 存储起来，后端先验证 JWT 是否有效再进行处理。具体的解决办法，我们会在后面的内容中详细介绍到，这里只是简单提一下。\n# 有效避免了CSRF攻击 CSRF（Cross Site Request Forgery） 一般被翻译为 跨站请求伪造。举个例子：\n这一天，小明同学百无聊赖地刷着Gmail邮件。大部分都是没营养的通知、验证码、聊天记录之类。但有一封邮件引起了小明的注意：\n甩卖比特币，一个只要998！！\n聪明的小明当然知道这种肯定是骗子，但还是抱着好奇的态度点了进去（请勿模仿）。果然，这只是一个什么都没有的空白页面，小明失望的关闭了页面。一切似乎什么都没有发生……\n在这平静的外表之下，黑客的攻击已然得手。小明的Gmail中，被偷偷设置了一个过滤规则，这个规则使得所有的邮件都会被自动转发到hacker@hackermail.com。小明还在继续刷着邮件，殊不知他的邮件正在一封封地，如脱缰的野马一般地，持续不断地向着黑客的邮箱转发而去。\n不久之后的一天，小明发现自己的域名已经被转让了。懵懂的小明以为是域名到期自己忘了续费，直到有一天，对方开出了 $650 的赎回价码，小明才开始觉得不太对劲。\n小明仔细查了下域名的转让，对方是拥有自己的验证码的，而域名的验证码只存在于自己的邮箱里面。小明回想起那天奇怪的链接，打开后重新查看了“空白页”的源码：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;form method=\u0026#34;POST\u0026#34; action=\u0026#34;https://mail.google.com/mail/h/ewt1jmuj4ddv/?v=prf\u0026#34; enctype=\u0026#34;multipart/form-data\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;cf2_emc\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;cf2_email\u0026#34; value=\u0026#34;hacker@hakermail.com\u0026#34;/\u0026gt; ..... \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;irf\u0026#34; value=\u0026#34;on\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;nvp_bu_cftb\u0026#34; value=\u0026#34;Create Filter\u0026#34;/\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;script\u0026gt; document.forms[0].submit(); \u0026lt;/script\u0026gt; 这个页面只要打开，就会向Gmail发送一个post请求。请求中，执行了“Create Filter”命令，将所有的邮件，转发到“hacker@hackermail.com”。\n小明由于刚刚就登陆了Gmail，所以这个请求发送时，携带着小明的登录凭证（Cookie），Gmail的后台接收到请求，验证了确实有小明的登录凭证，于是成功给小明配置了过滤器。\n黑客可以查看小明的所有邮件，包括邮件里的域名验证码等隐私信息。拿到验证码之后，黑客就可以要求域名服务商把域名重置给自己。\n小明很快打开Gmail，找到了那条过滤器，将其删除。然而，已经泄露的邮件，已经被转让的域名，再也无法挽回了……\n# JWT是如何进行避免的 一般情况下我们使用JWT的话，会在我们登陆成功获得JWT之后，一般会选择存放在localStorage中。前端的每一个请求后续都会附带这个JWT，整个过程压根不会涉及到Cookie。因此，即使你点击了非法链接发送了请求到服务端，这个非法请求也是不会携带JWT，所以这个请求将是非法的。\n总结：使用JWT进行身份验证不需要依赖Cookie，因此可以避免CSRF攻击。\n但是会存在XSS攻击。常见的避免 XSS 攻击的方式是过滤掉请求中存在 XSS 攻击风险的可疑字符串。\n# 适用于移动端 使用 Session 进行身份认证的话，需要保存一份信息在服务器端，而且这种方式会依赖到 Cookie（需要 Cookie 保存 SessionId），所以不适合移动端。\n但是，使用 JWT 进行身份认证就不会存在这种问题，因为只要 JWT 可以被客户端存储就能够使用，而且 JWT 还可以跨语言使用。\n为什么使用 Session 进行身份认证的话不适合移动端 ？\n状态管理: Session 基于服务器端的状态管理，而移动端应用通常是无状态的。移动设备的连接可能不稳定或中断，因此难以维护长期的会话状态。如果使用 Session 进行身份认证，移动应用需要频繁地与服务器进行会话维护，增加了网络开销和复杂性; 兼容性: 移动端应用通常会面向多个平台，如 iOS、Android 和 Web。每个平台对于 Session 的管理和存储方式可能不同，可能导致跨平台兼容性的问题; 安全性: 移动设备通常处于不受信任的网络环境，存在数据泄露和攻击的风险。将敏感的会话信息存储在移动设备上增加了被攻击的潜在风险。 # 单点登录友好 使用 Session 进行身份认证的话，实现单点登录，需要我们把用户的 Session 信息保存在一台电脑上，并且还会遇到常见的 Cookie 跨域的问题。但是，使用 JWT 进行认证的话， JWT 被保存在客户端，不会存在这些问题。\n# JWT 身份认证常见问题及解决办法 # 注销登录场景下JWT还有效 与之类似的具体相关场景有：\n退出登录; 修改密码; 服务端修改了某个用户具有的权限或者角色； 用户的帐户被封禁/删除； 用户被服务端强制注销； 用户被踢下线； …… 这个问题不存在于 Session 认证方式中，因为在 Session 认证方式中，遇到这种情况的话服务端删除对应的 Session 记录即可。但是，使用 JWT 认证的方式就不好解决了。我们也说过了，JWT 一旦派发出去，如果后端不增加其他逻辑的话，它在失效之前都是有效的。\n那我们如何解决这个问题呢？\n1. 将 JWT 存入数据库\n将有效的 JWT 存入数据库中，更建议使用内存数据库比如 Redis。如果需要让某个 JWT 失效就直接从 Redis 中删除这个 JWT 即可。但是，这样会导致每次使用 JWT 都要先从 Redis 中查询 JWT 是否存在的步骤，而且违背了 JWT 的无状态原则。\n2. 黑名单机制\n和上面的方式类似，使用内存数据库比如 Redis 维护一个黑名单，如果想让某个 JWT 失效的话就直接将这个 JWT 加入到 黑名单 即可。然后，每次使用 JWT 进行请求的话都会先判断这个 JWT 是否存在于黑名单中。\n前两种方案的核心在于将有效的 JWT 存储起来或者将指定的 JWT 拉入黑名单。\n虽然这两种方案都违背了 JWT 的无状态原则，但是一般实际项目中我们通常还是会使用这两种方案。\n3. 修改密钥 (Secret) :\n我们为每个用户都创建一个专属密钥，如果我们想让某个 JWT 失效，我们直接修改对应用户的密钥即可。但是，这样相比于前两种引入内存数据库带来了危害更大：\n如果服务是分布式的，则每次发出新的 JWT 时都必须在多台机器同步密钥。为此，你需要将密钥存储在数据库或其他外部服务中，这样和 Session 认证就没太大区别了。 如果用户同时在两个浏览器打开系统，或者在手机端也打开了系统，如果它从一个地方将账号退出，那么其他地方都要重新进行登录，这是不可取的。 4. 保持令牌的有效期限短并经常轮换\n很简单的一种方式。但是，会导致用户登录状态不会被持久记录，而且需要用户经常登录。\n另外，对于修改密码后 JWT 还有效问题的解决还是比较容易的。说一种我觉得比较好的方式：使用用户的密码的哈希值对 JWT 进行签名。因此，如果密码更改，则任何先前的令牌将自动无法验证。\n# JWT续签问题 JWT 有效期一般都建议设置的不太长，那么 JWT 过期后如何认证，如何实现动态刷新 JWT，避免用户经常需要重新登录？\n我们先来看看在 Session 认证中一般的做法：假如 Session 的有效期 30 分钟，如果 30 分钟内用户有访问，就把 Session 有效期延长 30 分钟。\nJWT 认证的话，我们应该如何解决续签问题呢？\n1、类似于 Session 认证中的做法（不推荐）\n这种方案满足于大部分场景。假设服务端给的 JWT 有效期设置为 30 分钟，服务端每次进行校验时，如果发现 JWT 的有效期马上快过期了，服务端就重新生成 JWT 给客户端。客户端每次请求都检查新旧 JWT，如果不一致，则更新本地的 JWT。这种做法的问题是仅仅在快过期的时候请求才会更新 JWT ，对客户端不是很友好。\n2、每次请求都返回新 JWT（不推荐）\n这种方案的的思路很简单，但是，开销会比较大，尤其是在服务端要存储维护 JWT 的情况下。\n3、JWT 有效期设置到半夜（不推荐）\n这种方案是一种折衷的方案，保证了大部分用户白天可以正常登录，适用于对安全性要求不高的系统。\n4、用户登录返回两个 JWT（推荐）\n第一个是 accessJWT ，它的过期时间 JWT 本身的过期时间比如半个小时，另外一个是 refreshJWT 它的过期时间更长一点比如为 1 天。refreshJWT 只用来获取 accessJWT，不容易被泄露。\n客户端登录后，将 accessJWT 和 refreshJWT 保存在本地，每次访问将 accessJWT 传给服务端。服务端校验 accessJWT 的有效性，如果过期的话，就将 refreshJWT 传给服务端。如果有效，服务端就生成新的 accessJWT 给客户端。否则，客户端就重新登录即可。\n这种方案的不足是：\n需要客户端来配合； 用户注销的时候需要同时保证两个 JWT 都无效； 重新请求获取 JWT 的过程中会有短暂 JWT 不可用的情况（可以通过在客户端设置定时器，当 accessJWT 快过期的时候，提前去通过 refreshJWT 获取新的 accessJWT）; 存在安全问题，只要拿到了未过期的 refreshJWT 就一直可以获取到 accessJWT。不过，由于 refreshJWT 只用来获取 accessJWT，不容易被泄露。 # 总结 介绍了JWT的概念，结构，使用场景，以及对应的优点，存在的缺陷，身份认证存在的问题等。\n","date":"2024-05-13T07:40:30+08:00","permalink":"https://runqizhao.cn/p/jwt%E8%AF%A6%E8%A7%A3/","title":"Jwt详解"},{"content":" # 认证和鉴权 说简单点：\n认证（Authentication）：你是谁。 鉴权（Authorization）：你有权限干什么。 正式点的：\n认证：是验证身份的凭据（例如用户名/用户ID和密码），通过这个凭据，系统得以知道你的身份，也就是这个用户的身份，也就是相当于你的身份凭证。 鉴权：发生在认证之后。分配给用户能够使用的资源，如果是系统管理员，这个时候就有增删改查的权限，诸如此类。 这两个一般在我们的系统中被结合在一起使用，目的就是为了保护我们系统的安全性。\n# RBAC模型 RBAC是基于角色的权限访问控制。这是一种通过角色关联权限，角色同时有关联用户的授权方式。\n简单来说：一个用户可以拥有若干角色，每一个角色又可以被分配若干权限，这样构造成“用户-角色-权限“的授权模型。这种模型中，用户与角色、角色与权限之间构成了多对多的关系。\n通常来说，如果系统对于权限控制要求比较严格的话，一般都会选择使用 RBAC 模型来做权限控制。\n# Cookie Cookie 和 Session 都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。\n简单来说：Cookie 存放在客户端，一般用来保存用户信息。\n下面是 Cookie 的一些应用案例：\n我们在 Cookie 中保存已经登录过的用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了。除此之外，Cookie 还能保存用户首选项，主题和其他设置信息。 使用 Cookie 保存 SessionId 或者 Token ，向后端发送请求的时候带上 Cookie，这样后端就能取到 Session 或者 Token 了。这样就能记录用户当前的状态了，因为 HTTP 协议是无状态的。 Cookie 还可以用来记录和分析用户行为。举个简单的例子你在网上购物的时候，因为 HTTP 协议是没有状态的，如果服务器想要获取你在某个页面的停留状态或者看了哪些商品，一种常用的实现方式就是将这些信息存放在 Cookie # Cookie 和 Session 有什么区别？ Session 的主要作用就是通过服务端记录用户的状态。 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。\nCookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。相对来说 Session 安全性更高。如果使用 Cookie 的一些敏感信息不要写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。\n# 如何使用cookie-session进行身份验证 很多时候都是使用SessionID来实现特定的用户，SessionID一般会存放在Redis中。\n用户成功登陆系统，然后返回用户端具有SessionID的Cooike。\n当用户向后端发起请求的时候会把SessionID带上，这样后端就知道你的身份状态了。\n用户向服务器发送用户名、密码、验证码用于登陆系统。\n服务器验证通过后，服务器为用户创建一个 Session，并将 Session 信息存储起来。\n服务器向用户返回一个 SessionID，写入用户的 Cookie。\n当用户保持登录状态时，Cookie 将与每个后续请求一起被发送出去。\n服务器可以将存储在 Cookie 上的 SessionID 与存储在内存中或者数据库中的 Session 信息进行比较，以验证用户的身份，返回给用户客户端响应信息的时候会附带用户当前的状态。\n使用 Session 的时候需要注意下面几个点：\n依赖 Session 的关键业务一定要确保客户端开启了 Cookie。 注意 Session 的过期时间。 # 多服务节点下cookie-session 存在问题：加入部署了两份相同的服务A，B，用户第一次登陆的时候，使用的是A服务器，这个时候用户的Session信息保存在A服务器。第二次访问的时候负载均衡访问的是B服务器，由于B服务器没有保存用户的Session信息，这个时候需要重新进行登录。\n解决办法：\n某个用户的所有请求都通过特性的哈希策略分配给同一个服务器处理。这样的话，每个服务器都保存了一部分用户的 Session 信息。服务器宕机，其保存的所有 Session 信息就完全丢失了。 每一个服务器保存的 Session 信息都是互相同步的，也就是说每一个服务器都保存了全量的 Session 信息。每当一个服务器的 Session 信息发生变化，我们就将其同步到其他服务器。这种方案成本太大，并且，节点越多时，同步成本也越高。 单独使用一个所有服务器都能访问到的数据节点（比如缓存）来存放 Session 信息。为了保证高可用，数据节点尽量要避免是单点。 Spring Session 是一个用于在多个服务器之间管理会话的项目。它可以与多种后端存储（如 Redis、MongoDB 等）集成，从而实现分布式会话管理。通过 Spring Session，可以将会话数据存储在共享的外部存储中，以实现跨服务器的会话同步和共享。 # 如果没有cookie，session可以使用吗 如果客户端禁用了 Cookie，那么 Session 就无法正常工作。\n但是，并不是没有 Cookie 之后就不能用 Session 了，比如你可以将 SessionID 放在请求的 url 里面https://runqizhao.cn/?Session_id=xxx 。这种方案的话可行，但是安全性和用户体验感降低。当然，为了安全你也可以对 SessionID 进行一次加密之后再传入后端。\n# 如何防止CSRF攻击？ CSRF(Cross Site Request Forgery) 一般被翻译为 跨站请求伪造 。举个例子：\n小壮登录了某网上银行，他来到了网上银行的帖子区，看到一个帖子下面有一个链接写着“科学理财，年盈利率过万”，小壮好奇的点开了这个链接，结果发现自己的账户少了 10000 元。这是这么回事呢？原来黑客在链接中藏了一个请求，这个请求直接利用小壮的身份给银行发送了一个转账请求,也就是通过你的 Cookie 向银行发出请求。\n上面也提到过，进行 Session 认证的时候，我们一般使用 Cookie 来存储 SessionId,当我们登陆后后端生成一个 SessionId 放在 Cookie 中返回给客户端，服务端通过 Redis 或者其他存储工具记录保存着这个 SessionId，客户端登录以后每次请求都会带上这个 SessionId，服务端通过这个 SessionId 来标示你这个人。如果别人通过 Cookie 拿到了 SessionId 后就可以代替你的身份访问系统了。\nSession 认证中 Cookie 中的 SessionId 是由浏览器发送到服务端的，借助这个特性，攻击者就可以通过让用户误点攻击链接，达到攻击效果。\n但是，我们使用 Token 的话就不会存在这个问题，在我们登录成功获得 Token 之后，一般会选择存放在 localStorage （浏览器本地存储）中。然后我们在前端通过某些方式会给每个发到后端的请求加上这个 Token,这样就不会出现 CSRF 漏洞的问题。因为，即使你点击了非法链接发送了请求到服务端，这个非法请求是不会携带 Token 的，所以这个请求将是非法的。\n需要注意的是：不论是 Cookie 还是 Token 都无法避免 跨站脚本攻击（Cross Site Scripting）XSS 。\n跨站脚本攻击（Cross Site Scripting）缩写为 CSS 但这会与层叠样式表（Cascading Style Sheets，CSS）的缩写混淆。因此，有人将跨站脚本攻击缩写为 XSS。\nXSS 中攻击者会用各种方式将恶意代码注入到其他用户的页面中。就可以通过脚本盗用信息比如 Cookie 。\n","date":"2024-05-12T23:21:52+08:00","permalink":"https://runqizhao.cn/p/%E8%AE%A4%E8%AF%81%E4%B8%8E%E9%89%B4%E6%9D%83/","title":"认证与鉴权"},{"content":" # 什么是CDN CDN 全称是 Content Delivery Network/Content Distribution Network，翻译过的意思是 内容分发网络 。\n这个概念个人觉得可以跟DNS进行比较，也就是咱们再找对应目标（数据）的时候，从不同DNS上查找，减少总域名服务器的压力。总体来说，CDN可以分为两个部分：\n内容：指的是静态资源比如图片、视频、文档、JS、CSS、HTML。 分发网络：指的是将这些静态资源分发到位于多个不同的地理位置机房中的服务器上，这样，就可以实现静态资源的就近访问比如北京的用户直接访问北京机房的数据。 CDN 就是将静态资源分发到多个不同的地方以实现就近访问，进而加快静态资源的访问速度，减轻服务器以及带宽的负担。\n我们经常拿全站加速和内容分发网络做对比，不要把两者搞混了！全站加速（不同云服务商叫法不同，腾讯云叫 ECDN、阿里云叫 DCDN）既可以加速静态资源又可以加速动态资源，内容分发网络（CDN）主要针对的是 静态资源 。\n# CDN工作原理 咱们再请求资源的时候，如果没有CDN，会经过以下步骤：\n而在使用CDN后，源站域名解析将配置为Cname，即将域名解析到CDN域名，并最终由CDN厂商的GSLB分配IP。此时，整体的访问流程变成如下所示，浏览器将到CDN节点请求资源。\n# GSLB GSLB系统可以基于智能的DNS技术来实现，相比于传统DNS具有功能更加强大、更加智能的特点。GSLB根据预先配置好的策略，为用户分配最适合的节点地址。\n以下几种为GSLB常见的调度策略：\n. 基于Local DNS的静态调度\n该策略会根据Local DNS的IP地址（或者终端机器的IP地址），然后在配置里面找到IP所对应的区域，返回该区域最适合的CDN节点地址给到客户端。\n. 基于RTT的调度\nRTT（Round-Trip Time）指节点到目标之间数据的往返时延，该策略会根据Local DNS的IP地址，将候选的CDN节点与该地址的RTT进行比较，并将其中RTT小的节点调度给用户。\n. 基于成本和带宽的调度\n成本方面主要从CDN厂商角度考虑，比如在某些业务少的地区，调度器会将部分请求调度给到其他区域的节点处理，这样可以减少在该区域的节点部署 。而基于带宽的调度则会根据CDN节点的出口带宽大小计算权重，分配访问请求。\n. 基于服务等级的调度\n该策略基于目标域名的企业服务等级，通常会将质量更好节点分配给等级更高的企业客户，以便提供给高级别用户更好的服务。\n以上几种为常见的调度策略，CDN厂商通常会将这几种方式结合使用，在成本和带宽满足的情况下，尽量提供就近选择的节点资源。当然，不排除部分CDN厂商还会有自身的定制化策略。\n# 缓存系统 缓存系统最基本的工作单元就是许许多多的Cache节点(缓存服务器），Cache节点负责直接响应最终用户的访问请求，把缓存在本地的内容快速提供给用户。同时 ，Cache节点也会与源站进行内容同步，把更新的内容以及本地没有的内容从源站点获取并保存在本地。\n缓存系统可能存在着多层级的架构，如典型的三层架构：边缘节点作为最接近用户的节点，提供给到用户进行就近访问。当边缘节点未命中资源时，会向上层节点请求。如果在中心节点仍未命中，则会回源到源站进行获取。\n这个其实就是：咱们将对应经常使用的，放在对应的边缘节点，然后不经常使用的放在中心节点。\n# 静态资源是如何加载到CDN中的 可以使用预热与回源两种方法进行加载：\n预热是指在 CDN 上提前将内容缓存到 CDN 节点上。这样当用户在请求这些资源时，能够快速地从最近的 CDN 节点获取到而不需要回源，进而减少了对源站的访问压力，提高了访问速度。 回源：当 CDN 节点上没有用户请求的资源或该资源的缓存已经过期时，CDN 节点需要从原始服务器获取最新的资源内容，这个过程就是回源。当用户请求发生回源的话，会导致该请求的响应速度比未使用 CDN 还慢，因为相比于未使用 CDN 还多了一层 CDN 的调用流程。 # 如何防止资源被盗 如果我们的资源被其他用户或者网站非法盗刷的话，将会是一笔不小的开支。\n解决这个问题最常用最简单的办法设置 Referer 防盗链，具体来说就是根据 HTTP 请求的头信息里面的 Referer 字段对请求进行限制。我们可以通过 Referer 字段获取到当前请求页面的来源页面的网站地址，这样我们就能确定请求是否来自合法的网站。\n这种方式比较基础，如果站点的防盗链配置允许 Referer 为空的话，通过隐藏 Referer，可以直接绕开防盗链。\n因此，通常情况下，我们会配合其他机制来确保静态资源被盗用，一种常用的机制是 时间戳防盗链 。相比之下，时间戳防盗链 的安全性更强一些。时间戳防盗链加密的 URL 具有时效性，过期之后就无法再被允许访问。\n时间戳防盗链的 URL 通常会有两个参数一个是签名字符串，一个是过期时间。签名字符串一般是通过对用户设定的加密字符串、请求路径、过期时间通过 MD5 哈希算法取哈希的方式获得。\n# 总结 CDN 就是将静态资源分发到多个不同的地方以实现就近访问，进而加快静态资源的访问速度，减轻服务器以及带宽的负担。\n基于成本、稳定性和易用性考虑，建议直接选择专业的云厂商（比如阿里云、腾讯云、华为云、青云）或者 CDN 厂商（比如网宿、蓝汛）提供的开箱即用的 CDN 服务。\nGSLB （Global Server Load Balance，全局负载均衡）是 CDN 的大脑，负责多个 CDN 节点之间相互协作，最常用的是基于 DNS 的 GSLB。CDN 会通过 GSLB 找到最合适的 CDN 节点。\n为了防止静态资源被盗用，我们可以利用 Referer 防盗链 + 时间戳防盗链 。\n","date":"2024-05-11T16:42:42+08:00","permalink":"https://runqizhao.cn/p/cdn%E8%AF%A6%E8%A7%A3/","title":"CDN详解"},{"content":" # 分布式ID的介绍 # 什么是ID 日常开发中，我们需要对系统中的各种数据使用 ID 唯一表示，比如用户 ID 对应且仅对应一个人，商品 ID 对应且仅对应一件商品，订单 ID 对应且仅对应一个订单。\n我们现实生活中也有各种 ID，比如身份证 ID 对应且仅对应一个人、地址 ID 对应且仅对应一个地址。\n简单来说，ID 就是数据的唯一标识。\n# 什么是分布式ID 分布式 ID 是分布式系统下的 ID。分布式 ID 不存在与现实生活中，属于计算机系统中的一个概念。\n我简单举一个分库分表的例子。\n我司的一个项目，使用的是单机 MySQL 。但是，没想到的是，项目上线一个月之后，随着使用人数越来越多，整个系统的数据量将越来越大。单机 MySQL 已经没办法支撑了，需要进行分库分表（推荐 Sharding-JDBC）。\n在分库之后， 数据遍布在不同服务器上的数据库，数据库的自增主键已经没办法满足生成的主键唯一了。我们如何为不同的数据节点生成全局唯一主键呢？\n这个时候就需要生成分布式 ID了。\n# 分布式ID需要满足哪些需求 分布式 ID 作为分布式系统中必不可少的一环，很多地方都要用到分布式 ID。\n一个最基本的分布式 ID 需要满足下面这些要求：\n全局唯一：ID 的全局唯一性肯定是首先要满足的！ 高性能：分布式 ID 的生成速度要快，对本地资源消耗要小。 高可用：生成分布式 ID 的服务要保证可用性无限接近于 100%。 方便易用：拿来即用，使用方便，快速接入！ 除了这些之外，一个比较好的分布式 ID 还应保证：\n安全：ID 中不包含敏感信息。 有序递增：如果要把 ID 存放在数据库的话，ID 的有序性可以提升数据库写入速度。并且，很多时候 ，我们还很有可能会直接通过 ID 来进行排序。 有具体的业务含义：生成的 ID 如果能有具体的业务含义，可以让定位问题以及开发更透明化（通过 ID 就能确定是哪个业务）。 独立部署：也就是分布式系统单独有一个发号器服务，专门用来生成分布式 ID。这样就生成 ID 的服务可以和业务相关的服务解耦。不过，这样同样带来了网络调用消耗增加的问题。总的来说，如果需要用到分布式 ID 的场景比较多的话，独立部署的发号器服务还是很有必要的。 # 分布式ID常见解决方案 # 数据库 # 数据库主键自增 这种方式就比较简单直白了，就是通过关系型数据库的自增主键产生来唯一的 ID。\n优点：实现起来比较简单、ID 有序递增、存储消耗空间小\n缺点：支持的并发量不大、存在数据库单点问题（可以使用数据库集群解决，不过增加了复杂度）、ID 没有具体业务含义、安全问题（比如根据订单 ID 的递增规律就能推算出每天的订单量，商业机密啊！ ）、每次获取 ID 都要访问一次数据库（增加了对数据库的压力，获取速度也慢）。\n# 数据库号段模式 基于数据库的号段模式来生成分布式 ID。\n优点：ID 有序递增、存储消耗空间小\n缺点：存在数据库单点问题（可以使用数据库集群解决，不过增加了复杂度）、ID 没有具体业务含义、安全问题（比如根据订单 ID 的递增规律就能推算出每天的订单量，商业机密啊！ ）\n# NoSQL 一般情况下，NoSQL 方案使用 Redis 多一些。我们通过 Redis 的 incr 命令即可实现对 id 原子顺序递增。\n1 2 3 4 5 6 127.0.0.1:6379\u0026gt; set sequence_id_biz_type 1 OK 127.0.0.1:6379\u0026gt; incr sequence_id_biz_type (integer) 2 127.0.0.1:6379\u0026gt; get sequence_id_biz_type \u0026#34;2\u0026#34; 为了提高可用性和并发，我们可以使用 Redis Cluster。Redis Cluster 是 Redis 官方提供的 Redis 集群解决方案（3.0+版本）。\n除了高可用和并发之外，我们知道 Redis 基于内存，我们需要持久化数据，避免重启机器或者机器故障后数据丢失。Redis 支持两种不同的持久化方式：快照（snapshotting，RDB）、只追加文件（append-only file, AOF）。 并且，Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。\nRedis 方案的优缺点：\n优点：性能不错并且生成的 ID 是有序递增的 缺点：和数据库主键自增方案的缺点类似 # 算法 # UUID UUID 是 Universally Unique Identifier（通用唯一标识符） 的缩写。UUID 包含 32 个 16 进制数字（8-4-4-4-12）。\nJDK 就提供了现成的生成 UUID 的方法，一行代码就行了。\n1 2 //输出示例：cb4a9ede-fa5e-4585-b9bb-d60bce986eaa UUID.randomUUID() RFC 4122open in new window 中关于 UUID 的示例是这样的：\n我们这里重点关注一下这个 Version(版本)，不同的版本对应的 UUID 的生成规则是不同的。\n优点：生成速度比较快、简单易用\n缺点：存储消耗空间大（32 个字符串，128 位）、 不安全（基于 MAC 地址生成 UUID 的算法会造成 MAC 地址泄露)、无序（非自增）、没有具体业务含义、需要解决重复 ID 问题（当机器时间不对的情况下，可能导致会产生重复 ID）\n# 雪花算法（重点） Snowflake 是 Twitter 开源的分布式 ID 生成算法。Snowflake 由 64 bit 的二进制数字组成，这 64bit 的二进制被分成了几部分，每一部分存储的数据都有特定的含义：\nsign(1bit):符号位（标识正负），始终为 0，代表生成的 ID 为正数。 timestamp (41 bits):一共 41 位，用来表示时间戳，单位是毫秒，可以支撑 2 ^41 毫秒（约 69 年） datacenter id + worker id (10 bits):一般来说，前 5 位表示机房 ID，后 5 位表示机器 ID（实际项目中可以根据实际情况调整）。这样就可以区分不同集群/机房的节点。 sequence (12 bits):一共 12 位，用来表示序列号。 序列号为自增值，代表单台机器每毫秒能够产生的最大 ID 数(2^12 = 4096),也就是说单台机器每毫秒最多可以生成 4096 个 唯一 ID。 在实际项目中，我们一般也会对 Snowflake 算法进行改造，最常见的就是在 Snowflake 算法生成的 ID 中加入业务类型信息。\n我们再来看看 Snowflake 算法的优缺点：\n优点：生成速度比较快、生成的 ID 有序递增、比较灵活（可以对 Snowflake 算法进行简单的改造比如加入业务 ID） 缺点：需要解决重复 ID 问题（ID 生成依赖时间，在获取时间的时候，可能会出现时间回拨的问题，也就是服务器上的时间突然倒退到之前的时间，进而导致会产生重复 ID）、依赖机器 ID 对分布式环境不友好（当需要自动启停或增减机器时，固定的机器 ID 可能不够灵活）。 雪花算法有许多现成的优化，需要重点掌握:\n在开源项目中看到一个改良版的雪花算法，现在它是你的了。 《Leaf——美团点评分布式 ID 生成系统》 ","date":"2024-04-30T10:14:29+08:00","permalink":"https://runqizhao.cn/p/%E5%88%86%E5%B8%83%E5%BC%8Fid/","title":"分布式ID"},{"content":" # Http长轮询 Zookeeper和WebSocket 数据同步的机制比较简单，而 Http长轮询则比较复杂。 Apache ShenYu 借鉴了 Apollo、Nacos 的设计思想，取其精华，自己实现了 Http长轮询数据同步功能。注意，这里并非传统的 ajax 长轮询！\nHttp长轮询 机制如上所示，Apache ShenYu网关主动请求 shenyu-admin 的配置服务，读取超时时间为 90s，意味着网关层请求配置服务最多会等待 90s，这样便于 shenyu-admin 配置服务及时响应变更数据，从而实现准实时推送。\nHttp长轮询 机制是由网关主动请求 shenyu-admin ，所以这次的源码分析，我们从网关这一侧开始。\n# 网关数据同步 # 加载配置 Http长轮询 数据同步配置的加载是通过spring boot的starter机制，当我们引入相关依赖和在配置文件中有如下配置时，就会加载。\n在pom文件中引入依赖：\n1 2 3 4 5 6 \u0026lt;!--shenyu data sync start use http--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shenyu\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;shenyu-spring-boot-starter-sync-data-http\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${project.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在application.yml配置文件中添加配置：\n1 2 3 4 shenyu: sync: http: url : http://localhost:9095 当网关启动时，配置类HttpSyncDataConfiguration就会执行，加载相应的Bean。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 /** * Http sync data configuration for spring boot. */ @Configuration @ConditionalOnClass(HttpSyncDataService.class) @ConditionalOnProperty(prefix = \u0026#34;shenyu.sync.http\u0026#34;, name = \u0026#34;url\u0026#34;) @EnableConfigurationProperties(value = HttpConfig.class) public class HttpSyncDataConfiguration { private static final Logger LOGGER = LoggerFactory.getLogger(HttpSyncDataConfiguration.class); /** * Rest template. * 创建RestTemplate * @param httpConfig the http config http配置 * @return the rest template */ @Bean public RestTemplate restTemplate(final HttpConfig httpConfig) { OkHttp3ClientHttpRequestFactory factory = new OkHttp3ClientHttpRequestFactory(); factory.setConnectTimeout(Objects.isNull(httpConfig.getConnectionTimeout()) ? (int) HttpConstants.CLIENT_POLLING_CONNECT_TIMEOUT : httpConfig.getConnectionTimeout()); factory.setReadTimeout(Objects.isNull(httpConfig.getReadTimeout()) ? (int) HttpConstants.CLIENT_POLLING_READ_TIMEOUT : httpConfig.getReadTimeout()); factory.setWriteTimeout(Objects.isNull(httpConfig.getWriteTimeout()) ? (int) HttpConstants.CLIENT_POLLING_WRITE_TIMEOUT : httpConfig.getWriteTimeout()); return new RestTemplate(factory); } /** * AccessTokenManager. * 创建AccessTokenManager,专门用户对admin进行http请求时access token的处理 * @param httpConfig the http config. * @param restTemplate the rest template. * @return the access token manager. */ @Bean public AccessTokenManager accessTokenManager(final HttpConfig httpConfig, final RestTemplate restTemplate) { return new AccessTokenManager(restTemplate, httpConfig); } /** * Http sync data service. * 创建 HttpSyncDataService * @param httpConfig the http config * @param pluginSubscriber the plugin subscriber * @param restTemplate the rest template * @param metaSubscribers the meta subscribers * @param authSubscribers the auth subscribers * @param accessTokenManager the access token manager * @return the sync data service */ @Bean public SyncDataService httpSyncDataService(final ObjectProvider\u0026lt;HttpConfig\u0026gt; httpConfig, final ObjectProvider\u0026lt;PluginDataSubscriber\u0026gt; pluginSubscriber, final ObjectProvider\u0026lt;RestTemplate\u0026gt; restTemplate, final ObjectProvider\u0026lt;List\u0026lt;MetaDataSubscriber\u0026gt;\u0026gt; metaSubscribers, final ObjectProvider\u0026lt;List\u0026lt;AuthDataSubscriber\u0026gt;\u0026gt; authSubscribers, final ObjectProvider\u0026lt;AccessTokenManager\u0026gt; accessTokenManager) { LOGGER.info(\u0026#34;you use http long pull sync shenyu data\u0026#34;); return new HttpSyncDataService( Objects.requireNonNull(httpConfig.getIfAvailable()), Objects.requireNonNull(pluginSubscriber.getIfAvailable()), Objects.requireNonNull(restTemplate.getIfAvailable()), metaSubscribers.getIfAvailable(Collections::emptyList), authSubscribers.getIfAvailable(Collections::emptyList), Objects.requireNonNull(accessTokenManager.getIfAvailable()) ); } } HttpSyncDataConfiguration是Http长轮询数据同步的配置类，负责创建HttpSyncDataService（负责http数据同步的具体实现）、RestTemplate和AccessTokenManager （负责与adminhttp调用时access token的处理）。它的注解如下：\n@Configuration：表示这是一个配置类； @ConditionalOnClass(HttpSyncDataService.class)：条件注解，表示要有HttpSyncDataService这个类； @ConditionalOnProperty(prefix = \u0026quot;shenyu.sync.http\u0026quot;, name = \u0026quot;url\u0026quot;)：条件注解，要有shenyu.sync.http.url这个属性配置。 @EnableConfigurationProperties(value = HttpConfig.class)：表示让HttpConfig上的注解@ConfigurationProperties(prefix = \u0026quot;shenyu.sync.http\u0026quot;)生效，将HttpConfig这个配置类注入Ioc容器中。 # 属性初始化 HttpSyncDataService 在HttpSyncDataService的构造函数中，完成属性初始化。\n1 2 3 4 5 public class HttpSyncDataService implements SyncDataService { // 省略了属性字段...... public HttpSyncDataService(final HttpConfig httpConfig, final PluginDataSubscriber pluginDataSubscriber, final RestTemplate restTemplate, final List\u0026lt;MetaDataSubscriber\u0026gt; metaDataSubscribers, final List\u0026lt;AuthDataSubscriber\u0026gt; authDataSubscribers, final AccessTokenManager accessTokenManager) { // 1.设置accessTokenManager this.accessTokenManager = accessTokenManager; // 2.创建数据处理器 this.factory = new DataRefreshFactory(pluginDataSubscriber, metaDataSubscribers, authDataSubscribers); // 3.shenyu-admin的url， 多个用逗号(,)分割 this.serverList = Lists.newArrayList(Splitter.on(\u0026#34;,\u0026#34;).split(httpConfig.getUrl())); // 4.只用于http长轮询的restTemplate this.restTemplate = restTemplate; // 5.开始执行长轮询任务 this.start(); } //...... } 上面代码中省略了其他函数和相关字段，在构造函数中完成属性的初始化，主要是：\n设置accessTokenManager，定时向admin请求更新accessToken的值。然后每次向admin发起请求时都必须将header的X-Access-Token属性设置成accessToken对应的值； 创建数据处理器，用于后续缓存各种类型的数据（插件、选择器、规则、元数据和认证数据）； 获取admin属性配置，主要是获取admin的url，admin有可能是集群，多个用逗号(,)分割； 设置RestTemplate，用于向admin发起请求； 开始执行长轮询任务。 # 开始长轮询 HttpSyncDataService#start() 在start()方法中，干了两件事情，一个是获取全量数据，即请求admin端获取所有需要同步的数据，然后将获取到的数据缓存到网关内存中。另一个是开启多线程执行长轮询任务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class HttpSyncDataService implements SyncDataService { // ...... private void start() { // It could be initialized multiple times, so you need to control that. if (RUNNING.compareAndSet(false, true)) { // fetch all group configs. this.fetchGroupConfig(ConfigGroupEnum.values()); int threadSize = serverList.size(); this.executor = new ThreadPoolExecutor(threadSize, threadSize, 60L, TimeUnit.SECONDS, new LinkedBlockingQueue\u0026lt;\u0026gt;(), ShenyuThreadFactory.create(\u0026#34;http-long-polling\u0026#34;, true)); // start long polling, each server creates a thread to listen for changes. this.serverList.forEach(server -\u0026gt; this.executor.execute(new HttpLongPollingTask(server))); } else { LOG.info(\u0026#34;shenyu http long polling was started, executor=[{}]\u0026#34;, executor); } } # 获取全量数据 HttpSyncDataService#fetchGroupConfig() ShenYu将所有需要同步的数据进行了分组，一共有5种数据类型，分别是插件、选择器、规则、元数据和认证数据。\n1 2 3 4 5 6 7 public enum ConfigGroupEnum { APP_AUTH, // 认证数据 PLUGIN, //插件 RULE, // 规则 SELECTOR, // 选择器 META_DATA; // 元数据 } admin有可能是集群，这里通过循环的方式向每个admin发起请求，有一个执行成功了，那么向admin获取全量数据并缓存到网关的操作就执行成功。如果出现了异常，就向下一个admin发起请求。\n1 2 3 4 5 public class HttpSyncDataService implements SyncDataService { // ...... private void fetchGroupConfig(final ConfigGroupEnum... groups) throws ShenyuException { // admin有可能是集群，这里通过循环的方式向每个admin发起请求 for (int index = 0; index \u0026lt; this.serverList.size(); index++) { String server = serverList.get(index); try { // 真正去执行 this.doFetchGroupConfig(server, groups); // 有一个成功，就成功了，可以退出循环 break; } catch (ShenyuException e) { // 出现异常，尝试执行下一个 // 最后一个也执行失败了，抛出异常 if (index \u0026gt;= serverList.size() - 1) { throw e; } LOG.warn(\u0026#34;fetch config fail, try another one: {}\u0026#34;, serverList.get(index + 1)); } } } // ...... } HttpSyncDataService#doFetchGroupConfig() 在此方法中，首先拼装请求参数，然后通过httpClient发起请求，到admin中获取数据，最后将获取到的数据更新到网关内存中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 public class HttpSyncDataService implements SyncDataService { private void doFetchGroupConfig(final String server, final ConfigGroupEnum... groups) { // 1. 拼请求参数，所有分组枚举类型 StringBuilder params = new StringBuilder(); for (ConfigGroupEnum groupKey : groups) { params.append(\u0026#34;groupKeys\u0026#34;).append(\u0026#34;=\u0026#34;).append(groupKey.name()).append(\u0026#34;\u0026amp;\u0026#34;); } // admin端提供的接口 /configs/fetch String url = server + Constants.SHENYU_ADMIN_PATH_CONFIGS_FETCH + \u0026#34;?\u0026#34; + StringUtils.removeEnd(params.toString(), \u0026#34;\u0026amp;\u0026#34;); LOG.info(\u0026#34;request configs: [{}]\u0026#34;, url); String json; try { HttpHeaders headers = new HttpHeaders(); // 设置accessToken headers.set(Constants.X_ACCESS_TOKEN, this.accessTokenManager.getAccessToken()); HttpEntity\u0026lt;String\u0026gt; httpEntity = new HttpEntity\u0026lt;\u0026gt;(headers); // 2. 发起请求，获取变更数据 json = this.restTemplate.exchange(url, HttpMethod.GET, httpEntity, String.class).getBody(); } catch (RestClientException e) { String message = String.format(\u0026#34;fetch config fail from server[%s], %s\u0026#34;, url, e.getMessage()); LOG.warn(message); throw new ShenyuException(message, e); } // 3. 更新网关内存中数据 boolean updated = this.updateCacheWithJson(json); if (updated) { LOG.debug(\u0026#34;get latest configs: [{}]\u0026#34;, json); return; } // 更新成功，此方法就执行完成了 LOG.info(\u0026#34;The config of the server[{}] has not been updated or is out of date. Wait for 30s to listen for changes again.\u0026#34;, server); // 服务端没有数据更新，就等30s ThreadUtils.sleep(TimeUnit.SECONDS, 30); } } 从代码中，可以看到 admin端提供的获取全量数据接口是 /configs/fetch，这里先不进一步深入，放在后文再分析。\n获取到admin返回结果数据，并成功更新，那么此方法就执行结束了。如果没有更新成功，那么有可能是服务端没有数据更新，就等待30s。\n这里需要提前说明一下，网关在判断是否更新成功时，有比对数据的操作，马上就会提到。\nHttpSyncDataService#updateCacheWithJson() 更新网关内存中的数据。使用GSON进行反序列化，从属性data中拿真正的数据，然后交给DataRefreshFactory去做更新。\n1 2 3 4 5 6 private boolean updateCacheWithJson(final String json) { // 使用GSON进行反序列化 JsonObject jsonObject = GSON.fromJson(json, JsonObject.class); // if the config cache will be updated? return factory.executor(jsonObject.getAsJsonObject(\u0026#34;data\u0026#34;)); } DataRefreshFactory#executor() 根据不同数据类型去更新数据，返回更新结果。具体更新逻辑交给了dataRefresh.refresh()方法。在更新结果中，有一种数据类型进行了更新，就表示此次操作发生了更新。\n1 2 3 4 5 6 7 public boolean executor(final JsonObject data) { //并行更新数据 List\u0026lt;Boolean\u0026gt; result = ENUM_MAP.values().parallelStream() .map(dataRefresh -\u0026gt; dataRefresh.refresh(data)) .collect(Collectors.toList()); //有一个更新就表示此次发生了更新操作 return result.stream().anyMatch(Boolean.TRUE::equals); } AbstractDataRefresh#refresh() 数据更新逻辑采用的是模板方法设计模式，通用操作在抽象方法中完成，不同的实现逻辑由子类完成。5种数据类型具体的更新逻辑有些差异，但是也存在通用的更新逻辑，类图关系如下：\n在通用的refresh()方法中，负责数据类型转换，判断是否需要更新，和实际的数据刷新操作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public abstract class AbstractDataRefresh\u0026lt;T\u0026gt; implements DataRefresh { // ...... @Override public Boolean refresh(final JsonObject data) { // 数据类型转换 JsonObject jsonObject = convert(data); if (Objects.isNull(jsonObject)) { return false; } boolean updated = false; // 得到数据类型 ConfigData\u0026lt;T\u0026gt; result = fromJson(jsonObject); // 是否需要更新 if (this.updateCacheIfNeed(result)) { updated = true; // 真正的更新逻辑，数据刷新操作 refresh(result.getData()); } return updated; } // ...... } AbstractDataRefresh#updateCacheIfNeed() 数据转换的过程，就是根据不同的数据类型进行转换，我们就不再进一步追踪了，看看数据是否需要更新的逻辑。方法名是updateCacheIfNeed()，通过方法重载实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public abstract class AbstractDataRefresh\u0026lt;T\u0026gt; implements DataRefresh { // ...... // result是数据 protected abstract boolean updateCacheIfNeed(ConfigData\u0026lt;T\u0026gt; result); // newVal是获取到的最新的值 // groupEnum 是哪种数据类型 protected boolean updateCacheIfNeed(final ConfigData\u0026lt;T\u0026gt; newVal, final ConfigGroupEnum groupEnum) { // 如果是第一次，那么直接放到cache中，返回 true，表示此次进行了更新 if (GROUP_CACHE.putIfAbsent(groupEnum, newVal) == null) { return true; } ResultHolder holder = new ResultHolder(false); GROUP_CACHE.merge(groupEnum, newVal, (oldVal, value) -\u0026gt; { // md5 值相同，不需要更新 if (StringUtils.equals(oldVal.getMd5(), newVal.getMd5())) { LOG.info(\u0026#34;Get the same config, the [{}] config cache will not be updated, md5:{}\u0026#34;, groupEnum, oldVal.getMd5()); return oldVal; } // 当前缓存的数据修改时间大于 新来的数据，不需要更新 // must compare the last update time if (oldVal.getLastModifyTime() \u0026gt;= newVal.getLastModifyTime()) { LOG.info(\u0026#34;Last update time earlier than the current configuration, the [{}] config cache will not be updated\u0026#34;, groupEnum); return oldVal; } LOG.info(\u0026#34;update {} config: {}\u0026#34;, groupEnum, newVal); holder.result = true; return newVal; }); return holder.result; } // ...... } 从上面的源码中可以看到，有两种情况不需要更新：\n两个的数据的md5 值相同，不需要更新; 当前缓存的数据修改时间大于 新来的数据，不需要更新。 其他情况需要更新数据。\n分析到这里，就将start() 方法中初次启动，获取全量数据的逻辑分析完了，接下来是长轮询的操作。为了方便，我将start()方法再粘贴一次：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class HttpSyncDataService implements SyncDataService { // ...... private void start() { // 只初始化一次，通过原子类实现。 if (RUNNING.compareAndSet(false, true)) { // 初次启动，获取全量数据 this.fetchGroupConfig(ConfigGroupEnum.values()); // 一个后台服务，一个线程 int threadSize = serverList.size(); // 自定义线程池 this.executor = new ThreadPoolExecutor(threadSize, threadSize, 60L, TimeUnit.SECONDS, new LinkedBlockingQueue\u0026lt;\u0026gt;(), ShenyuThreadFactory.create(\u0026#34;http-long-polling\u0026#34;, true)); // 开始长轮询，一个admin服务，创建一个线程用于数据同步 this.serverList.forEach(server -\u0026gt; this.executor.execute(new HttpLongPollingTask(server))); } else { LOG.info(\u0026#34;shenyu http long polling was started, executor=[{}]\u0026#34;, executor); } } // ...... } # 执行长轮询任务 HttpLongPollingTask#run() 长轮询任务是HttpLongPollingTask，它实现了Runnable接口，任务逻辑在run()方法中。通过while()循环实现不断执行任务，即长轮询。在每一次的轮询中有三次重试逻辑，一次轮询任务失败了，等 5s 再继续，3 次都失败了，等5 分钟再试。\n开始长轮询，一个admin服务，创建一个线程用于数据同步。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class HttpLongPollingTask implements Runnable { private final String server; HttpLongPollingTask(final String server) { this.server = server; } @Override public void run() { // 一直轮询 while (RUNNING.get()) { // 默认重试 3 次 int retryTimes = 3; for (int time = 1; time \u0026lt;= retryTimes; time++) { try { doLongPolling(server); } catch (Exception e) { if (time \u0026lt; retryTimes) { LOG.warn(\u0026#34;Long polling failed, tried {} times, {} times left, will be suspended for a while! {}\u0026#34;, time, retryTimes - time, e.getMessage()); // 长轮询失败了，等 5s 再继续 ThreadUtils.sleep(TimeUnit.SECONDS, 5); continue; } LOG.error(\u0026#34;Long polling failed, try again after 5 minutes!\u0026#34;, e); // 3 次都失败了，等 5 分钟再试 ThreadUtils.sleep(TimeUnit.MINUTES, 5); } } } LOG.warn(\u0026#34;Stop http long polling.\u0026#34;); } } HttpSyncDataService#doLongPolling() 执行长轮询任务的核心逻辑：\n根据数据类型组装请求参数：md5 和 lastModifyTime； 组装请求头和请求体； 向admin发起请求，判断组数据是否发生变更； 根据发生变更的组，再去获取数据。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 public class HttpSyncDataService implements SyncDataService { private void doLongPolling(final String server) { // 组装请求参数：md5 和 lastModifyTime MultiValueMap\u0026lt;String, String\u0026gt; params = new LinkedMultiValueMap\u0026lt;\u0026gt;(8); for (ConfigGroupEnum group : ConfigGroupEnum.values()) { ConfigData\u0026lt;?\u0026gt; cacheConfig = factory.cacheConfigData(group); if (cacheConfig != null) { String value = String.join(\u0026#34;,\u0026#34;, cacheConfig.getMd5(), String.valueOf(cacheConfig.getLastModifyTime())); params.put(group.name(), Lists.newArrayList(value)); } } // 组装请求头和请求体 HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_FORM_URLENCODED); // 设置accessToken headers.set(Constants.X_ACCESS_TOKEN, this.accessTokenManager.getAccessToken()); HttpEntity\u0026lt;MultiValueMap\u0026lt;String, String\u0026gt;\u0026gt; httpEntity = new HttpEntity\u0026lt;\u0026gt;(params, headers); String listenerUrl = server + Constants.SHENYU_ADMIN_PATH_CONFIGS_LISTENER; JsonArray groupJson; //向admin发起请求，判断组数据是否发生变更 //这里只是判断了某个组是否发生变更 try { String json = this.restTemplate.postForEntity(listenerUrl, httpEntity, String.class).getBody(); LOG.info(\u0026#34;listener result: [{}]\u0026#34;, json); JsonObject responseFromServer = GsonUtils.getGson().fromJson(json, JsonObject.class); groupJson = responseFromServer.getAsJsonArray(\u0026#34;data\u0026#34;); } catch (RestClientException e) { String message = String.format(\u0026#34;listener configs fail, server:[%s], %s\u0026#34;, server, e.getMessage()); throw new ShenyuException(message, e); } // 根据发生变更的组，再去获取数据 /** * 官网对此处的解释： * 网关收到响应信息之后，只知道是哪个 Group 发生了配置变更，还需要再次请求该 Group 的配置数据。 * 这里可能会存在一个疑问：为什么不是直接将变更的数据写出？ * 我们在开发的时候，也深入讨论过该问题，因为 http 长轮询机制只能保证准实时，如果在网关层处理不及时， * 或者管理员频繁更新配置，很有可能便错过了某个配置变更的推送，安全起见，我们只告知某个 Group 信息发生了变更。 * * 个人理解： * 如果将变更数据直接写出，当管理员频繁更新配置时，第一次更新了，将client移除阻塞队列，返回响应信息给网关。 * 如果这个时候进行了第二次更新，那么当前的client是不在阻塞队列中，所以这一次的变更就会错过。 * 网关层处理不及时，也是同理。 * 这是一个长轮询，一个网关一个同步线程，可能存在耗时的过程。 * 如果admin有数据变更，当前网关client是没有在阻塞队列中，就不到数据。 */ if (Objects.nonNull(groupJson) \u0026amp;\u0026amp; groupJson.size() \u0026gt; 0) { // fetch group configuration async. ConfigGroupEnum[] changedGroups = GsonUtils.getGson().fromJson(groupJson, ConfigGroupEnum[].class); LOG.info(\u0026#34;Group config changed: {}\u0026#34;, Arrays.toString(changedGroups)); this.doFetchGroupConfig(server, changedGroups); } } } 这里需要特别解释一点的是：在长轮询任务中，为什么不直接拿到变更的数据？而是先判断哪个分组数据发生了变更，然后再次请求admin，获取变更数据？\n官网对此处的解释是：\n网关收到响应信息之后，只知道是哪个 Group 发生了配置变更，还需要再次请求该 Group 的配置数据。 这里可能会存在一个疑问：为什么不是直接将变更的数据写出？ 我们在开发的时候，也深入讨论过该问题，因为 http 长轮询机制只能保证准实时，如果在网关层处理不及时， 或者管理员频繁更新配置，很有可能便错过了某个配置变更的推送，安全起见，我们只告知某个 Group 信息发生了变更。\n个人理解是：\n如果将变更数据直接写出，管理员频繁更新配置时，第一次更新了，将client移除阻塞队列，返回响应信息给网关。如果这个时候进行了第二次更新，那么当前的client是不在阻塞队列中，所以这一次的变更就会错过。网关层处理不及时，也是同理。 这是一个长轮询，一个网关一个同步线程，可能存在耗时的过程。如果admin有数据变更，当前网关client是没有在阻塞队列中，就会更新不到数据。\n我们还没有分析到admin端的处理逻辑，先大概说一下。在admin端，会将网关client放到阻塞队列，有数据变更，网关client就会出队列，发送变更数据。所以，如果有数据变更时，网关client不在阻塞队列，那么就无法得到当前变更的数据。\n知道哪个分组数据发生变更时，主动再向admin获取变更的数据，根据分组不同，全量拿数据。调用方法是doFetchGroupConfig()，这个在前面已经分析过了。\n分析到这里，网关端的数据同步操作就完成了。长轮询任务就是不断向admin发起请求，看看数据是否发生变更，如果有分组数据发生变更，那么就再主动向admin发起请求，获取变更数据，然后更新网关内存中的数据。\n网关端长轮询任务流程：\n# admin数据同步 从前面分析的过程中，可以看到，网关端主要调用admin的两个接口：\n/configs/listener：判断组数据是否发生变更； /configs/fetch：获取变更组数据。 直接从这两个接口分析的话，可能有的地方不好理解，所以我们还是从admin启动流程开始分析数据同步过程。\n# 加载配置 如果在配置文件application.yml中，进行了如下配置，就表示通过http长轮询的方式进行数据同步。\n1 2 3 4 shenyu: sync: http: enabled: true 程序启动时，通过springboot条件装配实现数据同步类的配置加载。在这个过程中，会创建HttpLongPollingDataChangedListener，负责处理长轮询的相关实现逻辑。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /** * 数据同步配置类 * 通过springboot条件装配实现 * The type Data sync configuration. */ @Configurationpublic class DataSyncConfiguration { /** * http长轮询 * http long polling. */ @Configuration @ConditionalOnProperty(name = \u0026#34;shenyu.sync.http.enabled\u0026#34;, havingValue = \u0026#34;true\u0026#34;) @EnableConfigurationProperties(HttpSyncProperties.class) static class HttpLongPollingListener { @Bean @ConditionalOnMissingBean(HttpLongPollingDataChangedListener.class) public HttpLongPollingDataChangedListener httpLongPollingDataChangedListener(final HttpSyncProperties httpSyncProperties) { return new HttpLongPollingDataChangedListener(httpSyncProperties); } } } # 数据变更监听器实例化 HttpLongPollingDataChangedListener 数据变更监听器通过构造函数的方式完成实例化和初始化操作。在构造函数中会创建阻塞队列，用于存放客户端；创建线程池，用于执行延迟任务，周期任务；保存长轮询相关属性信息。\n1 2 3 4 5 6 7 8 9 10 public HttpLongPollingDataChangedListener(final HttpSyncProperties httpSyncProperties) { // 默认客户端（这里是网关）1024个 this.clients = new ArrayBlockingQueue\u0026lt;\u0026gt;(1024); // 创建线程池 // ScheduledThreadPoolExecutor 可以执行延迟任务，周期任务，普通任务 this.scheduler = new ScheduledThreadPoolExecutor(1, ShenyuThreadFactory.create(\u0026#34;long-polling\u0026#34;, true)); // 长轮询的属性信息 this.httpSyncProperties = httpSyncProperties; } 另外，它的类图关系如下：\n实现了InitializingBean接口，所以在bean的初始化过程中执行afterInitialize()方法。通过线程池执行周期任务：更新内存中（CACHE）的数据每隔5分钟执行一次，5分钟后开始执行。刷新本地缓存就是从数据库读取数据到本地缓存（这里就是内存），通过refreshLocalCache()完成。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class HttpLongPollingDataChangedListener extends AbstractDataChangedListener { // ...... /** * 在 InitializingBean接口中的afterPropertiesSet()方法中被调用，即在bean的初始化过程中执行 */ @Override protected void afterInitialize() { long syncInterval = httpSyncProperties.getRefreshInterval().toMillis(); // 执行周期任务：更新内存中（CACHE）的数据每隔5分钟执行一次，5分钟后开始执行 // 防止admin先启动一段时间后，产生了数据；然后网关初次连接时，没有拿到全量数据 scheduler.scheduleWithFixedDelay(() -\u0026gt; { LOG.info(\u0026#34;http sync strategy refresh config start.\u0026#34;); try { // 从数据库读取数据到本地缓存（这里就是内存） this.refreshLocalCache(); LOG.info(\u0026#34;http sync strategy refresh config success.\u0026#34;); } catch (Exception e) { LOG.error(\u0026#34;http sync strategy refresh config error!\u0026#34;, e); } }, syncInterval, syncInterval, TimeUnit.MILLISECONDS); LOG.info(\u0026#34;http sync strategy refresh interval: {}ms\u0026#34;, syncInterval); } // ...... } refreshLocalCache() 分别对5种数据类型进行更新。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public abstract class AbstractDataChangedListener implements DataChangedListener, InitializingBean { // ...... // 从数据库读取数据到本地缓存（这里就是内存） private void refreshLocalCache() { //更新认证数据 this.updateAppAuthCache(); //更新插件数据 this.updatePluginCache(); //更新规则数据 this.updateRuleCache(); //更新选择器数据 this.updateSelectorCache(); //更新元数据 this.updateMetaDataCache(); } // ...... } 5个更新方法的逻辑是类似的，调用service方法获取数据，然后放到内存CACHE中。以更新规则数据方法updateRuleCache()为例，传入规则枚举类型，调用ruleService.listAll()从数据库获取所有规则数据。\n1 2 3 4 /** * Update rule cache. */ protected void updateRuleCache() { this.updateCache(ConfigGroupEnum.RULE, ruleService.listAll()); } updateCache() 使用数据库中的数据更新内存中的数据。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public abstract class AbstractDataChangedListener implements DataChangedListener, InitializingBean { // ...... // 缓存数据的 Map protected static final ConcurrentMap\u0026lt;String, ConfigDataCache\u0026gt; CACHE = new ConcurrentHashMap\u0026lt;\u0026gt;(); /** * if md5 is not the same as the original, then update lcoal cache. * 更新缓存中的数据 * @param group ConfigGroupEnum * @param \u0026lt;T\u0026gt; the type of class * @param data the new config data */ protected \u0026lt;T\u0026gt; void updateCache(final ConfigGroupEnum group, final List\u0026lt;T\u0026gt; data) { //数据序列化 String json = GsonUtils.getInstance().toJson(data); //传入md5值和修改时间 ConfigDataCache newVal = new ConfigDataCache(group.name(), json, Md5Utils.md5(json), System.currentTimeMillis()); //更新分组数据 ConfigDataCache oldVal = CACHE.put(newVal.getGroup(), newVal); LOG.info(\u0026#34;update config cache[{}], old: {}, updated: {}\u0026#34;, group, oldVal, newVal); } // ...... } 初始化的过程就是启动周期性任务，定时从数据库获取数据更新内存数据。\n接下来开始对两个接口开始分析：\n/configs/listener：判断组数据是否发生变更； /configs/fetch：获取变更组数据。 # 数据变更轮询接口 /configs/listener：判断组数据是否发生变更； 接口类是ConfigController，只有使用http长轮询进行数据同步时才会生效。接口方法listener()没有其他逻辑，直接调用doLongPolling()方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /** * This Controller only when HttpLongPollingDataChangedListener exist, will take effect. */ @ConditionalOnBean(HttpLongPollingDataChangedListener.class) @RestController@RequestMapping(\u0026#34;/configs\u0026#34;)public class ConfigController { private final HttpLongPollingDataChangedListener longPollingListener; public ConfigController(final HttpLongPollingDataChangedListener longPollingListener) { this.longPollingListener = longPollingListener; } // 省略其他逻辑 /** * Listener. * 监听数据变更，执行长轮询 * @param request the request * @param response the response */ @PostMapping(value = \u0026#34;/listener\u0026#34;) public void listener(final HttpServletRequest request, final HttpServletResponse response) { longPollingListener.doLongPolling(request, response); } } HttpLongPollingDataChangedListener#doLongPolling() 执行长轮询任务：如果有数据变更，将会立即响应给客户端（这里就是网关端）。否则，客户端会一直被阻塞，直到有数据变更或者超时。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class HttpLongPollingDataChangedListener extends AbstractDataChangedListener { // ...... /** * 执行长轮询：如果有数据变更，会立即响应给客户端（这里就是网关端）。 * 否则，否则客户端会一直被阻塞，直到有数据变更或者超时。 * @param request * @param response */ public void doLongPolling(final HttpServletRequest request, final HttpServletResponse response) { // compare group md5 // 比较md5，判断网关的数据和admin端的数据是否一致，得到发生变更的数据组 List\u0026lt;ConfigGroupEnum\u0026gt; changedGroup = compareChangedGroup(request); String clientIp = getRemoteIp(request); // response immediately. // 有变更的数据，则立即向网关响应 if (CollectionUtils.isNotEmpty(changedGroup)) { this.generateResponse(response, changedGroup); Log.info(\u0026#34;send response with the changed group, ip={}, group={}\u0026#34;, clientIp, changedGroup); return; } // 没有变更，则将客户端（这里就是网关）放进阻塞队列 final AsyncContext asyncContext = request.startAsync(); asyncContext.setTimeout(0L); scheduler.execute(new LongPollingClient(asyncContext, clientIp, HttpConstants.SERVER_MAX_HOLD_TIMEOUT)); } // ...... } HttpLongPollingDataChangedListener#compareChangedGroup() 判断组数据是否发生变更，判断逻辑是比较网关端和admin端的md5值和lastModifyTime。\n如果md5值不一样，那么需要更新； 如果admin端的lastModifyTime大于网关端的lastModifyTime，那么需要更新。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /** * 判断组数据是否发生变更 * @param request * @return */ private List\u0026lt;ConfigGroupEnum\u0026gt; compareChangedGroup(final HttpServletRequest request) { List\u0026lt;ConfigGroupEnum\u0026gt; changedGroup = new ArrayList\u0026lt;\u0026gt;(ConfigGroupEnum.values().length); for (ConfigGroupEnum group : ConfigGroupEnum.values()) { // 网关端数据的md5值和lastModifyTime String[] params = StringUtils.split(request.getParameter(group.name()), \u0026#39;,\u0026#39;); if (params == null || params.length != 2) { throw new ShenyuException(\u0026#34;group param invalid:\u0026#34; + request.getParameter(group.name())); } String clientMd5 = params[0]; long clientModifyTime = NumberUtils.toLong(params[1]); ConfigDataCache serverCache = CACHE.get(group.name()); // do check. 判断组数据是否发生变更 if (this.checkCacheDelayAndUpdate(serverCache, clientMd5, clientModifyTime)) { changedGroup.add(group); } } return changedGroup; } LongPollingClient 没有变更数据，则将客户端（这里就是网关）放进阻塞队列。阻塞时间是60秒，即60秒后移除，并响应客户端。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class LongPollingClient implements Runnable { // 省略了其他逻辑 @Override public void run() { try { // 先设置定时任务：60秒后移除，并响应客户端 this.asyncTimeoutFuture = scheduler.schedule(() -\u0026gt; { clients.remove(LongPollingClient.this); List\u0026lt;ConfigGroupEnum\u0026gt; changedGroups = compareChangedGroup((HttpServletRequest) asyncContext.getRequest()); sendResponse(changedGroups); }, timeoutTime, TimeUnit.MILLISECONDS); // 添加到阻塞队列 clients.add(this); } catch (Exception ex) { log.error(\u0026#34;add long polling client error\u0026#34;, ex); } } /** * Send response. * * @param changedGroups the changed groups */ void sendResponse(final List\u0026lt;ConfigGroupEnum\u0026gt; changedGroups) { // cancel scheduler if (null != asyncTimeoutFuture) { asyncTimeoutFuture.cancel(false); } // 响应变更的组 generateResponse((HttpServletResponse) asyncContext.getResponse(), changedGroups); asyncContext.complete(); } } # 获取变更数据接口 /configs/fetch：获取变更数据； 根据网关传入的参数，获取分组数据，返回结果。主要实现方法是longPollingListener.fetchConfig()。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @ConditionalOnBean(HttpLongPollingDataChangedListener.class) @RestController@RequestMapping(\u0026#34;/configs\u0026#34;)public class ConfigController { private final HttpLongPollingDataChangedListener longPollingListener; public ConfigController(final HttpLongPollingDataChangedListener longPollingListener) { this.longPollingListener = longPollingListener; } /** * Fetch configs shenyu result. * 全量获取分组数据 * @param groupKeys the group keys * @return the shenyu result */ @GetMapping(\u0026#34;/fetch\u0026#34;) public ShenyuAdminResult fetchConfigs(@NotNull final String[] groupKeys) { Map\u0026lt;String, ConfigData\u0026lt;?\u0026gt;\u0026gt; result = Maps.newHashMap(); for (String groupKey : groupKeys) { ConfigData\u0026lt;?\u0026gt; data = longPollingListener.fetchConfig(ConfigGroupEnum.valueOf(groupKey)); result.put(groupKey, data); } return ShenyuAdminResult.success(ShenyuResultMessage.SUCCESS, result); } // 省略了其他接口 } AbstractDataChangedListener#fetchConfig() 数据获取直接从CACHE中拿，然后根据不同分组类型进行匹配，封装。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public abstract class AbstractDataChangedListener implements DataChangedListener, InitializingBean { /** * fetch configuration from cache. * 获取分组下的全量数据 * @param groupKey the group key * @return the configuration data */ public ConfigData\u0026lt;?\u0026gt; fetchConfig(final ConfigGroupEnum groupKey) { // 直接从 CACHE 中拿数据 ConfigDataCache config = CACHE.get(groupKey.name()); switch (groupKey) { case APP_AUTH: // 认证数据 return buildConfigData(config, AppAuthData.class); case PLUGIN: // 插件数据 return buildConfigData(config, PluginData.class); case RULE: // 规则数据 return buildConfigData(config, RuleData.class); case SELECTOR: // 选择器数据 return buildConfigData(config, SelectorData.class); case META_DATA: // 元数据 return buildConfigData(config, MetaData.class); default: // 其他类型，抛出异常 throw new IllegalStateException(\u0026#34;Unexpected groupKey: \u0026#34; + groupKey); } } } # 数据变更 在之前的websocket数据同步和zookeeper数据同步源码分析文章中，我们知道admin端数据同步设计结构如下：\n各种数据变更监听器都是DataChangedListener的子类。\n当在admin端修改数据后，通过Spring的事件处理机制，发送事件通知。发送逻辑如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 /** * Event forwarders, which forward the changed events to each ConfigEventListener. * 数据变更事件分发器：当admin端有数据发生变更时，将变更数据同步到 ShenYu 网关 * 数据变更依赖于Spring的事件监听机制：ApplicationEventPublisher --\u0026gt; ApplicationEvent --\u0026gt; ApplicationListener * */ @Component public class DataChangedEventDispatcher implements ApplicationListener\u0026lt;DataChangedEvent\u0026gt;, InitializingBean { //省略了其他逻辑 /** * 有数据变更时，调用此方法 * @param event */ @Override @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public void onApplicationEvent(final DataChangedEvent event) { // 遍历数据变更监听器(一般使用一种数据同步的方式就好了) for (DataChangedListener listener : listeners) { // 哪种数据发生变更 switch (event.getGroupKey()) { case APP_AUTH: // 认证信息 listener.onAppAuthChanged((List\u0026lt;AppAuthData\u0026gt;) event.getSource(), event.getEventType()); break; case PLUGIN: // 插件信息 listener.onPluginChanged((List\u0026lt;PluginData\u0026gt;) event.getSource(), event.getEventType()); break; case RULE: // 规则信息 listener.onRuleChanged((List\u0026lt;RuleData\u0026gt;) event.getSource(), event.getEventType()); break; case SELECTOR: // 选择器信息 listener.onSelectorChanged((List\u0026lt;SelectorData\u0026gt;) event.getSource(), event.getEventType()); // 当选择器数据更新时，更新API文档信息 applicationContext.getBean(LoadServiceDocEntry.class).loadDocOnSelectorChanged((List\u0026lt;SelectorData\u0026gt;) event.getSource(), event.getEventType()); break; case META_DATA: // 元数据 listener.onMetaDataChanged((List\u0026lt;MetaData\u0026gt;) event.getSource(), event.getEventType()); break; default: // 其他类型，抛出异常 throw new IllegalStateException(\u0026#34;Unexpected value: \u0026#34; + event.getGroupKey()); } } } } 假设，对插件信息进行了修改，通过http长轮询的方式进行数据同步，那么listener.onPluginChanged()的实际调用的是org.apache.shenyu.admin.listener.AbstractDataChangedListener#onPluginChanged：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /** * 在admin的操作，有插件发生了更新 * @param changed the changed * @param eventType the event type */ @Override public void onPluginChanged(final List\u0026lt;PluginData\u0026gt; changed, final DataEventTypeEnum eventType) { if (CollectionUtils.isEmpty(changed)) { return; } // 更新内存CACHE this.updatePluginCache(); // 执行变更任务 this.afterPluginChanged(changed, eventType); } 有两个处理操作，一是更新内存CACHE，这个在前面分析过了；另一个是执行变更任务，在线程池中执行。\nHttpLongPollingDataChangedListener#afterPluginChanged() 1 2 3 4 5 @Override protected void afterPluginChanged(final List\u0026lt;PluginData\u0026gt; changed, final DataEventTypeEnum eventType) { // 在线程池中执行 scheduler.execute(new DataChangeTask(ConfigGroupEnum.PLUGIN)); } DataChangeTask 数据变更任务：将阻塞队列中的客户端依次移除，并发送响应，通知网关有组数据发生变更。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class DataChangeTask implements Runnable { //省略了其他逻辑 @Override public void run() { // 阻塞队列中的客户端超过了给定的值100，则分批执行 if (clients.size() \u0026gt; httpSyncProperties.getNotifyBatchSize()) { List\u0026lt;LongPollingClient\u0026gt; targetClients = new ArrayList\u0026lt;\u0026gt;(clients.size()); clients.drainTo(targetClients); List\u0026lt;List\u0026lt;LongPollingClient\u0026gt;\u0026gt; partitionClients = Lists.partition(targetClients, httpSyncProperties.getNotifyBatchSize()); // 分批执行 partitionClients.forEach(item -\u0026gt; scheduler.execute(() -\u0026gt; doRun(item))); } else { // 执行任务 doRun(clients); } } private void doRun(final Collection\u0026lt;LongPollingClient\u0026gt; clients) { // 通知所有客户端发生了数据变更 for (Iterator\u0026lt;LongPollingClient\u0026gt; iter = clients.iterator(); iter.hasNext();) { LongPollingClient client = iter.next(); iter.remove(); // 发送响应 client.sendResponse(Collections.singletonList(groupKey)); LOG.info(\u0026#34;send response with the changed group,ip={}, group={}, changeTime={}\u0026#34;, client.ip, groupKey, changeTime); } } } 至此，admin端数据同步逻辑就分析完了。在基于http长轮询数据同步是，它主要有三个功能：\n提供数据变更监听接口； 提供获取变更数据接口； 有数据变更时，移除阻塞队列中的客户端，并响应结果。 最后，用三张图描述下admin端长轮询任务流程：\n/configs/listener数据变更监听接口： /configs/fetch获取变更数据接口： 在admin后台管理系统更新数据，进行数据同步： # 总结 文主要对ShenYu网关中的http长轮询数据同步进行了源码分析。涉及到的主要知识点如下：\nhttp长轮询由网关端主动发起请求，不断请求admin端； 变更数据以组为粒度（认证信息、插件、选择器、规则、元数据）； http长轮询结果只拿到了变更组，还需要再次发起请求获取组数据； 数据是否更新由md5值和修改时间lastModifyTime决定。 ","date":"2024-04-29T18:59:19+08:00","image":"https://shenyu.apache.org/zh/img/logo.svg","permalink":"https://runqizhao.cn/p/%E6%9C%8D%E5%8A%A1%E5%90%8C%E6%AD%A5-hhtp%E9%95%BF%E8%BD%AE%E8%AF%A2/","title":"服务同步-hhtp长轮询"},{"content":"在我们炼丹的时候，一般卷积神经网络是我们 不可避免 接触到的概念，就算你 使用使用时 Transformer，其实也是跟卷积神将网络中的 部分思想是相关，本文将会 解析 Pytorch 中 conv2d 中的源码，简单说明其中 的原理，只有深度了解了对应的 原理，才能更好的进行 修改。\n首先的话还是老规矩，看官方链接。\n从连接上面虽然可以对每个变量有深刻的理解，但是还是迷迷糊糊，为了更改好的理解，本文从一个例子说起，说明其中对应的内容，然后与 前面编写 e2cnn 的群卷积神经网络 进行对比，争取彻底理解二者之间 每一步的关联以及对应的意思。\n这个例子很简单，就是下面一句代码：\n1 m = nn.Conv2d(16, 33, 3, stride=2) 其中16时我们输入特征的通道数，33时我们设置的输出特征的通道数，3时卷积核的大小（$3 \\times 3$），stride是步长。然后我们看Conv2d的源码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 class Conv2d(_ConvNd): __doc__ = r\u0026#34;\u0026#34;\u0026#34;Applies a 2D convolution over an input signal composed of several input planes. In the simplest case, the output value of the layer with input size :math:`(N, C_{\\text{in}}, H, W)` and output :math:`(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})` can be precisely described as: .. math:: \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) + \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k) where :math:`\\star` is the valid 2D `cross-correlation`_ operator, :math:`N` is a batch size, :math:`C` denotes a number of channels, :math:`H` is a height of input planes in pixels, and :math:`W` is width in pixels. \u0026#34;\u0026#34;\u0026#34; + r\u0026#34;\u0026#34;\u0026#34; This module supports :ref:`TensorFloat32\u0026lt;tf32_on_ampere\u0026gt;`. * :attr:`stride` controls the stride for the cross-correlation, a single number or a tuple. * :attr:`padding` controls the amount of padding applied to the input. It can be either a string {{\u0026#39;valid\u0026#39;, \u0026#39;same\u0026#39;}} or a tuple of ints giving the amount of implicit padding applied on both sides. * :attr:`dilation` controls the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does. {groups_note} The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be: - a single ``int`` -- in which case the same value is used for the height and width dimension - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension, and the second `int` for the width dimension Note: {depthwise_separable_note} Note: {cudnn_reproducibility_note} Note: ``padding=\u0026#39;valid\u0026#39;`` is the same as no padding. ``padding=\u0026#39;same\u0026#39;`` pads the input so the output has the shape as the input. However, this mode doesn\u0026#39;t support any stride values other than 1. Args: in_channels (int): Number of channels in the input image out_channels (int): Number of channels produced by the convolution kernel_size (int or tuple): Size of the convolving kernel stride (int or tuple, optional): Stride of the convolution. Default: 1 padding (int, tuple or str, optional): Padding added to all four sides of the input. Default: 0 padding_mode (string, optional): ``\u0026#39;zeros\u0026#39;``, ``\u0026#39;reflect\u0026#39;``, ``\u0026#39;replicate\u0026#39;`` or ``\u0026#39;circular\u0026#39;``. Default: ``\u0026#39;zeros\u0026#39;`` dilation (int or tuple, optional): Spacing between kernel elements. Default: 1 groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1 bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True`` \u0026#34;\u0026#34;\u0026#34;.format(**reproducibility_notes, **convolution_notes) + r\u0026#34;\u0026#34;\u0026#34; Shape: - Input: :math:`(N, C_{in}, H_{in}, W_{in})` or :math:`(C_{in}, H_{in}, W_{in})` - Output: :math:`(N, C_{out}, H_{out}, W_{out})` or :math:`(C_{out}, H_{out}, W_{out})`, where .. math:: H_{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0] \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor .. math:: W_{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1] \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor Attributes: weight (Tensor): the learnable weights of the module of shape :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},` :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`. The values of these weights are sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}` bias (Tensor): the learnable bias of the module of shape (out_channels). If :attr:`bias` is ``True``, then the values of these weights are sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}` Examples: \u0026gt;\u0026gt;\u0026gt; # With square kernels and equal stride \u0026gt;\u0026gt;\u0026gt; m = nn.Conv2d(16, 33, 3, stride=2) \u0026gt;\u0026gt;\u0026gt; # non-square kernels and unequal stride and with padding \u0026gt;\u0026gt;\u0026gt; m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2)) \u0026gt;\u0026gt;\u0026gt; # non-square kernels and unequal stride and with padding and dilation \u0026gt;\u0026gt;\u0026gt; m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1)) \u0026gt;\u0026gt;\u0026gt; input = torch.randn(20, 16, 50, 100) \u0026gt;\u0026gt;\u0026gt; output = m(input) .. _cross-correlation: https://en.wikipedia.org/wiki/Cross-correlation .. _link: https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md \u0026#34;\u0026#34;\u0026#34; def __init__( self, in_channels: int, out_channels: int, kernel_size: _size_2_t, stride: _size_2_t = 1, padding: Union[str, _size_2_t] = 0, dilation: _size_2_t = 1, groups: int = 1, bias: bool = True, padding_mode: str = \u0026#39;zeros\u0026#39;, # TODO: refine this type device=None, dtype=None ) -\u0026gt; None: factory_kwargs = {\u0026#39;device\u0026#39;: device, \u0026#39;dtype\u0026#39;: dtype} kernel_size_ = _pair(kernel_size) stride_ = _pair(stride) padding_ = padding if isinstance(padding, str) else _pair(padding) dilation_ = _pair(dilation) super(Conv2d, self).__init__( in_channels, out_channels, kernel_size_, stride_, padding_, dilation_, False, _pair(0), groups, bias, padding_mode, **factory_kwargs) ok，在了解了我们输入的变量之后，下面一句来看其中的内容。\nfactory_kwargs = {'device': device, 'dtype': dtype}这个就是指定你先使用的 设备 是什么（CPU or CUDA）。\nkernel_size_ = _pair(kernel_size)就是将对应 我们输入的卷积核大小变成对应的pair形式(3 -\u0026gt; $3 \\times 3$)。\nstride_ = _pair(stride)这个的话同理，将数值变成 对应的pair形式(2 -\u0026gt; $2 \\times 2$)。\npadding_ = padding if isinstance(padding, str) else _pair(padding)也是同理，不过是这里你再输入的时候可能已经是对应padding形式。\ndilation_ = _pair(dilation)这句话依然是同理，将数值变成对应的pair形式()。\nsuper(Conv2d, self).__init__(in_channels, out_channels, kernel_size_, stride_, padding_, dilation_,False, _pair(0), groups, bias, padding_mode, **factory_kwargs)这个函数是我们需要着重关注的 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 def __init__(self, in_channels: int, out_channels: int, kernel_size: Tuple[int, ...], stride: Tuple[int, ...], padding: Tuple[int, ...], dilation: Tuple[int, ...], transposed: bool, output_padding: Tuple[int, ...], groups: int, bias: bool, padding_mode: str, device=None, dtype=None) -\u0026gt; None: factory_kwargs = {\u0026#39;device\u0026#39;: device, \u0026#39;dtype\u0026#39;: dtype} super(_ConvNd, self).__init__() if in_channels % groups != 0: raise ValueError(\u0026#39;in_channels must be divisible by groups\u0026#39;) if out_channels % groups != 0: raise ValueError(\u0026#39;out_channels must be divisible by groups\u0026#39;) valid_padding_strings = {\u0026#39;same\u0026#39;, \u0026#39;valid\u0026#39;} if isinstance(padding, str): if padding not in valid_padding_strings: raise ValueError( \u0026#34;Invalid padding string {!r}, should be one of {}\u0026#34;.format( padding, valid_padding_strings)) if padding == \u0026#39;same\u0026#39; and any(s != 1 for s in stride): raise ValueError(\u0026#34;padding=\u0026#39;same\u0026#39; is not supported for strided convolutions\u0026#34;) valid_padding_modes = {\u0026#39;zeros\u0026#39;, \u0026#39;reflect\u0026#39;, \u0026#39;replicate\u0026#39;, \u0026#39;circular\u0026#39;} if padding_mode not in valid_padding_modes: raise ValueError(\u0026#34;padding_mode must be one of {}, but got padding_mode=\u0026#39;{}\u0026#39;\u0026#34;.format( valid_padding_modes, padding_mode)) self.in_channels = in_channels self.out_channels = out_channels self.kernel_size = kernel_size self.stride = stride self.padding = padding self.dilation = dilation self.transposed = transposed self.output_padding = output_padding self.groups = groups self.padding_mode = padding_mode # `_reversed_padding_repeated_twice` is the padding to be passed to # `F.pad` if needed (e.g., for non-zero padding types that are # implemented as two ops: padding + conv). `F.pad` accepts paddings in # reverse order than the dimension. if isinstance(self.padding, str): self._reversed_padding_repeated_twice = [0, 0] * len(kernel_size) if padding == \u0026#39;same\u0026#39;: for d, k, i in zip(dilation, kernel_size, range(len(kernel_size) - 1, -1, -1)): total_padding = d * (k - 1) left_pad = total_padding // 2 self._reversed_padding_repeated_twice[2 * i] = left_pad self._reversed_padding_repeated_twice[2 * i + 1] = ( total_padding - left_pad) else: self._reversed_padding_repeated_twice = _reverse_repeat_tuple(self.padding, 2) if transposed: self.weight = Parameter(torch.empty( (in_channels, out_channels // groups, *kernel_size), **factory_kwargs)) else: self.weight = Parameter(torch.empty( (out_channels, in_channels // groups, *kernel_size), **factory_kwargs)) if bias: self.bias = Parameter(torch.empty(out_channels, **factory_kwargs)) else: self.register_parameter(\u0026#39;bias\u0026#39;, None) self.reset_parameters() 这个函数中仍然是相同的，最开始进行初始化，指定 weight，bias的大小。然后看 reset_parameters这个函数。\n1 2 3 4 5 6 7 8 9 10 def reset_parameters(self) -\u0026gt; None: # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with # uniform(-1/sqrt(k), 1/sqrt(k)), where k = weight.size(1) * prod(*kernel_size) # For more details see: https://github.com/pytorch/pytorch/issues/15314#issuecomment-477448573 init.kaiming_uniform_(self.weight, a=math.sqrt(5)) if self.bias is not None: fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight) if fan_in != 0: bound = 1 / math.sqrt(fan_in) init.uniform_(self.bias, -bound, bound) 这段代码的作用时重新初始化层的 参数（权重和偏置）。\n然后我们逐步检查这个方法的功能：\ninit.kaiming_uniform_(self.weight, a=math.sqrt(5))：这个的话使用了PyTorch的kaiming_uniform_初始化方法 ，采用Kaiming He等人提出的初始化策略，针对ReLU激活函数的权重初始化方法。然后的话看这个函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def kaiming_uniform_(tensor, a=0, mode=\u0026#39;fan_in\u0026#39;, nonlinearity=\u0026#39;leaky_relu\u0026#39;): r\u0026#34;\u0026#34;\u0026#34;Fills the input `Tensor` with values according to the method described in `Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification` - He, K. et al. (2015), using a uniform distribution. The resulting tensor will have values sampled from :math:`\\mathcal{U}(-\\text{bound}, \\text{bound})` where .. math:: \\text{bound} = \\text{gain} \\times \\sqrt{\\frac{3}{\\text{fan\\_mode}}} Also known as He initialization. Args: tensor: an n-dimensional `torch.Tensor` a: the negative slope of the rectifier used after this layer (only used with ``\u0026#39;leaky_relu\u0026#39;``) mode: either ``\u0026#39;fan_in\u0026#39;`` (default) or ``\u0026#39;fan_out\u0026#39;``. Choosing ``\u0026#39;fan_in\u0026#39;`` preserves the magnitude of the variance of the weights in the forward pass. Choosing ``\u0026#39;fan_out\u0026#39;`` preserves the magnitudes in the backwards pass. nonlinearity: the non-linear function (`nn.functional` name), recommended to use only with ``\u0026#39;relu\u0026#39;`` or ``\u0026#39;leaky_relu\u0026#39;`` (default). Examples: \u0026gt;\u0026gt;\u0026gt; w = torch.empty(3, 5) \u0026gt;\u0026gt;\u0026gt; nn.init.kaiming_uniform_(w, mode=\u0026#39;fan_in\u0026#39;, nonlinearity=\u0026#39;relu\u0026#39;) \u0026#34;\u0026#34;\u0026#34; if torch.overrides.has_torch_function_variadic(tensor): return torch.overrides.handle_torch_function( kaiming_uniform_, (tensor,), tensor=tensor, a=a, mode=mode, nonlinearity=nonlinearity) if 0 in tensor.shape: warnings.warn(\u0026#34;Initializing zero-element tensors is a no-op\u0026#34;) return tensor fan = _calculate_correct_fan(tensor, mode) gain = calculate_gain(nonlinearity, a) std = gain / math.sqrt(fan) bound = math.sqrt(3.0) * std # Calculate uniform bounds from standard deviation with torch.no_grad(): return tensor.uniform_(-bound, bound) 这段代码的作用初始化权重的代码之一，使用均匀分布初始化权重。\n计算_calculate_correct_fan函数计算对应 的权重张量。然后的话看这个函数。\n1 2 3 4 5 6 7 8 def _calculate_correct_fan(tensor, mode): mode = mode.lower() valid_modes = [\u0026#39;fan_in\u0026#39;, \u0026#39;fan_out\u0026#39;] if mode not in valid_modes: raise ValueError(\u0026#34;Mode {} not supported, please use one of {}\u0026#34;.format(mode, valid_modes)) fan_in, fan_out = _calculate_fan_in_and_fan_out(tensor) return fan_in if mode == \u0026#39;fan_in\u0026#39; else fan_out 套娃函数，看_calculate_fan_in_and_fan_out这个函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def _calculate_fan_in_and_fan_out(tensor): dimensions = tensor.dim() if dimensions \u0026lt; 2: raise ValueError(\u0026#34;Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\u0026#34;) num_input_fmaps = tensor.size(1) num_output_fmaps = tensor.size(0) receptive_field_size = 1 if tensor.dim() \u0026gt; 2: # math.prod is not always available, accumulate the product manually # we could use functools.reduce but that is not supported by TorchScript for s in tensor.shape[2:]: receptive_field_size *= s fan_in = num_input_fmaps * receptive_field_size fan_out = num_output_fmaps * receptive_field_size return fan_in, fan_out 这个函数算是看到对应的 内容是怎么计算的了，首先，我们先获取权重，通过权重的大小计算fan_in和 fan_out。\ndimensions = tensor.dim(): 获取张量的维度数。\n如果张量的维度数小于 2，则抛出异常，因为无法为少于 2 维的张量计算 fan_in 和 fan_out。\n计算 num_input_fmaps 和 num_output_fmaps：\nnum_input_fmaps 是输入特征图的数量，通常对应于输入张量的第二个维度的大小（索引为 1）。\nnum_output_fmaps 是输出特征图的数量，通常对应于输出张量的第一个维度的大小（索引为 0）。\n如果张量的维度大于 2：\n初始化 receptive_field_size 为 1。 对张量的除了前两个维度（通常是批量大小和通道数）之外的维度进行遍历，计算这些维度的乘积，以计算感受野的大小。 这里采用了一个循环，将除前两个维度外的所有维度大小相乘，得到 receptive_field_size。 然后计算fan_in和fan_out：\nfan_in 是输入通道数量，是输入特征图数量乘以感受野大小的结果。 fan_out 是输出通道数量，是输出特征图数量乘以感受野大小的结果。 然后计算返回计算得到的fan_in和fan_out。\nok，现在我们得到对应的权重张量，然后接着看下面的函数。\n1 2 3 4 5 gain = calculate_gain(nonlinearity, a) std = gain / math.sqrt(fan) bound = math.sqrt(3.0) * std # Calculate uniform bounds from standard deviation with torch.no_grad(): return tensor.uniform_(-bound, bound) 然后这里我们需要看计算gain(增益)的函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 def calculate_gain(nonlinearity, param=None): r\u0026#34;\u0026#34;\u0026#34;Return the recommended gain value for the given nonlinearity function. The values are as follows: ================= ==================================================== nonlinearity gain ================= ==================================================== Linear / Identity :math:`1` Conv{1,2,3}D :math:`1` Sigmoid :math:`1` Tanh :math:`\\frac{5}{3}` ReLU :math:`\\sqrt{2}` Leaky Relu :math:`\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}` SELU :math:`\\frac{3}{4}` ================= ==================================================== .. warning:: In order to implement `Self-Normalizing Neural Networks`_ , you should use ``nonlinearity=\u0026#39;linear\u0026#39;`` instead of ``nonlinearity=\u0026#39;selu\u0026#39;``. This gives the initial weights a variance of ``1 / N``, which is necessary to induce a stable fixed point in the forward pass. In contrast, the default gain for ``SELU`` sacrifices the normalisation effect for more stable gradient flow in rectangular layers. Args: nonlinearity: the non-linear function (`nn.functional` name) param: optional parameter for the non-linear function Examples: \u0026gt;\u0026gt;\u0026gt; gain = nn.init.calculate_gain(\u0026#39;leaky_relu\u0026#39;, 0.2) # leaky_relu with negative_slope=0.2 .. _Self-Normalizing Neural Networks: https://papers.nips.cc/paper/2017/hash/5d44ee6f2c3f71b73125876103c8f6c4-Abstract.html \u0026#34;\u0026#34;\u0026#34; linear_fns = [\u0026#39;linear\u0026#39;, \u0026#39;conv1d\u0026#39;, \u0026#39;conv2d\u0026#39;, \u0026#39;conv3d\u0026#39;, \u0026#39;conv_transpose1d\u0026#39;, \u0026#39;conv_transpose2d\u0026#39;, \u0026#39;conv_transpose3d\u0026#39;] if nonlinearity in linear_fns or nonlinearity == \u0026#39;sigmoid\u0026#39;: return 1 elif nonlinearity == \u0026#39;tanh\u0026#39;: return 5.0 / 3 elif nonlinearity == \u0026#39;relu\u0026#39;: return math.sqrt(2.0) elif nonlinearity == \u0026#39;leaky_relu\u0026#39;: if param is None: negative_slope = 0.01 elif not isinstance(param, bool) and isinstance(param, int) or isinstance(param, float): # True/False are instances of int, hence check above negative_slope = param else: raise ValueError(\u0026#34;negative_slope {} not a valid number\u0026#34;.format(param)) return math.sqrt(2.0 / (1 + negative_slope ** 2)) elif nonlinearity == \u0026#39;selu\u0026#39;: return 3.0 / 4 # Value found empirically (https://github.com/pytorch/pytorch/pull/50664) else: raise ValueError(\u0026#34;Unsupported nonlinearity {}\u0026#34;.format(nonlinearity)) LeakyReLU: 返回$\\sqrt\\frac{2}{1 + negative_slope}$\n计算出对应的gain，然后接着往下走。\n1 2 3 4 std = gain / math.sqrt(fan) bound = math.sqrt(3.0) * std # Calculate uniform bounds from standard deviation with torch.no_grad(): return tensor.uniform_(-bound, bound) 这个的话就是数值 计算出对应的标准差以及均匀分布的边界bound，这个是$\\sqrt 3$乘以对应的 标准差。\n计算出来这些之后，进行返回。然后接着看返回后的 下面的 函数。\n1 2 3 4 5 if self.bias is not None: fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight) if fan_in != 0: bound = 1 / math.sqrt(fan_in) init.uniform_(self.bias, -bound, bound) 这几句话的作用时 如果当前 偏置参数不为空，通过权重计算出对应fain_in（输入通道数量），如果说当前输入通道数不为0，则对方法偏执参数的均匀分布的重新初始化。\n这些都计算完毕之后，就返回了。\n返回的内容如下 ：\n得到了对应的内容，然后我们看官网中有这么 一个公式： $$ out(N_{i},C_{out_{j}}) = bias(C_{out_{j}}) + \\sum_{k = 0}^{C_m - 1} weight(C_{out_{j}},k) \\star input(N_{i},k) $$ 其实上面的过程，就是这个公式的计算。\n# 总结 其实我们在使用的 时候，一般不会看着详细的计算过程，因为这个公式已经介绍的很清楚了，但是最近在看群卷积神经网络，对于卷积这块突然间不知道对应的滤波是怎么进行设置，因此将这部分重新简单看下，这部分比较简单，但是其中也有很多细节值得深究，象何凯明大佬里面的leaky_relu这个函数的设置等等，不得不承认好的开源社区就是充满活力，代码写的真的好。\n","date":"2023-12-05T14:30:19+08:00","permalink":"https://runqizhao.cn/p/conv2d%E7%9A%84%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3/","title":"Conv2d的简单理解"},{"content":"下面开始讲解对应R2Conv对应的 模块，这里的话我们还是从ReResNet中进行运行，然后拿到对应的数据，在拿到对应的数据之后，将里面的值进行传递，然后供面进行使用。\n在对应的前面三节中，我们已经创建了对应循环群，输入类型，输出类型，这个里面，是将里面内容进行利用。\n还是从ReResNet中开始看起，在我们进行初始化的时候，会运行下面语句：\n1 self._make_stem_layer(in_channels, stem_channels) 然后看这个函数里面的内容\n1 2 3 4 5 6 7 8 9 10 11 def _make_stem_layer(self, in_channels, stem_channels): \u0026#34;\u0026#34;\u0026#34;Build stem layer.\u0026#34;\u0026#34;\u0026#34; if not self.deep_stem: self.conv1 = ennTrivialConv( in_channels, stem_channels, kernel_size=7, stride=2, padding=3) self.norm1_name, norm1 = build_enn_norm_layer( stem_channels, postfix=1) self.add_module(self.norm1_name, norm1) self.relu = ennReLU(stem_channels) self.maxpool = ennMaxPool( stem_channels, kernel_size=3, stride=2, padding=1) 然后继续看ennTrivialConv这个函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def ennTrivialConv(inplanes, outplanes, kernel_size=3, stride=1, padding=0, groups=1, bias=False, dilation=1): \u0026#34;\u0026#34;\u0026#34;enn convolution with trivial input feature. Args: in_channels (List[int]): Number of input channels per scale. out_channels (int): Number of output channels (used at each scale). kernel_size (int, optional): The size of kernel. stride (int, optional): Stride of the convolution. Default: 1. padding (int or tuple): Zero-padding added to both sides of the input. Default: 0. groups (int): Number of blocked connections from input. channels to output channels. Default: 1. bias (bool): If True, adds a learnable bias to the output. Default: False. dilation (int or tuple): Spacing between kernel elements. Default: 1. \u0026#34;\u0026#34;\u0026#34; in_type = build_enn_trivial_feature(inplanes) out_type = build_enn_divide_feature(outplanes) return enn.R2Conv( in_type, out_type, kernel_size, stride=stride, padding=padding, groups=groups, bias=bias, dilation=dilation, sigma=None, frequencies_cutoff=lambda r: 3 * r, ) 这里的话在前两讲中以及说明了对应的 输入类型和输出类型，这里的话直接将对应的内容进行截图，不再进行详细阐述，如果说不了解的话去看前面两节。\nok，知道了这些内容 ，下面来看本文的核心函数 ：R2Conv函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 class R2Conv(EquivariantModule): def __init__(self, in_type: FieldType, out_type: FieldType, kernel_size: int, padding: int = 0, stride: int = 1, dilation: int = 1, padding_mode: str = \u0026#39;zeros\u0026#39;, groups: int = 1, bias: bool = True, basisexpansion: str = \u0026#39;blocks\u0026#39;, sigma: Union[List[float], float] = None, frequencies_cutoff: Union[float, Callable[[float], int]] = None, rings: List[float] = None, maximum_offset: int = None, recompute: bool = False, basis_filter: Callable[[dict], bool] = None, initialize: bool = True, ): r\u0026#34;\u0026#34;\u0026#34; G-steerable planar convolution mapping between the input and output :class:`~e2cnn.nn.FieldType` s specified by the parameters ``in_type`` and ``out_type``. This operation is equivariant under the action of :math:`\\R^2\\rtimes G` where :math:`G` is the :attr:`e2cnn.nn.FieldType.fibergroup` of ``in_type`` and ``out_type``. Specifically, let :math:`\\rho_\\text{in}: G \\to \\GL{\\R^{c_\\text{in}}}` and :math:`\\rho_\\text{out}: G \\to \\GL{\\R^{c_\\text{out}}}` be the representations specified by the input and output field types. Then :class:`~e2cnn.nn.R2Conv` guarantees an equivariant mapping .. math:: \\kappa \\star [\\mathcal{T}^\\text{in}_{g,u} . f] = \\mathcal{T}^\\text{out}_{g,u} . [\\kappa \\star f] \\qquad\\qquad \\forall g \\in G, u \\in \\R^2 where the transformation of the input and output fields are given by .. math:: [\\mathcal{T}^\\text{in}_{g,u} . f](x) \u0026amp;= \\rho_\\text{in}(g)f(g^{-1} (x - u)) \\\\ [\\mathcal{T}^\\text{out}_{g,u} . f](x) \u0026amp;= \\rho_\\text{out}(g)f(g^{-1} (x - u)) \\\\ The equivariance of G-steerable convolutions is guaranteed by restricting the space of convolution kernels to an equivariant subspace. As proven in `3D Steerable CNNs \u0026lt;https://arxiv.org/abs/1807.02547\u0026gt;`_, this parametrizes the *most general equivariant convolutional map* between the input and output fields. For feature fields on :math:`\\R^2` (e.g. images), the complete G-steerable kernel spaces for :math:`G \\leq \\O2` is derived in `General E(2)-Equivariant Steerable CNNs \u0026lt;https://arxiv.org/abs/1911.08251\u0026gt;`_. During training, in each forward pass the module expands the basis of G-steerable kernels with learned weights before calling :func:`torch.nn.functional.conv2d`. When :meth:`~torch.nn.Module.eval()` is called, the filter is built with the current trained weights and stored for future reuse such that no overhead of expanding the kernel remains. .. warning :: When :meth:`~torch.nn.Module.train()` is called, the attributes :attr:`~e2cnn.nn.R2Conv.filter` and :attr:`~e2cnn.nn.R2Conv.expanded_bias` are discarded to avoid situations of mismatch with the learnable expansion coefficients. See also :meth:`e2cnn.nn.R2Conv.train`. This behaviour can cause problems when storing the :meth:`~torch.nn.Module.state_dict` of a model while in a mode and lately loading it in a model with a different mode, as the attributes of the class change. To avoid this issue, we recommend converting the model to eval mode before storing or loading the state dictionary. The learnable expansion coefficients of the this module can be initialized with the methods in :mod:`e2cnn.nn.init`. By default, the weights are initialized in the constructors using :func:`~e2cnn.nn.init.generalized_he_init`. .. warning :: This initialization procedure can be extremely slow for wide layers. In case initializing the model is not required (e.g. before loading the state dict of a pre-trained model) or another initialization method is preferred (e.g. :func:`~e2cnn.nn.init.deltaorthonormal_init`), the parameter ``initialize`` can be set to ``False`` to avoid unnecessary overhead. The parameters ``basisexpansion``, ``sigma``, ``frequencies_cutoff``, ``rings`` and ``maximum_offset`` are optional parameters used to control how the basis for the filters is built, how it is sampled on the filter grid and how it is expanded to build the filter. We suggest to keep these default values. Args: in_type (FieldType): the type of the input field, specifying its transformation law out_type (FieldType): the type of the output field, specifying its transformation law kernel_size (int): the size of the (square) filter padding (int, optional): implicit zero paddings on both sides of the input. Default: ``0`` padding_mode(str, optional): ``zeros``, ``reflect``, ``replicate`` or ``circular``. Default: ``zeros`` stride (int, optional): the stride of the kernel. Default: ``1`` dilation (int, optional): the spacing between kernel elements. Default: ``1`` groups (int, optional): number of blocked connections from input channels to output channels. It allows depthwise convolution. When used, the input and output types need to be divisible in ``groups`` groups, all equal to each other. Default: ``1``. bias (bool, optional): Whether to add a bias to the output (only to fields which contain a trivial irrep) or not. Default ``True`` basisexpansion (str, optional): the basis expansion algorithm to use sigma (list or float, optional): width of each ring where the bases are sampled. If only one scalar is passed, it is used for all rings. frequencies_cutoff (callable or float, optional): function mapping the radii of the basis elements to the maximum frequency accepted. If a float values is passed, the maximum frequency is equal to the radius times this factor. By default (``None``), a more complex policy is used. rings (list, optional): radii of the rings where to sample the bases maximum_offset (int, optional): number of additional (aliased) frequencies in the intertwiners for finite groups. By default (``None``), all additional frequencies allowed by the frequencies cut-off are used. recompute (bool, optional): if ``True``, recomputes a new basis for the equivariant kernels. By Default (``False``), it caches the basis built or reuse a cached one, if it is found. basis_filter (callable, optional): function which takes as input a descriptor of a basis element (as a dictionary) and returns a boolean value: whether to preserve (``True``) or discard (``False``) the basis element. By default (``None``), no filtering is applied. initialize (bool, optional): initialize the weights of the model. Default: ``True`` Attributes: ~.weights (torch.Tensor): the learnable parameters which are used to expand the kernel ~.filter (torch.Tensor): the convolutional kernel obtained by expanding the parameters in :attr:`~e2cnn.nn.R2Conv.weights` ~.bias (torch.Tensor): the learnable parameters which are used to expand the bias, if ``bias=True`` ~.expanded_bias (torch.Tensor): the equivariant bias which is summed to the output, obtained by expanding the parameters in :attr:`~e2cnn.nn.R2Conv.bias` \u0026#34;\u0026#34;\u0026#34; # 输入类型和输出类型必须是一个群 assert in_type.gspace == out_type.gspace assert isinstance(in_type.gspace, GeneralOnR2) # 初始化对应的内容 super(R2Conv, self).__init__() self.space = in_type.gspace self.in_type = in_type self.out_type = out_type self.kernel_size = kernel_size self.stride = stride self.dilation = dilation self.padding = padding self.padding_mode = padding_mode self.groups = groups # 检查是padding是否是元组 if isinstance(padding, tuple) and len(padding) == 2: _padding = padding # 检查padding是否是int，是int则直接将对应的内容直接进行赋值 elif isinstance(padding, int): _padding = (padding, padding) else: raise ValueError(\u0026#39;padding needs to be either an integer or a tuple containing two integers but {} found\u0026#39;.format(padding)) padding_modes = {\u0026#39;zeros\u0026#39;, \u0026#39;reflect\u0026#39;, \u0026#39;replicate\u0026#39;, \u0026#39;circular\u0026#39;} if padding_mode not in padding_modes: raise ValueError(\u0026#34;padding_mode must be one of [{}], but got padding_mode=\u0026#39;{}\u0026#39;\u0026#34;.format(padding_modes, padding_mode)) self._reversed_padding_repeated_twice = tuple(x for x in reversed(_padding) for _ in range(2)) # 检查输入和输出类可以分为“groups”组，所有组都彼此相等 # TODO: 搞懂这个变量的作用 if groups \u0026gt; 1: # Check the input and output classes can be split in `groups` groups, all equal to each other # first, check that the number of fields is divisible by `groups` assert len(in_type) % groups == 0 assert len(out_type) % groups == 0 in_size = len(in_type) // groups out_size = len(out_type) // groups # then, check that all groups are equal to each other, i.e. have the same types in the same order assert all(in_type.representations[i] == in_type.representations[i % in_size] for i in range(len(in_type))) assert all(out_type.representations[i] == out_type.representations[i % out_size] for i in range(len(out_type))) # finally, retrieve the type associated to a single group in input. # this type will be used to build a smaller kernel basis and a smaller filter # as in PyTorch, to build a filter for grouped convolution, we build a filter which maps from one input # group to all output groups. Then, PyTorch\u0026#39;s standard convolution routine interpret this filter as `groups` # different filters, each mapping an input group to an output group. in_type = in_type.index_select(list(range(in_size))) # 这段代码检查`bias`是否为真值。如果`bias`为镇，则执行以下步骤： if bias: # bias can be applied only to trivial irreps inside the representation # to apply bias to a field we learn a bias for each trivial irreps it contains # and, then, we transform it with the change of basis matrix to be able to apply it to the whole field # this is equivalent to transform the field to its irreps through the inverse change of basis, # sum the bias only to the trivial irrep and then map it back with the change of basis # count the number of trivial irreps # 计算具有平凡表示的数量 trivials = 0 # 遍历out_type中每个元素r # 对于 r 中的每个 irr（表示），检查 self.out_type.fibergroup.irreps[irr] 是否为“trivial”（平凡的）。 # 如果是，则将 trivials 加 1 for r in self.out_type: for irr in r.irreps: if self.out_type.fibergroup.irreps[irr].is_trivial(): trivials += 1 # if there is at least 1 trivial irrep # 如果至少有一个平凡表示 if trivials \u0026gt; 0: # matrix containing the columns of the change of basis which map from the trivial irreps to the # field representations. This matrix allows us to map the bias defined only over the trivial irreps # to a bias for the whole field more efficiently # 创建一个大小为 (self.out_type.size, trivials) 的零张量 bias_expansion，用于存储变换矩阵，该矩阵能够将平凡表示映射到字段表示中。 bias_expansion = torch.zeros(self.out_type.size, trivials) # 通过循环遍历 self.out_type 中的每个元素 r，并且对于 r 中的每个 irr： # 检查 self.out_type.fibergroup.irreps[irr] 是否为平凡表示。 # 如果是平凡表示，将 r.change_of_basis[:, pi] 赋值给 bias_expansion 的相应位置，并更新索引 c。 p, c = 0, 0 for r in self.out_type: pi = 0 for irr in r.irreps: irr = self.out_type.fibergroup.irreps[irr] if irr.is_trivial(): bias_expansion[p:p+r.size, c] = torch.tensor(r.change_of_basis[:, pi]) c += 1 pi += irr.size p += r.size # 注册属性 bias_expansion 为类的缓冲区（buffer）属性，表示此属性的值不需要进行梯度计算。 # 创建参数 self.bias，它是一个大小为 trivials 的张量，并将其设置为需要梯度计算。 # 注册属性 expanded_bias 为类的缓冲区（buffer）属性，表示此属性的值不需要进行梯度计算，并初始化为大小为 out_type.size 的零张量。 self.register_buffer(\u0026#34;bias_expansion\u0026#34;, bias_expansion) self.bias = Parameter(torch.zeros(trivials), requires_grad=True) self.register_buffer(\u0026#34;expanded_bias\u0026#34;, torch.zeros(out_type.size)) else: self.bias = None self.expanded_bias = None else: self.bias = None self.expanded_bias = None # compute the parameters of the basis grid, basis_filter, rings, sigma, maximum_frequency = compute_basis_params(kernel_size, frequencies_cutoff, rings, sigma, dilation, basis_filter) # BasisExpansion: submodule which takes care of building the filter self._basisexpansion = None # notice that `in_type` is used instead of `self.in_type` such that it works also when `groups \u0026gt; 1` if basisexpansion == \u0026#39;blocks\u0026#39;: # 这里是整个核心 self._basisexpansion = BlocksBasisExpansion(in_type, out_type, basis_generator=self.space.build_kernel_basis, points=grid, sigma=sigma, rings=rings, maximum_offset=maximum_offset, maximum_frequency=maximum_frequency, basis_filter=basis_filter, recompute=recompute) else: raise ValueError(\u0026#39;Basis Expansion algorithm \u0026#34;%s\u0026#34; not recognized\u0026#39; % basisexpansion) if self.basisexpansion.dimension() == 0: raise ValueError(\u0026#39;\u0026#39;\u0026#39; The basis for the steerable filter is empty! Tune the `frequencies_cutoff`, `kernel_size`, `rings`, `sigma` or `basis_filter` parameters to allow for a larger basis. \u0026#39;\u0026#39;\u0026#39;) self.weights = Parameter(torch.zeros(self.basisexpansion.dimension()), requires_grad=True) self.register_buffer(\u0026#34;filter\u0026#34;, torch.zeros(out_type.size, in_type.size, kernel_size, kernel_size)) if initialize: # by default, the weights are initialized with a generalized form of He\u0026#39;s weight initialization init.generalized_he_init(self.weights.data, self.basisexpansion) 这个函数不算短，咱们还是老规矩，一句一句看。\n对应的初始化咱们这就不看了，直接看对应代码我写的注释吧。\nif groups \u0026gt; 1：这里的group代表是输入通道到输出通道的阻塞连接数，在这里允许 深度卷积，使用时，输入和输出类型需要可分为groups组，并且彼此相等。\n然后，我们在这里默认是1，因此在这里，我们暂时不考虑对应的内容。这个 if分支暂时跳过。\nif bias: 这个分支在代码中解释的比较清楚 ，直接看对应的代码就好。\ngrid, basis_filter, rings, sigma, maximum_frequency = compute_basis_params(kernel_size,frequencies_cutoff,rings,sigma,dilation,basis_filter)：这个函数 的作用是计算basis的变量。然后看这个函数中的细节。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 def compute_basis_params(kernel_size: int, frequencies_cutoff: Union[float, Callable[[float], float]] = None, rings: List[float] = None, sigma: List[float] = None, dilation: int = 1, custom_basis_filter: Callable[[dict], bool] = None, ): # compute the coordinates of the centers of the cells in the grid where the filter is sampled # 计算对滤波器进行采样的网格中单元格中心的坐标 grid = get_grid_coords(kernel_size, dilation) # 计算滤波器的最大半径 max_radius = np.sqrt((grid **2).sum(0)).max() # max_radius = kernel_size // 2 # by default, the number of rings equals half of the filter size if rings is None: n_rings = math.ceil(kernel_size / 2) # if self.group.order() \u0026gt; 0: # # compute the number of edges of the polygon inscribed in the filter (which is a square) # # whose points stay inside the filter under the action of the group # # the number of edges is lcm(group\u0026#39;s order, 4) # n_edges = self.group.order() # while n_edges % 4 \u0026gt; 0: # n_edges *= 2 # # the largest ring we can sample has radius equal to the circumradius of the polygon described above # n_rings /= math.cos(math.pi/n_edges) # n_rings = s // 2 + 1 # torch.linspace(start, end, steps) 是一个 PyTorch 函数，它生成一个包含在指定范围内、包括起始值和结束值的均匀间隔的一维张量（Tensor），此处用于生成环的半径（rings）。 # start 是起始值，这里为0，表示张量中第一个元素的值。 # end 是结束值，即(kernel_size - 1) // 2，这个值是由卷积核大小减去1，然后整除2得到的。这个值决定了张量中最后一个元素的值。 # n_rings 是生成的张量中元素的数量，即生成的环数目。 # dilation 将整个生成的张量元素乘以 dilation。这个步骤将按照 dilation 的倍数来调整生成的环的半径值。 # rings = torch.linspace(1 - s % 2, s // 2, n_rings) rings = torch.linspace(0, (kernel_size - 1) // 2, n_rings) * dilation rings = rings.tolist() assert all([max_radius \u0026gt;= r \u0026gt;= 0 for r in rings]) if sigma is None: sigma = [0.6] * (len(rings) - 1) + [0.4] for i, r in enumerate(rings): if r == 0.: sigma[i] = 0.005 elif isinstance(sigma, float): sigma = [sigma] * len(rings) # TODO - use a string name for this setting if frequencies_cutoff is None: frequencies_cutoff = -1. if isinstance(frequencies_cutoff, float): if frequencies_cutoff == -3: frequencies_cutoff = _manual_fco3(kernel_size // 2) elif frequencies_cutoff == -2: frequencies_cutoff = _manual_fco2(kernel_size // 2) elif frequencies_cutoff == -1: frequencies_cutoff = _manual_fco1(kernel_size // 2) else: frequencies_cutoff = lambda r, fco=frequencies_cutoff: fco * r # check if the object is a callable function assert callable(frequencies_cutoff) maximum_frequency = int(max(frequencies_cutoff(r) for r in rings)) fco_filter = bandlimiting_filter(frequencies_cutoff) if custom_basis_filter is not None: basis_filter = lambda d, custom_basis_filter=custom_basis_filter, fco_filter=fco_filter: (custom_basis_filter(d) and fco_filter(d)) else: basis_filter = fco_filter return grid, basis_filter, rings, sigma, maximum_frequency 这个代码也是 一个稍微长点的代码，ok，咱们还是一行一行看。\ngrid = get_grid_coords(kernel_size, dilation)这个函数计算滤波器采样网格中单元中心的坐标，首先先看 这个函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def get_grid_coords(kernel_size: int, dilation: int = 1): # 这里面就是在那个电科大的硕士论文中写的东西，根据卷积核的大小与转换函数的得到对应的标志矩阵 actual_size = dilation * (kernel_size -1) + 1 origin = actual_size / 2 - 0.5 points = [] for y in range(kernel_size): y *= dilation for x in range(kernel_size): x *= dilation p = (x - origin, -y + origin) points.append(p) points = np.array(points) assert points.shape == (kernel_size ** 2, 2), points.shape return points.T 这个内容其实很清楚，就是根据卷积核的大小以及转换函数生成对应的转换矩阵。具体内容可以看电科大的硕士论文中对于这个过程的描述，这里截个图。\n然后我们看下面的代码：max_radius = np.sqrt((grid **2).sum(0)).max()计算对应滤波器的最大半径。\nif rings is None:n_rings = math.ceil(kernel_size / 2)这个的话如果rings这个变量不存在，则直接指定为卷积核大小的一半。\nrings = torch.linspace(0, (kernel_size - 1) // 2, n_rings) * dilation:Torch.linspace(start, end, steps) 是一个 PyTorch 函数，它生成一个包含在指定范围内、包括起始值和结束值的均匀间隔的一维张量（Tensor），此处用于生成环的半径（rings）。start 是起始值，这里为0，表示张量中第一个元素的值。end 是结束值，即(kernel_size - 1) // 2，这个值是由卷积核大小减去1，然后整除2得到的。这个值决定了张量中最后一个元素的值。n_rings 是生成的张量中元素的数量，即生成的环数目。dilation 将整个生成的张量元素乘以 dilation。这个步骤将按照 dilation 的倍数来调整生成的环的半径值。\nrings = rings.tolist()转换成对应的列表。\n这里的话其实就是设置一个变量，然后接着往下面看。\n1 2 3 4 5 if sigma is None: sigma = [0.6] * (len(rings) - 1) + [0.4] for i, r in enumerate(rings): if r == 0.: sigma[i] = 0.005 这里的话还是生成对应的sigma变量，根据上面 生成rings，指定其中sigma角度。\nok，再往下面很长，但是在本次运行中，有很多没有走到，所以这里直接看运行时使用的内容，剩下的等有时间再去看吧。\n1 2 3 maximum_frequency = int(max(frequencies_cutoff(r) for r in rings)) fco_filter = bandlimiting_filter(frequencies_cutoff) basis_filter = fco_filter 这个的就是取得rings中的最大值，然后进行返回。\n下面的函数用于根据给定的属性来决定是否保留基础元素，这个函数也不是很重要 ，由于时间有限，先不写，标记一个TODO。\nok，这个 函数阶数，然后接着向下看。\n1 2 3 4 5 6 7 8 9 10 11 12 13 self._basisexpansion = None # notice that `in_type` is used instead of `self.in_type` such that it works also when `groups \u0026gt; 1` if basisexpansion == \u0026#39;blocks\u0026#39;: # 这里是整个核心 self._basisexpansion = BlocksBasisExpansion(in_type, out_type, basis_generator=self.space.build_kernel_basis, points=grid, sigma=sigma, rings=rings, maximum_offset=maximum_offset, maximum_frequency=maximum_frequency, basis_filter=basis_filter, recompute=recompute) 在我们生成了对应 的内容之后，下面BlocksBasisExpansion就是整个函数的核心，整个函数的作用就是卷积核的设置。ok，下面看这个函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 class BlocksBasisExpansion(BasisExpansion): def __init__(self, in_type: FieldType, out_type: FieldType, basis_generator: Callable[[Representation, Representation], Basis], points: np.ndarray, basis_filter: Callable[[dict], bool] = None, recompute: bool = False, **kwargs ): r\u0026#34;\u0026#34;\u0026#34; With this algorithm, the expansion is done on the intertwiners of the fields\u0026#39; representations pairs in input and output. Args: in_type (FieldType): the input field type out_type (FieldType): the output field type basis_generator (callable): method that generates the analytical filter basis points (~numpy.ndarray): points where the analytical basis should be sampled basis_filter (callable, optional): filter for the basis elements. Should take a dictionary containing an element\u0026#39;s attributes and return whether to keep it or not. recompute (bool, optional): whether to recompute new bases or reuse, if possible, already built tensors. **kwargs: keyword arguments to be passed to ```basis_generator``` Attributes: S (int): number of points where the filters are sampled \u0026#34;\u0026#34;\u0026#34; assert in_type.gspace == out_type.gspace assert isinstance(in_type.gspace, GeneralOnR2) super(BlocksBasisExpansion, self).__init__() self._in_type = in_type self._out_type = out_type self._input_size = in_type.size self._output_size = out_type.size self.points = points # int: number of points where the filters are sampled self.S = self.points.shape[1] # we group the basis vectors by their input and output representations _block_expansion_modules = {} # iterate through all different pairs of input/output representationions # and, for each of them, build a basis for i_repr in in_type._unique_representations: for o_repr in out_type._unique_representations: reprs_names = (i_repr.name, o_repr.name) try: basis = basis_generator(i_repr, o_repr, **kwargs) block_expansion = block_basisexpansion(basis, points, basis_filter, recompute=recompute) _block_expansion_modules[reprs_names] = block_expansion # register the block expansion as a submodule self.add_module(f\u0026#34;block_expansion_{reprs_names}\u0026#34;, block_expansion) except EmptyBasisException: # print(f\u0026#34;Empty basis at {reprs_names}\u0026#34;) pass if len(_block_expansion_modules) == 0: print(\u0026#39;WARNING! The basis for the block expansion of the filter is empty!\u0026#39;) self._n_pairs = len(in_type._unique_representations) * len(out_type._unique_representations) # the list of all pairs of input/output representations which don\u0026#39;t have an empty basis self._representations_pairs = sorted(list(_block_expansion_modules.keys())) # retrieve for each representation in both input and output fields: # - the number of its occurrences, # - the indices where it occurs and # - whether its occurrences are contiguous or not self._in_count, _in_indices, _in_contiguous = _retrieve_indices(in_type) self._out_count, _out_indices, _out_contiguous = _retrieve_indices(out_type) # compute the attributes and an id for each basis element (and, so, of each parameter) # attributes, basis_ids = _compute_attrs_and_ids(in_type, out_type, _block_expansion_modules) basis_ids = _compute_attrs_and_ids(in_type, out_type, _block_expansion_modules) self._weights_ranges = {} last_weight_position = 0 self._ids_to_basis = {} self._basis_to_ids = [] self._contiguous = {} # iterate through the different group of blocks # i.e., through all input/output pairs for io_pair in self._representations_pairs: self._contiguous[io_pair] = _in_contiguous[io_pair[0]] and _out_contiguous[io_pair[1]] # build the indices tensors if self._contiguous[io_pair]: # in_indices = torch.LongTensor([ in_indices = [ _in_indices[io_pair[0]].min(), _in_indices[io_pair[0]].max() + 1, _in_indices[io_pair[0]].max() + 1 - _in_indices[io_pair[0]].min() ]# ) # out_indices = torch.LongTensor([ out_indices = [ _out_indices[io_pair[1]].min(), _out_indices[io_pair[1]].max() + 1, _out_indices[io_pair[1]].max() + 1 - _out_indices[io_pair[1]].min() ] #) setattr(self, \u0026#39;in_indices_{}\u0026#39;.format(io_pair), in_indices) setattr(self, \u0026#39;out_indices_{}\u0026#39;.format(io_pair), out_indices) else: out_indices, in_indices = torch.meshgrid([_out_indices[io_pair[1]], _in_indices[io_pair[0]]]) in_indices = in_indices.reshape(-1) out_indices = out_indices.reshape(-1) # register the indices tensors and the bases tensors as parameters of this module self.register_buffer(\u0026#39;in_indices_{}\u0026#39;.format(io_pair), in_indices) self.register_buffer(\u0026#39;out_indices_{}\u0026#39;.format(io_pair), out_indices) # count the actual number of parameters total_weights = len(basis_ids[io_pair]) for i, id in enumerate(basis_ids[io_pair]): self._ids_to_basis[id] = last_weight_position + i self._basis_to_ids += basis_ids[io_pair] # evaluate the indices in the global weights tensor to use for the basis belonging to this group self._weights_ranges[io_pair] = (last_weight_position, last_weight_position + total_weights) # increment the position counter last_weight_position += total_weights 这个也是一个长函数，首先也是初始化变量，然后直接看这个算法中对应的核心：\n1 2 3 4 5 6 7 8 for i_repr in in_type._unique_representations: for o_repr in out_type._unique_representations: reprs_names = (i_repr.name, o_repr.name) try: basis = basis_generator(i_repr, o_repr, **kwargs) block_expansion = block_basisexpansion(basis, points, basis_filter, recompute=recompute) _block_expansion_modules[reprs_names] = block_expansion 看这段代码的时候，直接看里面的函数吧。block_basisexpansion这个函数是本文需要重点讲解的内容。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def block_basisexpansion(basis: Basis, points: np.ndarray, basis_filter: Callable[[dict], bool] = None, recompute: bool = False ) -\u0026gt; SingleBlockBasisExpansion: r\u0026#34;\u0026#34;\u0026#34; Return an instance of :class:`~e2cnn.nn.modules.r2_conv.SingleBlockBasisExpansion`. This function support caching through the argument ``recompute``. Args: basis (Basis): basis defining the space of kernels points (~np.ndarray): points where the analytical basis should be sampled basis_filter (callable, optional): filter for the basis elements. Should take a dictionary containing an element\u0026#39;s attributes and return whether to keep it or not. recompute (bool, optional): whether to recompute new bases (``True``) or reuse, if possible, already built tensors (``False``, default). \u0026#34;\u0026#34;\u0026#34; if not recompute: # compute the mask of the sampled basis containing only the elements allowed by the filter mask = np.zeros(len(basis), dtype=bool) for b, attr in enumerate(basis): mask[b] = basis_filter(attr) key = (basis, mask.tobytes(), points.tobytes()) if key not in _stored_filters: _stored_filters[key] = SingleBlockBasisExpansion(basis, points, basis_filter) return _stored_filters[key] else: return SingleBlockBasisExpansion(basis, points, basis_filter) 咱们前面已经计算得到对应的point等内容，这些内容都传过来，由于recompute的值时False，这个时候走的是else分支，使用 的SingleBlockBasisExpansion函数。\n1 2 3 class SingleBlockBasisExpansion(BasisExpansion): 这个函数是对给定基础的一部分进行采样，并进行一系列处理（过滤、归一化等），以便在模型中使用。basis 是一个代表分析基函数的对象。\npoints 是基函数应该被采样的点。 basis_filter 是一个可选的回调函数，用于过滤基函数元素。它接受一个包含元素属性的字典，并返回是否保留该元素。 在初始化过程中，首先调用父类 BasisExpansion 的构造函数。 接下来，基于 basis_filter 过滤基函数，并提取属性信息。如果过滤后的基函数为空，则引发 EmptyBasisException 异常。 计算基函数元素的实际输出大小，以便执行归一化操作。 在网格上对基函数进行采样，并过滤掉被过滤器丢弃的基函数元素。 使用 torch.Tensor 创建基函数张量，并对其进行一些处理和归一化操作。 丢弃几乎全为零的基函数元素。 将最终的掩码（mask）存储为类的私有属性 _mask。 将符合条件的属性信息和采样后的基函数张量作为模块参数进行注册。 上面的函数在经过操作之后，会存储对应的变量，这个时候里面存储的变量如下：\n上述操作的内容都会存储下来，然后存储到对应的位置 。如果说 有哪个变量不知道 什么含义的，请看上文的解释，解释的比较清楚。\nok，现在我们设置完了所有变量 ，出了对应的 循环，即block_expansion已经设置完成了，接着看下面的内容。\n1 self._n_pairs = len(in_type._unique_representations) * len(out_type._unique_representations) 设置_n_pairs，这个的话就是将里面的输入类型的长度以及初始类型的长度进行相乘，得到对应的_n_pairs长度。\n1 self._in_count, _in_indices, _in_contiguous = _retrieve_indices(in_type) 然后看retreve_indices这个函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def _retrieve_indices(type: FieldType): fiber_position = 0 _indices = defaultdict(list) _count = defaultdict(int) _contiguous = {} for repr in type.representations: _indices[repr.name] += list(range(fiber_position, fiber_position + repr.size)) fiber_position += repr.size _count[repr.name] += 1 for name, indices in _indices.items(): # _contiguous[o_name] = indices == list(range(indices[0], indices[0]+len(indices))) _contiguous[name] = utils.check_consecutive_numbers(indices) _indices[name] = torch.LongTensor(indices) return _count, _indices, _contiguous 看这个函数 ，这个函数的作用就是根据字段类型，生成一个字典 _indices，其中包含了不同表示（representation）的索引列表，并检查这些索引列表是否是连续的。这些表示通常代表了某种类型的向量或数据集合在某个高维空间中的表示。\nfiber_position 被初始化为 0，用于追踪索引的位置。\n创建了 _indices 字典，用于存储不同表示的索引列表。\n创建了 _count 字典，用于统计每个表示的出现次数。\n创建了一个空字典 _contiguous，用于存储每个表示的索引列表是否是连续的。\n对于给定的 type.representations 中的每个表示（repr）：\n将表示的名称作为键，将该表示的索引范围（从 fiber_position 到 fiber_position + repr.size）添加到 _indices 中。\n将 fiber_position 更新为下一个表示的起始位置。\n增加该表示的计数器 _count。\n对于 _indices中的每个表示名称和对应的索引列表：\n使用 utils.check_consecutive_numbers 函数检查索引列表是否连续，并将结果存储在 _contiguous 中。\n将索引列表转换为 torch.LongTensor 类型，并将其重新赋值给 _indices。\n返回包含 _count（表示计数）、_indices（表示的索引列表）和 _contiguous（表示索引是否连续的字典）的元组。\n在处理完了这些变量之后，对应内容 就是 ：\n在了解 这些变量之后，看下面一句：\n1 self._out_count, _out_indices, _out_contiguous = _retrieve_indices(out_type) 这一句的作用和上面一句的作用相同 ，这里不再进行详细赘述。\nok，接着往下看\n1 basis_ids = _compute_attrs_and_ids(in_type, out_type, _block_expansion_modules) 这个函数的作用是计算每个基本元素的属性和 id。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def _compute_attrs_and_ids(in_type, out_type, block_submodules): basis_ids = defaultdict(lambda: []) # iterate over all blocks # each block is associated to an input/output representations pair out_fiber_position = 0 out_irreps_count = 0 for o, o_repr in enumerate(out_type.representations): in_fiber_position = 0 in_irreps_count = 0 for i, i_repr in enumerate(in_type.representations): reprs_names = (i_repr.name, o_repr.name) # if a basis for the space of kernels between the current pair of representations exists if reprs_names in block_submodules: # retrieve the attributes of each basis element and build a new list of # attributes adding information specific to the current block ids = [] for attr in block_submodules[reprs_names].get_basis_info(): # build the ids of the basis vectors # add names and indices of the input and output fields id = \u0026#39;({}-{},{}-{})\u0026#39;.format(i_repr.name, i, o_repr.name, o) # add the original id in the block submodule id += \u0026#34;_\u0026#34; + attr[\u0026#34;id\u0026#34;] ids.append(id) # append the ids of the basis vectors basis_ids[reprs_names] += ids in_fiber_position += i_repr.size in_irreps_count += len(i_repr.irreps) out_fiber_position += o_repr.size out_irreps_count += len(o_repr.irreps) # return attributes, basis_ids return basis_ids 首先 创建一个默认值为列表的defaultdict队形，用于存储基础ids。 然后迭代输出类型的表示。 接着初始化输出表示的起始位置 和不可约的计数。 然后迭代输入类型的表示。 接着如果当前表示对存在于block_submodules中。 然后获取当前白哦是对应的模块的基础信息。 构建基础向量的标识符 将基础向量的标识符添加到对应表示对的 basis_ids 列表中 更新输入表示的位置和不可约表示的计数 更新输出表示的位置和不可约表示的计数 返回基础 ids 这个函数的主要流程是对输入和输出类型的表示进行迭代，检查对应的表示对是否存在于 block_submodules 中，如果存在，则根据模块的基础信息构建基础向量的标识符，并将其存储在 basis_ids 中。最后返回这些基础 ids。\n然后看完了这个函数 ，发现这个 函数其实并不是重点，里面不过是将一些变量进行初始化，真正的重点还在下面。\n然后接着往下走，发现走到下面几句：\n1 2 3 4 5 self.weights = Parameter(torch.zeros(self.basisexpansion.dimension()), requires_grad=True) self.register_buffer(\u0026#34;filter\u0026#34;, torch.zeros(out_type.size, in_type.size, kernel_size, kernel_size)) if initialize: # by default, the weights are initialized with a generalized form of He\u0026#39;s weight initialization init.generalized_he_init(self.weights.data, self.basisexpansion) 这里的其那两句相当于将里面的数据进行放入，暂时先不管对应的内容。然后看初始化，也就是看generalized_he_init这个函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def generalized_he_init(tensor: torch.Tensor, basisexpansion: BasisExpansion, cache: bool = False): r\u0026#34;\u0026#34;\u0026#34; 可算是找到了重点... Initialize the weights of a convolutional layer with a generalized He\u0026#39;s weight initialization method. Because the computation of the variances can be expensive, to save time on consecutive runs of the same model, it is possible to cache the tensor containing the variance of each weight, for a specific ```basisexpansion```. This can be useful if a network contains multiple convolution layers of the same kind (same input and output types, same kernel size, etc.) or if one needs to train the same network from scratch multiple times (e.g. to perform hyper-parameter search over learning rate or to repeat an experiment with different random seeds). .. note :: The variance tensor is cached in memory and therefore is only available to the current process. Args: tensor (torch.Tensor): the tensor containing the weights basisexpansion (BasisExpansion): the basis expansion method cache (bool, optional): cache the variance tensor. By default, ```cache=False``` \u0026#34;\u0026#34;\u0026#34; # Initialization assert tensor.shape == (basisexpansion.dimension(),) if cache and basisexpansion not in cached_he_vars: cached_he_vars[basisexpansion] = _generalized_he_init_variances(basisexpansion) if cache: vars = cached_he_vars[basisexpansion] else: vars = _generalized_he_init_variances(basisexpansion) tensor[:] = vars * torch.randn_like(tensor) 这个函数的作用是使用广义he权重初始化卷积层的权重，这个函数首先先判断输入的数据是否符合条件，如果不符合，则直接进行返回，然后判断是否存在对应的缓存，有的话，直接使用上次已经初始化好的变量进行初始化，没有的话，调用对应的_generalized_he_init_variances函数进行初始化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def _generalized_he_init_variances(basisexpansion: BasisExpansion): r\u0026#34;\u0026#34;\u0026#34; 使用广义 He 权重初始化方法计算卷积层权重的方差。 Compute the variances of the weights of a convolutional layer with a generalized He\u0026#39;s weight initialization method. Args: basisexpansion (BasisExpansion): the basis expansion method \u0026#34;\u0026#34;\u0026#34; vars = torch.ones((basisexpansion.dimension(),)) inputs_count = defaultdict(lambda: set()) basis_count = defaultdict(int) basis_info = list(basisexpansion.get_basis_info()) for attr in basis_info: i, o = attr[\u0026#34;in_irreps_position\u0026#34;], attr[\u0026#34;out_irreps_position\u0026#34;] in_irrep, out_irrep = attr[\u0026#34;in_irrep\u0026#34;], attr[\u0026#34;out_irrep\u0026#34;] inputs_count[o].add(in_irrep) basis_count[(in_irrep, o)] += 1 for o in inputs_count.keys(): inputs_count[o] = len(inputs_count[o]) for w, attr in enumerate(basis_info): i, o = attr[\u0026#34;in_irreps_position\u0026#34;], attr[\u0026#34;out_irreps_position\u0026#34;] in_irrep, out_irrep = attr[\u0026#34;in_irrep\u0026#34;], attr[\u0026#34;out_irrep\u0026#34;] vars[w] = 1. / math.sqrt(inputs_count[o] * basis_count[(in_irrep, o)]) return vars 这个函数使用广义he权重初始化方法 计算卷积层权重的方差，然后我们仍然是一行一行的看这个代码。\n首先的话仍然是拿到对应的变量 ，将对应的变量进行初始化。\n这里将每个初始化的变量截图：\n一个即兴提问：为什么都是960个维度，这个是怎么得出来的，这里标记一个TODO。\n然后接着往下面看，看到第一个循环：\n1 2 3 4 5 for attr in basis_info: i, o = attr[\u0026#34;in_irreps_position\u0026#34;], attr[\u0026#34;out_irreps_position\u0026#34;] in_irrep, out_irrep = attr[\u0026#34;in_irrep\u0026#34;], attr[\u0026#34;out_irrep\u0026#34;] inputs_count[o].add(in_irrep) basis_count[(in_irrep, o)] += 1 attr 在每次循环中代表 basis_info 列表中的一个元素（或者是一个字典）。\ni 和 o 分别用于存储 attr 字典中的键 \u0026quot;in_irreps_position\u0026quot; 和 \u0026quot;out_irreps_position\u0026quot; 对应的值。\nin_irrep 和 out_irrep 存储了 attr 字典中键为 \u0026quot;in_irrep\u0026quot; 和 \u0026quot;out_irrep\u0026quot; 的对应值。\ninputs_count[o].add(in_irrep)这行代码在创建一个数据结构（可能是字典或集合），其中 o 是键，inputs_count[o] 可能是一个集合，代码尝试将 in_irrep 的值添加到该集合中。\nbasis_count[(in_irrep, o)] += 1这行代码在一个名为 basis_count 的字典中记录某些键的计数。它使用了一个元组 (in_irrep, o) 作为键，并且将该键对应的值（假设是一个整数）增加了 1。\n按照我的 理解，这里面是对其中变量进行了复制，统计其中basis的个数，共下面使用。\n1 2 for o in inputs_count.keys(): inputs_count[o] = len(inputs_count[o]) 这句话的意思是统计其中输入的 不可约表示的总数。\n然后下面就是对应的卷积计算：\n1 2 3 4 for w, attr in enumerate(basis_info): i, o = attr[\u0026#34;in_irreps_position\u0026#34;], attr[\u0026#34;out_irreps_position\u0026#34;] in_irrep, out_irrep = attr[\u0026#34;in_irrep\u0026#34;], attr[\u0026#34;out_irrep\u0026#34;] vars[w] = 1. / math.sqrt(inputs_count[o] * basis_count[(in_irrep, o)]) 这里面在进行对应位置 的方差，使用遍历的方式遍历basis_info中的每个基，并且获取其属性信息，对于每个基，利用输入不可约表示的 数量和输入到输出不可约表示的数量，计算权重方差，并将其存储在vars中。\n总体而言，这个函数通过基扩展方法 basisexpansion 来计算卷积层权重初始化时的方差。它首先统计输入和基的信息，然后根据这些信息计算每个基对应的权重方差，并将结果作为张量返回。\n在计算出来对应的方差之后，将其中的 值进行返回，对应的广义he就初始化完成。整个函数就完成。\n看到了 这里，我最大的疑问出来了，核的定义到底是什么，为什么这里计算出对应的方差，就算是将核初始化完成了？\n关于卷积神经网络的核，这里的话还是在单独写一篇文章，普及其中的概念吧。\n","date":"2023-12-04T18:47:52+08:00","permalink":"https://runqizhao.cn/p/e2cnn-%E5%86%85%E5%AE%B9%E7%90%86%E8%A7%A3-r2conv-%E8%AF%A6%E8%A7%A3/","title":"e2cnn 内容理解-R2Conv 详解"},{"content":"在有了上面的群的创建，输入类型的创建，下面看看输出类型的创建。\n输出类型的创建其实 与输入类型的创建有很多相似之处。\n首先看看对应输出类型的创建语句：\n1 self._make_stem_layer(in_channels, stem_channels) 然后进到这个函数\n1 2 3 4 5 6 7 8 9 10 11 def _make_stem_layer(self, in_channels, stem_channels): \u0026#34;\u0026#34;\u0026#34;Build stem layer.\u0026#34;\u0026#34;\u0026#34; if not self.deep_stem: self.conv1 = ennTrivialConv( in_channels, stem_channels, kernel_size=7, stride=2, padding=3) self.norm1_name, norm1 = build_enn_norm_layer( stem_channels, postfix=1) self.add_module(self.norm1_name, norm1) self.relu = ennReLU(stem_channels) self.maxpool = ennMaxPool( stem_channels, kernel_size=3, stride=2, padding=1) 然后对进到ennTrivialConv这个函数里面\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def ennTrivialConv(inplanes, outplanes, kernel_size=3, stride=1, padding=0, groups=1, bias=False, dilation=1): \u0026#34;\u0026#34;\u0026#34;enn convolution with trivial input feature. Args: in_channels (List[int]): Number of input channels per scale. out_channels (int): Number of output channels (used at each scale). kernel_size (int, optional): The size of kernel. stride (int, optional): Stride of the convolution. Default: 1. padding (int or tuple): Zero-padding added to both sides of the input. Default: 0. groups (int): Number of blocked connections from input. channels to output channels. Default: 1. bias (bool): If True, adds a learnable bias to the output. Default: False. dilation (int or tuple): Spacing between kernel elements. Default: 1. \u0026#34;\u0026#34;\u0026#34; in_type = build_enn_trivial_feature(inplanes) out_type = build_enn_divide_feature(outplanes) return enn.R2Conv( in_type, out_type, kernel_size, stride=stride, padding=padding, groups=groups, bias=bias, dilation=dilation, sigma=None, frequencies_cutoff=lambda r: 3 * r, ) 里面创建了对应的输入类型和输出类型，输入类型和上一节中是一样的，这里的话不再进行详细的讲解，输出类型是本节的重点，将会进行重点讲解。\n下面我们来看对应的输出类型的函数。\n1 2 3 4 5 6 7 8 def build_enn_divide_feature(planes): \u0026#34;\u0026#34;\u0026#34;build a enn regular feature map with the specified number of channels divided by N.\u0026#34;\u0026#34;\u0026#34; assert gspace.fibergroup.order() \u0026gt; 0 N = gspace.fibergroup.order() planes = planes / N planes = int(planes) return enn.FieldType(gspace, [gspace.regular_repr] * planes) 上面这一段是重新设对应的planes的 大小，这里为什么要处理对应的总数？这里其实不是很明白，标记一个TODO。\n然后我们在进去对应FiledType之前，我们系要使用对应regular_repr函数，这里的话就是我们在创建群是创建的平凡表示（碎碎念：其实平凡表示我搞得也不是很懂，但是这个内容是群中的一个概念，这个系列对于一个没有学习过群论的人来说确实有点难度，这里的话还是先放在这里吧）。\n然后我们拿到这个变量，对应的内容如下：\n这里面的东西就是我们在初始化群已经初始化好的内容。\n在我们经过输出类型的设置之后，对应的内容是什么？\n这里的话我们输入的是64，在讲过相除之后，输入FieldType里面的planes是8，这个时候我们还是上一讲中讲的直积操作，将里面的内容直接 进行拼接，然后返回，对应的输出如下：\n这个时候对应的就是矩阵拼接，然后这里咱们主要看一下对应的fileds_star与fileds_end，这两个内容跟上一讲中内容还是有点差别的，这是因为上一讲中我们是以1为间隔单位进行的设置，这里的话是以8为间隔单位进行设置。\n上述内容设置完，相当于对应的输出类型已经创建完成，下一讲将会讲述本文的核心内容，也就是对应的R2Conv。\n","date":"2023-12-04T17:01:17+08:00","permalink":"https://runqizhao.cn/p/e2cnn-%E5%86%85%E5%AE%B9%E7%90%86%E8%A7%A3-%E7%BE%A4%E7%9A%84%E8%BE%93%E5%87%BA%E7%B1%BB%E5%9E%8B/","title":"e2cnn 内容理解 - 群的输出类型"},{"content":"上一个内容之中，我们已经解释了 对应e2cnn的创建，现在我们解释对应的输入类型的创建。\n首先我们要知道，我们现在已经创建了一个循环群，创建完成循环群之后里面已经有对应的平凡表示，这些内容都有了之后，下面会使用 上一讲中已经创建的内容，构建群的如数类型$\\rho_{in}$。\n本文使用的是ReDet的ReResNet进行说明，因此，里面会出现对应的内容 。\n首先，在我们创建完成对应的循环群 之后，会使用下面代码创建对应的输入类型 ：\n1 2 3 4 5 6 self.in_type = build_enn_trivial_feature(3) def build_enn_trivial_feature(planes): \u0026#34;\u0026#34;\u0026#34;build a enn trivial feature map with the specified number of channels.\u0026#34;\u0026#34;\u0026#34; return enn.FieldType(gspace, planes * [gspace.trivial_repr]) gspace是我们上一讲中创建的类型，trivial_repr是对应“琐碎表示”，这个的话可以看论文之中的解释，在这里我们依然使用的是上面对应已经创建好的循环群中的第一个元素，这里是有理论支撑的，但是里面的内容确实不简单，先按下不表。\n然后接下来将会使用FieldType，可以说，这个是本文的重头戏，这个理解好了，输入类型就理解好了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 class FieldType: def __init__(self, gspace: GSpace, representations: List[Representation]): r\u0026#34;\u0026#34;\u0026#34; An ``FieldType`` can be interpreted as the *data type* of a feature space. It describes: - the base space on which a feature field is living and its symmetries considered - the transformation law of feature fields under the action of the fiber group The former is formalize by a choice of ``gspace`` while the latter is determined by a choice of group representations (``representations``), passed as a list of :class:`~e2cnn.group.Representation` instances. Each single representation in this list corresponds to one independent feature field contained in the feature space. The input ``representations`` need to belong to ``gspace``\u0026#39;s fiber group (:attr:`e2cnn.gspaces.GSpace.fibergroup`). .. note :: Mathematically, this class describes a *(trivial) vector bundle*, *associated* to the symmetry group :math:`(\\R^D, +) \\rtimes G`. Given a *principal bundle* :math:`\\pi: (\\R^D, +) \\rtimes G \\to \\R^D, tg \\mapsto tG` with fiber group :math:`G`, an *associated vector bundle* has the same base space :math:`\\R^D` but its fibers are vector spaces like :math:`\\mathbb{R}^c`. Moreover, these vector spaces are associated to a :math:`c`-dimensional representation :math:`\\rho` of the fiber group :math:`G` and transform accordingly. The representation :math:`\\rho` is defined as the *direct sum* of the representations :math:`\\{\\rho_i\\}_i` in ``representations``. See also :func:`~e2cnn.group.directsum`. Args: gspace (GSpace): the space where the feature fields live and its symmetries representations (list): a list of :class:`~e2cnn.group.Representation` s of the ``gspace``\u0026#39;s fiber group, determining the transformation laws of the feature fields Attributes: ~.gspace (GSpace) ~.representations (list) ~.size (int): dimensionality of the feature space described by the :class:`~e2cnn.nn.FieldType`. It corresponds to the sum of the dimensionalities of the individual feature fields or group representations (:attr:`e2cnn.group.Representation.size`). \u0026#34;\u0026#34;\u0026#34; assert len(representations) \u0026gt; 0 for repr in representations: assert repr.group == gspace.fibergroup # GSpace: Space where data lives and its (abstract) symmetries self.gspace = gspace # list: List of representations of each feature field composing the feature space of this type self.representations = representations # int: size of the field associated to this type. # as the representation associated to the field is the direct sum of the representations # in :attr:`e2cnn.nn.fieldtype.representations`, its size is the sum of each of these # representations\u0026#39; size self.size = sum([repr.size for repr in representations]) self._unique_representations = set(self.representations) self._representation = None self._field_start = None self._field_end = None self._hash = hash(self.gspace.name + \u0026#39;: {\u0026#39; + \u0026#39;, \u0026#39;.join([r.name for r in self.representations]) + \u0026#39;}\u0026#39;) 一个 ``FieldType` 可以解释为一个特征空间的数据类型。它描述\n特征域所处的基础空间及其对称性\n特征场在纤维群作用下的变换规律\n前者是通过选择 \u0026ldquo;特征空间 \u0026ldquo;来形式化的，而后者则是由选择群来决定的 表征（representations），以 :class:~e2cnn.group.Representation 实例列表的形式传递。 该列表中的每个表示法都对应于特征空间中的一个独立特征字段空间。\n上面是作者给的 解释，其实看的还是云里雾里。\n还是老规矩，一行一行代码查看，首先的话还是先进性初始化。\n初始化完成之后，下面这一步进行哈希操作：\n1 self._hash = hash(self.gspace.name + \u0026#39;: {\u0026#39; + \u0026#39;, \u0026#39;.join([r.name for r in self.representations]) + \u0026#39;}\u0026#39;) 通过将 gspace.name 和 representations 中每个表示的名称连接起来，并计算哈希值来表示 FieldType 的唯一性。\n这里第一个坑点来了，从程序上面来看，我们初始化完成之后，输入类型就已经创建结束，但是我们看论文中的解释：\n这里的话论文中是这么说的：在第 5 行，我们定义了输入 $\\rho_{in}$ 的字段类型，指定它包含 3 个标量字段，由平凡表示$\\psi $ 描述（例如 RGB 图像，另见第 3.2 节）。\n然后我们卡一下官网的解释，在官网中进行解释的时候，使用对应一个例子解释，可以直接看对应的连接。\n结合这个例子可以看到，在官网中，依旧是进行直积操作，因此，说到底，这个输入类型的创建就将你设置的通道进行直积操作 ，就是将对应内容拼接在一起，为了验证这个想法，我们下面看一个例子。\n现在假设我们输入的是一个图像，输入的是3通道 ，现在调用下面的语句：\n1 self.in_type = build_enn_trivial_feature(3) 在这一条调用 完成之后，相当于我们现在设置的输入通道是3通道（一个RGB图像）。现在我们看函数里面的具体内容：\n1 2 3 4 def build_enn_trivial_feature(planes): \u0026#34;\u0026#34;\u0026#34;build a enn trivial feature map with the specified number of channels.\u0026#34;\u0026#34;\u0026#34; return enn.FieldType(gspace, planes * [gspace.trivial_repr]) 通过函数里面的具体内容可知，在进行创建的时候，使用到了我们上篇文章创建的gspace，但是在上一篇中，我们在进行创建的时候没有使用trival_rper函数，因此，则会里面我们跳到对应的函数中，查看这个函数对应的变量。\n1 2 3 4 5 6 7 8 9 10 11 @property def trivial_repr(self) -\u0026gt; e2cnn.group.Representation: r\u0026#34;\u0026#34;\u0026#34; The trivial representation of the fiber group of this space. .. seealso:: :attr:`e2cnn.group.Group.trivial_representation` \u0026#34;\u0026#34;\u0026#34; return self.fibergroup.trivial_representation 然后我们看了这里面对应的内容，根据上面注释的解释，这里是该空间纤维群的平凡表示，然后为了彻底搞懂这个内容，跳到这个函数里面查看里面的内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 @property @abstractmethod def trivial_representation(self) -\u0026gt; e2cnn.group.IrreducibleRepresentation: r\u0026#34;\u0026#34;\u0026#34; Builds the trivial representation of the group. The trivial representation is a 1-dimensional representation which maps any element to 1, i.e. :math:`\\forall g \\in G,\\ \\rho(g) = 1`. Returns: the trivial representation of the group \u0026#34;\u0026#34;\u0026#34; pass 在这个函数里面，我们构建群的平凡表示，这个平凡 表示是一种以为表示，可以将任何元素映射为1，例如 $$ \\forall g \\in G,\\ \\rho(g) = 1 $$ 总结一下上面函数，相当于我们创建了群中的元素都是1，然后再创建完成之后，直接与其中的通道相乘，设置成对应的输入类型。因此，在这个里面 ，应该是3个相同的变量 。\n从这里面可以看出，不过是将对应1映射到对应的维度上面，然后将里面每个内容都复制对应的三份，然后直接更新对应的representation与representations，然后直接进行返回，然后这里用出现了新东西，里面的fields_star与fileds_end没有出现，这里的话我们还是通过源码进行调试，找到生成对应值的函数。\n但是单点调试了很久，都没有跳到对应的程序里面，这里是不是出现了问题？\nTODO：这里是一个 带及觉得 点。\nok，先不纠结这个问题，然后我们直接将里面的内容进行 对应的直积操作，在进行的时候，我们刚开始使用的是$1 \\times 1$大小的核心，因此这里的直积是将里面的内容进行拼接，然后进行返回。\n这里说一下直积的公式： $$ \\rho_{in} = irrpe_0 \\oplus irrpe_0 \\oplus irrpe_0 =\\left[\\begin{array}{ccc} irrpe_0 \u0026amp; 0 \u0026amp; 0 \\ 0 \u0026amp; irrpe_0 \u0026amp; 0 \\ 0 \u0026amp; 0 \u0026amp; irrpe_0 \\end{array}\\right] $$\n因此，上面的内容就是将里面的内容进行拼接。从数据返回来看，也是将里面内容进行拼接。\n但是里面的代码确实没有找到 ，我现在直接跳转到对应直积和函数，然后向上找到其中对应的断点。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def directsum(reprs: List[e2cnn.group.Representation], change_of_basis: np.ndarray = None, name: str = None ) -\u0026gt; e2cnn.group.Representation: r\u0026#34;\u0026#34;\u0026#34; Compute the *direct sum* of a list of representations of a group. The direct sum of two representations is defined as follow: .. math:: \\rho_1(g) \\oplus \\rho_2(g) = \\begin{bmatrix} \\rho_1(g) \u0026amp; 0 \\\\ 0 \u0026amp; \\rho_2(g) \\end{bmatrix} This can be generalized to multiple representations as: .. math:: \\bigoplus_{i=1}^I \\rho_i(g) = (\\rho_1(g) \\oplus (\\rho_2(g) \\oplus (\\rho_3(g) \\oplus \\dots = \\begin{bmatrix} \\rho_1(g) \u0026amp; 0 \u0026amp; \\dots \u0026amp; 0 \\\\ 0 \u0026amp; \\rho_2(g) \u0026amp; \\dots \u0026amp; \\vdots \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; 0 \\\\ 0 \u0026amp; \\dots \u0026amp; 0 \u0026amp; \\rho_I(g) \\\\ \\end{bmatrix} .. note:: All the input representations need to belong to the same group. Args: reprs (list): the list of representations to sum. change_of_basis (~numpy.ndarray, optional): an invertible square matrix to use as change of basis after computing the direct sum. By default (``None``), an identity matrix is used, such that only the direct sum is evaluated. name (str, optional): a name for the new representation. Returns: the direct sum \u0026#34;\u0026#34;\u0026#34; group = reprs[0].group for r in reprs: assert group == r.group if name is None: name = \u0026#34;_\u0026#34;.join([f\u0026#34;[{r.name}]\u0026#34; for r in reprs]) irreps = [] for r in reprs: irreps += r.irreps size = sum([r.size for r in reprs]) cob = np.zeros((size, size)) cob_inv = np.zeros((size, size)) p = 0 for r in reprs: cob[p:p + r.size, p:p + r.size] = r.change_of_basis cob_inv[p:p + r.size, p:p + r.size] = r.change_of_basis_inv p += r.size if change_of_basis is not None: change_of_basis = change_of_basis @ cob change_of_basis_inv = sp.linalg.inv(change_of_basis) else: change_of_basis = cob change_of_basis_inv = cob_inv supported_nonlinearities = set.intersection(*[r.supported_nonlinearities for r in reprs]) return Representation(group, name, irreps, change_of_basis, supported_nonlinearities, change_of_basis_inv=change_of_basis_inv) 从程序上面来看，就是将里面的内容进行拼接，然后返回对应的值。\n# 总结 输入的 内容就是将里面的内容直接进行拼接操作，然后进行返回。\n","date":"2023-12-03T20:56:54+08:00","permalink":"https://runqizhao.cn/p/e2cnn%E5%86%85%E5%AE%B9%E7%90%86%E8%A7%A3-%E7%BE%A4%E7%9A%84%E8%BE%93%E5%85%A5%E7%B1%BB%E5%9E%8B/","title":"e2cnn内容理解-群的输入类型"},{"content":" # 创建 循环群 这里的话考虑的是简单情况，使用对应的循环群。对应的方法如下：\n1 2 N = 8 gspace = gspaces.Rot2dOnR2(N=N) 然后看这个函数里面的东西：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def __init__(self, N: int = None, maximum_frequency: int = None, fibergroup: Group = None): r\u0026#34;\u0026#34;\u0026#34; Describes rotation symmetries of the plane :math:`\\R^2`. If ``N \u0026gt; 1``, the class models *discrete* rotations by angles which are multiple of :math:`\\frac{2\\pi}{N}` (:class:`~e2cnn.group.CyclicGroup`). Otherwise, if ``N=-1``, the class models *continuous* planar rotations (:class:`~e2cnn.group.SO2`). In that case the parameter ``maximum_frequency`` is required to specify the maximum frequency of the irreps of :class:`~e2cnn.group.SO2` (see its documentation for more details) Args: N (int): number of discrete rotations (integer greater than 1) or ``-1`` for continuous rotations maximum_frequency (int): maximum frequency of :class:`~e2cnn.group.SO2`\u0026#39;s irreps if ``N = -1`` fibergroup (Group, optional): use an already existing instance of the symmetry group. In that case, the other parameters should not be provided. \u0026#34;\u0026#34;\u0026#34; assert N is not None or fibergroup is not None, \u0026#34;Error! Either use the parameter `N` or the parameter `group`!\u0026#34; if fibergroup is not None: assert isinstance(fibergroup, CyclicGroup) or isinstance(fibergroup, SO2) assert maximum_frequency is None, \u0026#34;Maximum Frequency can\u0026#39;t be set when the group is already provided in input\u0026#34; N = fibergroup.order() assert isinstance(N, int) if N \u0026gt; 1: assert maximum_frequency is None, \u0026#34;Maximum Frequency can\u0026#39;t be set for finite cyclic groups\u0026#34; name = \u0026#39;{}-Rotations\u0026#39;.format(N) elif N == -1: name = \u0026#39;Continuous-Rotations\u0026#39; else: raise ValueError(f\u0026#39;Error! \u0026#34;N\u0026#34; has to be an integer greater than 1 or -1, but got {N}\u0026#39;) if fibergroup is None: if N \u0026gt; 1: fibergroup = cyclic_group(N) elif N == -1: fibergroup = so2_group(maximum_frequency) super(Rot2dOnR2, self).__init__(fibergroup, name) 这个注释里面描述的是：描述平面$R^2$的旋转对称性。然后，咱们一句一句看：\n1 assert N is not None or fibergroup is not None, \u0026#34;Error! Either use the parameter `N` or the parameter `group`!\u0026#34; 这段代码要求在使用这段代码所在的函数或程序时，要么提供变量 N 的值，要么提供变量 fibergroup 的值。如果两者都没有提供一个非空的值，就会触发断言错误，以防止程序进一步执行下去。\n接着看下面这段话：\n1 2 3 4 5 6 if fibergroup is not None: assert isinstance(fibergroup, CyclicGroup) or isinstance(fibergroup, SO2) assert maximum_frequency is None, \u0026#34;Maximum Frequency can\u0026#39;t be set when the group is already provided in input\u0026#34; N = fibergroup.order() assert isinstance(N, int) assert isinstance(fibergroup, CyclicGroup) or isinstance(fibergroup, SO2)：这是一个断言语句，用于检查 fibergroup 是否是 CyclicGroup 类型或者 SO2 类型的实例。如果 fibergroup 不是这两种类型的实例，则会引发一个断言错误。\nN = fibergroup.order()：如果之前的条件检查通过（即 fibergroup 不是 None 并且是 CyclicGroup 或 SO2 的实例），则计算 N 的值为 fibergroup 的阶数（order）。\n上面几句，其实一般不会用到，看下面语句：\n1 2 3 4 5 6 7 if N \u0026gt; 1: assert maximum_frequency is None, \u0026#34;Maximum Frequency can\u0026#39;t be set for finite cyclic groups\u0026#34; name = \u0026#39;{}-Rotations\u0026#39;.format(N) elif N == -1: name = \u0026#39;Continuous-Rotations\u0026#39; else: raise ValueError(f\u0026#39;Error! \u0026#34;N\u0026#34; has to be an integer greater than 1 or -1, but got {N}\u0026#39;) 然后看下面这些语句，这里的话就是根据你输入参数的给不同的群命令，比如现在 我们输入$N=8$，那么这个时候名字就是8-Rotations。代表 8 个循环群轮换。\n然后看下面：\n1 2 3 4 5 if fibergroup is None: if N \u0026gt; 1: fibergroup = cyclic_group(N) elif N == -1: fibergroup = so2_group(maximum_frequency) 这里的话我们先说明对应循环群，即看cyclic_group这个函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def cyclic_group(N: int): r\u0026#34;\u0026#34;\u0026#34; Builds a cyclic group :math:`C_N`of order ``N``, i.e. the group of ``N`` discrete planar rotations. You should use this factory function to build an instance of :class:`e2cnn.group.CyclicGroup`. Only one instance is built and, in case of multiple calls to this function, the same instance is returned. In case of multiple calls of this function with different parameters or in case new representations are built (eg. through the method :meth:`~e2cnn.group.Group.quotient_representation`), this unique instance is updated with the new representations and, therefore, all its references will see the new representations. Args: N (int): number of discrete rotations in the group Returns: the cyclic group of order ``N`` \u0026#34;\u0026#34;\u0026#34; return CyclicGroup._generator(N) 这个的话就是构建结束为N的循环群 $C_{N}$。然后，我们 跳进去这个函数里面看看对应的细节。注意，里面的内容是对应的核心。\n1 2 3 4 5 6 def _generator(N: int) -\u0026gt; \u0026#39;CyclicGroup\u0026#39;: global _cached_group_instances if N not in _cached_group_instances: _cached_group_instances[N] = CyclicGroup(N) return _cached_group_instances[N] 这段代码定义了一个函数 _generator，它接受一个整数 N 作为参数，并返回一个 CyclicGroup 对象。函数使用了一个全局变量 _cached_group_instances，该变量可能用于存储已经创建过的 CyclicGroup 实例。\n然后，现如何说没有创建对应的循环群，这个时候 需要调用CyclicGroup的初始化，下面看这个函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def __init__(self, N: int): r\u0026#34;\u0026#34;\u0026#34; Build an instance of the cyclic group :math:`C_N` which contains :math:`N` discrete planar rotations. The group elements are :math:`\\{e, r, r^2, r^3, \\dots, r^{N-1}\\}`, with group law :math:`r^a \\cdot r^b = r^{\\ a + b \\!\\! \\mod \\!\\! N \\ }`. The cyclic group :math:`C_N` is isomorphic to the integers *modulo* ``N``. For this reason, elements are stored as the integers between :math:`0` and :math:`N-1`, where the :math:`k`-th element can also be interpreted as the discrete rotation by :math:`k\\frac{2\\pi}{N}`. Args: N (int): order of the group \u0026#34;\u0026#34;\u0026#34; assert (isinstance(N, int) and N \u0026gt; 0) super(CyclicGroup, self).__init__(\u0026#34;C%d\u0026#34; % N, False, True) self.elements = list(range(N)) self.elements_names = [\u0026#39;e\u0026#39;] + [\u0026#39;r%d\u0026#39; % i for i in range(1, N)] self.identity = 0 self._build_representations() 这个函数就是构建包含$N$离散平面旋转的循环群$C_{N}$的实例。\ndef __init__(self, N: int):：这是 Python 类的构造函数（initializer），用于创建 CyclicGroup 类的实例。它接受一个整数 N 作为参数，代表循环群的阶或元素的数量。\nassert (isinstance(N, int) and N \u0026gt; 0)：这是一个断言语句，用于确保输入的 N 是正整数。如果 N 不是整数或者小于等于零，将会触发 AssertionError。这里的话是因为当小于 0 的时候，我们创建的是离散群，这个时候应该\nsuper(CyclicGroup, self).__init__(\u0026quot;C%d\u0026quot; % N, False, True)：这行代码调用了 super() 函数来调用父类的构造函数。它将创建一个新的 CyclicGroup 类的实例，并将群的名称设置为字符串形式的 C 后跟阶数 N。\nself.elements = list(range(N))：创建了一个存储群元素的列表，列表中的元素是从 0 到 N-1 的整数，代表循环群中的元素。注意，这个参数很重要，就是因为有了这个参数，我们才能说使用先缓缓创建对应的循环群。现在我们N=8，这个时候 elements 是[0,1,2,3,4,5,6,7]\nself.elements_names = ['e'] + ['r%d' % i for i in range(1, N)]：创建了一个包含群元素名称的列表。群元素名字中 e 代表群的单位元素，其他的元素用 r1, r2, \u0026hellip;, rN-1 表示。现在N=8，elements_name就是['e', 'r1', 'r2', 'r3', 'r4', 'r5', 'r6', 'r7']。\nself.identity = 0：将群的单位元素（标识为 e）的索引设为 0。\nself._build_representations()：调用了一个名为 _build_representations() 的方法。下面看看这个方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def _build_representations(self): r\u0026#34;\u0026#34;\u0026#34; Build the irreps and the regular representation for this group \u0026#34;\u0026#34;\u0026#34; N = self.order() # Build all the Irreducible Representations for k in range(0, int(N // 2) + 1): self.irrep(k) # Build all Representations # add all the irreps to the set of representations already built for this group self.representations.update(**self.irreps) # build the regular representation self.representations[\u0026#39;regular\u0026#39;] = self.regular_representation self.representations[\u0026#39;regular\u0026#39;].supported_nonlinearities.add(\u0026#39;vectorfield\u0026#39;) 先看对应的 第一句，调用的是 order 函数，对应的函数如下：\n1 2 3 4 5 6 7 8 9 10 11 12 def order(self) -\u0026gt; int: r\u0026#34;\u0026#34;\u0026#34; Returns the number of elements in this group if it is a finite group, otherwise -1 is returned Returns: the size of the group or ``-1`` if it is a continuous group \u0026#34;\u0026#34;\u0026#34; if self.elements is not None: return len(self.elements) else: return -1 现在咱们元素不为 0，这个时候返回的就是 elements 数组的长度，即返回 8。然后再看下面的语句：\n1 2 3 # Build all the Irreducible Representations for k in range(0, int(N // 2) + 1): self.irrep(k) for k in range(0, int(N // 2) + 1):：这是一个循环结构，用于迭代地构建循环群的不可约表示。range(0, int(N // 2) + 1) 用来生成从 0 到 N // 2 的整数序列，包括 N // 2。在每次迭代中，调用 self.irrep(k) 方法，这个方法可能用来生成和存储循环群的不可约表示。\n注意，我么要时刻记住我们是在一个循环中进来了这里，因此，这里其实会调用四次。\n但是，在后续的代码调试中，其实这部分虽然是进去了，但是里面的函数都没有运行，这是因为 lamda 表达式的特性：lambda 函数将在之后被调用或使用时执行。只有在你实际调用 irrep 变量作为函数，并传递参数 element 和可能的其他参数时，lambda 函数内部的代码才会执行。可以看下图：\n其中的等到build_representations,cyclicgroup.py:221这一行的时候才能进行才会开始调用，相当于函数中的这一句：\n1 self.representations[\u0026#39;regular\u0026#39;] = self.regular_representation 这里面会使用到 irrep 变量，这个时候才会执行对应函数，我们先说明这个函数的执行过程，出现的变量需要集合后续步骤才能解释明白。\n然后，关于群的 不可约表示可以理解成：群的一个表示，如果它的所有矩阵可以借助于某一个相似变换变 成相同形式的对角方块化矩阵，则此表示是可约的，否则是不可约的。\nok，下面我们先看irrep这部分的代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def irrep(self, k: int) -\u0026gt; IrreducibleRepresentation: r\u0026#34;\u0026#34;\u0026#34; Build the irrep of frequency ``k`` of the current cyclic group. The frequency has to be a non-negative integer in :math:`\\{0, \\dots, \\left \\lfloor N/2 \\right \\rfloor \\}`, where :math:`N` is the order of the group. Args: k (int): the frequency of the representation Returns: the corresponding irrep \u0026#34;\u0026#34;\u0026#34; assert 0 \u0026lt;= k \u0026lt;= self.order()//2 name = f\u0026#34;irrep_{k}\u0026#34; if name not in self.irreps: n = self.order() base_angle = 2.0 * np.pi / n if k == 0: # Trivial representation irrep = lambda element, identity=np.eye(1): identity character = lambda e: 1 supported_nonlinearities = [\u0026#39;pointwise\u0026#39;, \u0026#39;gate\u0026#39;, \u0026#39;norm\u0026#39;, \u0026#39;gated\u0026#39;, \u0026#39;concatenated\u0026#39;] self.irreps[name] = IrreducibleRepresentation(self, name, irrep, 1, 1, supported_nonlinearities=supported_nonlinearities, # character=character, # trivial=True, frequency=k) elif n % 2 == 0 and k == int(n/2): # 1 dimensional Irreducible representation (only for even order groups) irrep = lambda element, k=k, base_angle=base_angle: np.array([[np.cos(k * element * base_angle)]]) supported_nonlinearities = [\u0026#39;norm\u0026#39;, \u0026#39;gated\u0026#39;, \u0026#39;concatenated\u0026#39;] self.irreps[name] = IrreducibleRepresentation(self, name, irrep, 1, 1, supported_nonlinearities=supported_nonlinearities, frequency=k) else: # 2 dimensional Irreducible Representations # build the rotation matrix with rotation frequency \u0026#39;frequency\u0026#39; irrep = lambda element, k=k, base_angle=base_angle: utils.psi(element * base_angle, k=k) supported_nonlinearities = [\u0026#39;norm\u0026#39;, \u0026#39;gated\u0026#39;] self.irreps[name] = IrreducibleRepresentation(self, name, irrep, 2, 2, supported_nonlinearities=supported_nonlinearities, frequency=k) return self.irreps[name] 这个irrrp对应的代码，通过代码的注释，可以知道，是建立当前循环群频率为 k 的次循环。这个时候我们跳进来，看对应 的内容。\nassert 0 \u0026lt;= k \u0026lt;= self.order()//2：首先的话还是老规矩，这个的话断言判断，可以分成两部分进行查看：\n0 \u0026lt;= k：确保频率 k 是非负整数，因为频率通常是一个非负的整数。在这里，频率表示不可约表示的特定特征，因此必须为非负整数。 k \u0026lt;= self.order()//2：保证频率 k 不超过循环群的阶数 N 的一半。在数学上，对于循环群的不可约表示，频率 k 的范围通常被限制在 0 到 N/2 之间，因此这个断言确保了频率 k 不会超出有效范围。 当然，第二个正确性有待考究！！！\nname = f\u0026quot;irrep_{k}\u0026quot;：构建表示的名称，用于存储在 self.irreps 字典中。\n1 2 3 if name not in self.irreps: n = self.order() base_angle = 2.0 * np.pi / n 还是一样，首先读取对应 群元素阶数，这个可以看上面的order的 介绍，得到n=8。\n然后，我们创建对应的base_angle,这里的话 就是$\\frac{2 \\pi}{n}$。相当于我们现在的基本角度是 360/群 元素阶数，因为循环群中的元素是围绕一个圆周循环的，所以 2.0 * np.pi / n 计算出了循环群中每个元素之间的角度间隔。通过将整个圆周（2.0 * np.pi）分成循环群的阶数 n 份，可以得到每个群元素之间的平均角度间隔，这个角度间隔在表示不同群元素的线性变换中很有用。\n在构建循环群的不可约表示时，这个 base_angle 变量被用来计算表示矩阵中角度的变换。具体地，在不同频率的不可约表示中，元素与 base_angle 的乘积用来确定对应元素的矩阵表示。这种方式有效地利用了循环群元素之间的角度关系来构建不同频率的表示。\n然后，接着看面对应的代码：\n1 2 3 4 5 6 7 8 9 10 if k == 0: # Trivial representation irrep = lambda element, identity=np.eye(1): identity character = lambda e: 1 supported_nonlinearities = [\u0026#39;pointwise\u0026#39;, \u0026#39;gate\u0026#39;, \u0026#39;norm\u0026#39;, \u0026#39;gated\u0026#39;, \u0026#39;concatenated\u0026#39;] self.irreps[name] = IrreducibleRepresentation(self, name, irrep, 1, 1, supported_nonlinearities=supported_nonlinearities, # character=character, # trivial=True, frequency=k) 当 k 为 0 时，构建了一个平凡表示（Trivial representation），对应于单位矩阵。\n平凡表示（Trivial representation）是群论中的一个概念，指的是一个群的每个元素都被映射成一个恒等矩阵或单位矩阵。对于每个群元素，这个表示都将其映射为相同的单位矩阵。\n如果循环群的阶数 n 为偶数且 k 等于 n/2，构建一个一维不可约表示。\n1 2 3 4 5 6 7 elif n % 2 == 0 and k == int(n/2): # 1 dimensional Irreducible representation (only for even order groups) irrep = lambda element, k=k, base_angle=base_angle: np.array([[np.cos(k * element * base_angle)]]) supported_nonlinearities = [\u0026#39;norm\u0026#39;, \u0026#39;gated\u0026#39;, \u0026#39;concatenated\u0026#39;] self.irreps[name] = IrreducibleRepresentation(self, name, irrep, 1, 1, supported_nonlinearities=supported_nonlinearities, frequency=k) TDOO：解释对应的参数\n其他情况（k=1,2,3）都会来到下面：\n1 2 3 4 5 6 7 8 9 10 else: # 2 dimensional Irreducible Representations # build the rotation matrix with rotation frequency \u0026#39;frequency\u0026#39; irrep = lambda element, k=k, base_angle=base_angle: utils.psi(element * base_angle, k=k) supported_nonlinearities = [\u0026#39;norm\u0026#39;, \u0026#39;gated\u0026#39;] self.irreps[name] = IrreducibleRepresentation(self, name, irrep, 2, 2, supported_nonlinearities=supported_nonlinearities, frequency=k) lambda element, k=k, base_angle=base_angle:：这定义了一个匿名函数，接受两个参数 element、k 和一个默认参数 base_angle。这个函数可以根据传入的 element 参数以及已定义的 k 和 base_angle 参数来计算结果。 utils.psi(element * base_angle, k=k)：这是函数的返回表达式。它调用了一个名为 utils.psi 的函数（假设 utils 是一个模块或对象的名称）。此函数可能用于计算给定元素乘以基础角度（element * base_angle）所得的结果，然后以及给定的频率 k 为参数。这个函数的具体操作和实现由 utils.psi 定义。这个函数的目的是计算表示矩阵的元素。 这里需要简单看一眼 psi 这个函数：\n1 2 3 4 5 6 7 8 9 10 def psi(theta: float, k: int = 1, gamma: float = 0.): r\u0026#34;\u0026#34;\u0026#34; Rotation matrix corresponding to the angle :math:`k \\theta + \\gamma`. \u0026#34;\u0026#34;\u0026#34; x = k * theta + gamma c, s = np.cos(x), np.sin(x) return np.array(([ [c, -s], [s, c], ])) 现在举一个例子，假设我们现在$k = 1, elements= [0,1,2,3,4,5,6,7]$，这个时候，对应计算结果应该出来 8 个。手写出来对应的 例子，如下：\n然后，在后面使用时对里面的值有一个操作，这里的话还有一个疑问，后面那句话不是已经使用了嘛，为什么不是这个时候进行初始化？ 先看后面程序，等回头在解决这个问题。\n然后，来到最后一种情况，相当于现在是 n 是偶数并 k=n/2 是才会进入。\n1 2 3 4 5 6 7 elif n % 2 == 0 and k == int(n/2): # 1 dimensional Irreducible representation (only for even order groups) irrep = lambda element, k=k, base_angle=base_angle: np.array([[np.cos(k * element * base_angle)]]) supported_nonlinearities = [\u0026#39;norm\u0026#39;, \u0026#39;gated\u0026#39;, \u0026#39;concatenated\u0026#39;] self.irreps[name] = IrreducibleRepresentation(self, name, irrep, 1, 1, supported_nonlinearities=supported_nonlinearities, frequency=k) 跟上面的进行对比，这个区别就是里面创建的矩阵不一样了，成了一个$1 \\times 1$的矩阵。\n上面这个函数疑问重重，为什么一个频率有 7 个表示，然后他们后面会进行什么操作，这些都要看下面的代码，然后才能进行解答。\nok，现在看下面的代码，回答上面的问题。\n1 2 3 4 5 6 # Build all Representations # add all the irreps to the set of representations already built for this group self.representations.update(**self.irreps) # build the regular representation self.representations[\u0026#39;regular\u0026#39;] = self.regular_representation self.representations[\u0026#39;regular\u0026#39;].supported_nonlinearities.add(\u0026#39;vectorfield\u0026#39;) 如果说现在已经有了不可约表示，直接更新。\n如果说不存在，这个是将会将群与rugular的键与self.regular_representation关联起来，存储在slef.reular_representation中。\n下面的话看这个里面的代码，是重头戏：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 def regular_representation(self) -\u0026gt; e2cnn.group.Representation: r\u0026#34;\u0026#34;\u0026#34; Builds the regular representation of the group if the group has a *finite* number of elements; returns ``None`` otherwise. The regular representation of a finite group :math:`G` acts on a vector space :math:`\\R^{|G|}` by permuting its axes. Specifically, associating each axis :math:`e_g` of :math:`\\R^{|G|}` to an element :math:`g \\in G`, the representation of an element :math:`\\tilde{g}\\in G` is a permutation matrix which maps :math:`e_g` to :math:`e_{\\tilde{g}g}`. For instance, the regular representation of the group :math:`C_4` with elements :math:`\\{r^k | k=0,\\dots,3 \\}` is instantiated by: +-----------------------------------+------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+ | :math:`g` | :math:`e` | :math:`r` | :math:`r^2` | :math:`r^3` | +===================================+============================================================================================================+============================================================================================================+============================================================================================================+============================================================================================================+ | :math:`\\rho_\\text{reg}^{C_4}(g)` | :math:`\\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\\\ \\end{bmatrix}` | :math:`\\begin{bmatrix} 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\\\ 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\\\ \\end{bmatrix}` | :math:`\\begin{bmatrix} 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\\\ 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \\\\ \\end{bmatrix}` | :math:`\\begin{bmatrix} 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\\\ 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ \\end{bmatrix}` | +-----------------------------------+------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------+ A vector :math:`v=\\sum_g v_g e_g` in :math:`\\R^{|G|}` can be interpreted as a scalar function :math:`v:G \\to \\R,\\, g \\mapsto v_g` on :math:`G`. Returns: the regular representation of the group \u0026#34;\u0026#34;\u0026#34; if self.order() \u0026lt; 0: raise ValueError(f\u0026#34;Regular representation is supported only for finite groups but \u0026#34; f\u0026#34;the group {self.name} has an infinite number of elements\u0026#34;) else: if \u0026#34;regular\u0026#34; not in self.representations: irreps, change_of_basis, change_of_basis_inv = e2cnn.group.representation.build_regular_representation(self) supported_nonlinearities = [\u0026#39;pointwise\u0026#39;, \u0026#39;norm\u0026#39;, \u0026#39;gated\u0026#39;, \u0026#39;concatenated\u0026#39;] self.representations[\u0026#34;regular\u0026#34;] = e2cnn.group.Representation(self, \u0026#34;regular\u0026#34;, [r.name for r in irreps], change_of_basis, supported_nonlinearities, change_of_basis_inv=change_of_basis_inv, ) return self.representations[\u0026#34;regular\u0026#34;] 如果说现在是有限循环群，这段代码将构建群的正则表示。\n然后，我们看到里面irreps这个变量将会进行创建，执行的是这个语句：\n1 irreps, change_of_basis, change_of_basis_inv = e2cnn.group.representation.build_regular_representation(self) 那么下面，需要看build_regular_representation这个函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 def build_regular_representation(group: e2cnn.group.Group) -\u0026gt; Tuple[List[e2cnn.group.IrreducibleRepresentation], np.ndarray, np.ndarray]: r\u0026#34;\u0026#34;\u0026#34; Build the regular representation of the input ``group``. As the regular representation has size equal to the number of elements in the group, only finite groups are accepted. Args: group (Group): the group whose representations has to be built Returns: a tuple containing the list of irreps, the change of basis and the inverse change of basis of the regular representation \u0026#34;\u0026#34;\u0026#34; assert group.order() \u0026gt; 0 assert group.elements is not None and len(group.elements) \u0026gt; 0 size = group.order() index = {e: i for i, e in enumerate(group.elements)} representation = {} character = {} for e in group.elements: # print(index[e], e) r = np.zeros((size, size), dtype=float) for g in group.elements: eg = group.combine(e, g) i = index[g] j = index[eg] r[j, i] = 1.0 representation[e] = r # the character maps an element to the trace of its representation character[e] = np.trace(r) # compute the multiplicities of the irreps from the dot product between # their characters and the character of the representation irreps = [] multiplicities = [] for irrep_name, irrep in group.irreps.items(): # for each irrep multiplicity = 0.0 # compute the inner product with the representation\u0026#39;s character for element, char in character.items(): multiplicity += char * irrep.character(group.inverse(element)) multiplicity /= len(character) * irrep.sum_of_squares_constituents # the result has to be an integer assert math.isclose(multiplicity, round(multiplicity), abs_tol=1e-9), \\ \u0026#34;Multiplicity of irrep %s is not an integer: %f\u0026#34; % (irrep_name, multiplicity) # print(irrep_name, multiplicity) multiplicity = int(round(multiplicity)) irreps += [irrep]*multiplicity multiplicities += [(irrep, multiplicity)] P = directsum(irreps, name=\u0026#34;irreps\u0026#34;) v = np.zeros((size, 1), dtype=float) p = 0 for irr, m in multiplicities: assert irr.size \u0026gt;= m s = irr.size v[p:p+m*s, 0] = np.eye(m, s).reshape(-1) * np.sqrt(s) p += m*s change_of_basis = np.zeros((size, size)) np.set_printoptions(precision=4, threshold=10*size**2, suppress=False, linewidth=25*size + 5) for e in group.elements: ev = P(e) @ v change_of_basis[index[e], :] = ev.T change_of_basis /= np.sqrt(size) # the computed change of basis is an orthonormal matrix # change_of_basis_inv = sp.linalg.inv(change_of_basis) change_of_basis_inv = change_of_basis.T return irreps, change_of_basis, change_of_basis_inv 这个函数其实是核心中的核心，这个就是将每个频率进行相加，然后得到一个值。下面将这个进行逐行解析。\n1 2 3 4 5 6 assert group.order() \u0026gt; 0 assert group.elements is not None and len(group.elements) \u0026gt; 0 size = group.order() index = {e: i for i, e in enumerate(group.elements)} 这个还是老规矩，首先先判断，然后设置群的结束，以及对应的索引号。然后创建 index 的字典。\ngroup.elements：这个部分可能是一个群（group）对象或类中的属性，其中包含了群的元素。 enumerate(group.elements)：enumerate() 函数用于迭代一个可迭代对象（比如列表、元组等），并返回索引值和对应的元素。这里对群中的元素进行了枚举，i 是索引，e 是群中的元素。 {e: i for i, e in enumerate(group.elements)}：这是一个字典推导式。它遍历了 enumerate(group.elements) 返回的枚举对象，对每个元素创建了一个键值对。字典的键是群中的元素 e，而值是它们在群中的索引 i。 在本文的情况下 index 的值就是{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n然后看下面的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 for e in group.elements: print(index[e], e) r = np.zeros((size, size), dtype=float) for g in group.elements: eg = group.combine(e, g) i = index[g] j = index[eg] r[j, i] = 1.0 representation[e] = r # the character maps an element to the trace of its representation character[e] = np.trace(r) 这段代码首先先遍历里面的元素，创建一个大小为 (size,size) 大小的二维数组r。\n在每个元素 e 的循环内，这段代码嵌套了一个循环，遍历群 group 中的每个元素 g。将对应的群e和g结合起来，创建一个新的群元素eg。\ni = index[g] 和 j = index[eg]：这两行代码分别获取了群元素 g 和 eg 在 index 字典中的索引值，即它们在表示矩阵 r 中对应的位置。\nr[j, i] = 1.0：这行代码将表示矩阵 r 中的位置 (j, i)（根据群元素 eg 和 g 的索引值计算得到）的元素设置为 1.0。这是表示矩阵中的一个元素，用于表示群操作后的结果。\nrepresentation[e] = r：将表示矩阵 r 存储到表示字典 representation 中，其中键是群元素 e。\ncharacter[e] = np.trace(r)：这行代码计算了表示矩阵 r 的迹（trace），并将其存储在字符（character）字典 character 中，键是群元素 e。在群论中，表示的迹（trace）通常被称为字符（character），它是表示理论中的一个重要性质之一。\n还是从一个例子出发，这里的话还使用对应的e=0，g= 0,1,2,3,4,5,6,7这种情况。\n这个时候，eg=0,1,2,3,4,5,6,7，在遍历完成之后，对应的r矩阵应该就是$8 \\times 8$的单位矩阵，然后此时 representation 应该就是 (0) 位置是 1，其他位置都是 0。character[0]应该是 矩阵的迹，是 8。\n以此类推，创建完对应的数组。\n然后接着看下面的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 irreps = [] multiplicities = [] for irrep_name, irrep in group.irreps.items(): # for each irrep multiplicity = 0.0 # compute the inner product with the representation\u0026#39;s character for element, char in character.items(): multiplicity += char * irrep.character(group.inverse(element)) multiplicity /= len(character) * irrep.sum_of_squares_constituents # the result has to be an integer assert math.isclose(multiplicity, round(multiplicity), abs_tol=1e-9), \\ \u0026#34;Multiplicity of irrep %s is not an integer: %f\u0026#34; % (irrep_name, multiplicity) # print(irrep_name, multiplicity) multiplicity = int(round(multiplicity)) irreps += [irrep]*multiplicity multiplicities += [(irrep, multiplicity)] 计算群的不可约表示（irreducible representations）的重复数量（multiplicities），并将结果存储在 irreps 和 multiplicities 中。下面逐行分析对应的代码。\n首先的话创建对应的变量进行存储。\nfor irrep_name, irrep in group.irreps.items():：这段代码遍历了群 group 的不可约表示字典（group.irreps）中的每一个不可约表示，其中 irrep_name 是表示的名称，irrep 是表示对象。\ngroup.irreps.items() 就是我们 上面创建好的群元素。\nfor element, char in character.items():：这段代码遍历了字符（character）字典 character 中的每个群元素和对应的字符值（character value）。\nmultiplicity += char * irrep.character(group.inverse(element))：在每个不可约表示 irrep 的循环内，计算了该不可约表示与表示对应群元素的字符的内积（inner product）。这个内积计算用于确定表示的重复次数。\nmultiplicity /= len(character) * irrep.sum_of_squares_constituents：在内积计算之后，对结果进行了归一化，除以表示的元素数乘以不可约表示的总元素平方和。\nassert math.isclose(multiplicity, round(multiplicity), abs_tol=1e-9)：这行代码检查 multiplicity 是否接近于整数，如果不是，则会触发断言错误。\nmultiplicity = int(round(multiplicity))：将 multiplicity 舍入为最接近的整数值，确保它是整数。\nirreps += [irrep]*multiplicity 和 multiplicities += [(irrep, multiplicity)]：将不可约表示 irrep 重复 multiplicity 次添加到 irreps 列表中，并将表示和其重复次数的元组添加到 multiplicities 列表中。\n然后看下面的代码：\n1 2 3 4 5 6 7 8 P = directsum(irreps, name=\u0026#34;irreps\u0026#34;) v = np.zeros((size, 1), dtype=float) p = 0 for irr, m in multiplicities: assert irr.size \u0026gt;= m s = irr.size v[p:p+m*s, 0] = np.eye(m, s).reshape(-1) * np.sqrt(s) p += m*s directsum(irreps, name=\u0026quot;irreps\u0026quot;)：这里使用了一个名为 directsum 的函数，它的目的是将不可约表示列表 irreps 中的不可约表示按照其给定的重数信息相加，构建一个直和表示 P。\n看directsum这个函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def directsum(reprs: List[e2cnn.group.Representation], change_of_basis: np.ndarray = None, name: str = None ) -\u0026gt; e2cnn.group.Representation: r\u0026#34;\u0026#34;\u0026#34; Compute the *direct sum* of a list of representations of a group. The direct sum of two representations is defined as follow: .. math:: \\rho_1(g) \\oplus \\rho_2(g) = \\begin{bmatrix} \\rho_1(g) \u0026amp; 0 \\\\ 0 \u0026amp; \\rho_2(g) \\end{bmatrix} This can be generalized to multiple representations as: .. math:: \\bigoplus_{i=1}^I \\rho_i(g) = (\\rho_1(g) \\oplus (\\rho_2(g) \\oplus (\\rho_3(g) \\oplus \\dots = \\begin{bmatrix} \\rho_1(g) \u0026amp; 0 \u0026amp; \\dots \u0026amp; 0 \\\\ 0 \u0026amp; \\rho_2(g) \u0026amp; \\dots \u0026amp; \\vdots \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; 0 \\\\ 0 \u0026amp; \\dots \u0026amp; 0 \u0026amp; \\rho_I(g) \\\\ \\end{bmatrix} .. note:: All the input representations need to belong to the same group. Args: reprs (list): the list of representations to sum. change_of_basis (~numpy.ndarray, optional): an invertible square matrix to use as change of basis after computing the direct sum. By default (``None``), an identity matrix is used, such that only the direct sum is evaluated. name (str, optional): a name for the new representation. Returns: the direct sum \u0026#34;\u0026#34;\u0026#34; group = reprs[0].group for r in reprs: assert group == r.group if name is None: name = \u0026#34;_\u0026#34;.join([f\u0026#34;[{r.name}]\u0026#34; for r in reprs]) irreps = [] for r in reprs: irreps += r.irreps size = sum([r.size for r in reprs]) cob = np.zeros((size, size)) cob_inv = np.zeros((size, size)) p = 0 for r in reprs: cob[p:p + r.size, p:p + r.size] = r.change_of_basis cob_inv[p:p + r.size, p:p + r.size] = r.change_of_basis_inv p += r.size if change_of_basis is not None: change_of_basis = change_of_basis @ cob change_of_basis_inv = sp.linalg.inv(change_of_basis) else: change_of_basis = cob change_of_basis_inv = cob_inv supported_nonlinearities = set.intersection(*[r.supported_nonlinearities for r in reprs]) return Representation(group, name, irreps, change_of_basis, supported_nonlinearities, change_of_basis_inv=change_of_basis_inv) 这个函数作用是计算群的代表列表的直积。两个数的直积可以表示成： $$ \\rho_1(g) \\oplus \\rho_2(g) = \\begin{bmatrix} \\rho_1(g) \u0026amp; 0 \\ 0 \u0026amp; \\rho_2(g) \\end{bmatrix} $$ 这可以推广为多种表示形式： $$ \\bigoplus_{i=1}^I \\rho_i(g) = (\\rho_1(g) \\oplus (\\rho_2(g) \\oplus (\\rho_3(g) \\oplus \\dots = \\begin{bmatrix} \\rho_1(g) \u0026amp; 0 \u0026amp; \\dots \u0026amp; 0 \\ 0 \u0026amp; \\rho_2(g) \u0026amp; \\dots \u0026amp; \\vdots \\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; 0 \\ 0 \u0026amp; \\dots \u0026amp; 0 \u0026amp; \\rho_I(g) \\ \\end{bmatrix} $$ 里面拿到很多变量进行直积操作，相当于矩阵的拼接以及填充，里面没有什么好讲的。\n然后，我们现在讲不可约群 进行直接操作，命名成irreps，接下来将创建一个大小为 (size, 1) 的全零列向量 v，该向量将用作基的变换矩阵的一部分。\n然后接下就到循环部分：\n1 2 3 4 5 6 p = 0 for irr, m in multiplicities: assert irr.size \u0026gt;= m s = irr.size v[p:p+m*s, 0] = np.eye(m, s).reshape(-1) * np.sqrt(s) p += m*s 对于每个不可约表示irr和其对应的重数m: s = irr.size：获取不可约表示的维度。 np.eye(m, s).reshape(-1) * np.sqrt(s)：生成一个大小为 (m, s) 的单位矩阵，并对其进行重塑（reshape）以变成一个列向量，并乘以 $\\sqrt{s}$。 v[p:p+m*s, 0] = ...：将生成的列向量放置在 v 的适当位置，根据当前 p 的值和表示的维度 s。 p += m*s：更新下一个表示的起始位置。 然后的话看接下来的代码：\n1 2 3 4 5 6 change_of_basis = np.zeros((size, size)) np.set_printoptions(precision=4, threshold=10*size**2, suppress=False, linewidth=25*size + 5) for e in group.elements: ev = P(e) @ v change_of_basis[index[e], :] = ev.T change_of_basis /= np.sqrt(size) 这一部分代码是计算群的正则表示的基之间的变换矩阵。它使用之前构建的直和表示 P 和基的变换矩阵 v，来计算群的元素之间的表示矩阵，最终得到基的变换矩阵 change_of_basis。\nchange_of_basis = np.zeros((size, size))： 创建一个大小为 (size, size) 的全零矩阵 change_of_basis，该矩阵将存储基之间的变换矩阵。 np.set_printoptions(...)：\n设置打印选项，以便后续打印变换矩阵时能够更好地显示数值。 for e in group.elements:：\n对于群中的每个元素 e： ev = P(e) @ v：\n计算群元素 e 对应的表示矩阵，通过用直和表示 P 对 e 作用于基的变换矩阵 v change_of_basis[index[e], :] = ev.T：\n将得到的表示矩阵 ev 的转置（为了匹配矩阵维度）存储在 change_of_basis 中，位置由 index[e] 确定。 change_of_basis /= np.sqrt(size)：\n对整个 change_of_basis 矩阵进行归一化处理，以确保该变换矩阵是正交的。 change_of_basis_inv = change_of_basis.T\n将矩阵进行转置。 然后返回对应的 变量，一致返回到最开始。\n# 总结 上面虽然介绍了 e2cnn 等变群卷积创建群 的过程，但是 实话实说，整体流程仍然是云里雾里，因此我们需要对里面 的流程做一个重新的梳理。\n指定群的阶数，调用 Rot2dOnR2 进行初始化。 判断传入 N 的大小，如果说现在是大于 0 的话创建 循环群，小于 0 的话创建的 是离散群。这篇博客仅仅讨论 循环群的创建。 确定为循环群，调用循环群cyclic_group的初始化。将回调用_generator里面的 CyclicGroup 函数，初始化对应的循环群。 初始化群元素的给个数，名称，表示，然后调用_build_representations构建群。 首先构建群的不可约表示，因为现在使用的是 循环群（对称群），这个时候不可约表示肯定不会超过其中的一半。 根据传入的群的阶数不同，每个群中的元素需要分别使用不同的初始化方式进行构建，这个详细请看上面的介绍。 注意，这里面有坑点，里面使用了 lamda 表达式，会在 使用的时候才会进行初始化。 下面将会构建对应的 regular 层，这里的话其实就是根据我们上面计算出来的 irreps（不可约表示），计算对应的 irreps, change_of_basis, change_of_basis_inv。这个就像与 构建 了群的 常规表示。 以上 就是循环群的创建，但是在第 7 点，里面的细节没有讲清楚，这里的话其实应该结合论文来看。\n讲道理，上面的源码当中，表示了循环群的常规表示法，也构建了向量$v$，构建了对应的表示，在构建对应的表示的时候，使用到了每个群元素中的 表示，对应上面公式，就能解释的通\n最关键就是这里的转换，就是有了着了的转换，才能使用上面对应的内容进行表示。\n","date":"2023-12-02T16:55:17+08:00","permalink":"https://runqizhao.cn/p/e2cnn-%E5%86%85%E5%AE%B9%E7%90%86%E8%A7%A3-%E7%BE%A4%E7%9A%84%E5%88%9B%E5%BB%BA%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3/","title":"e2cnn 内容理解 - 群的创建源码详解 "},{"content":"本篇将会详细介绍ThreadLocal线程\n学习一个新知识，无非就是三步：\n这个是啥 怎么实现的 应用场景都有啥 下面将通过这三部进行分析。\n# 什么是ThreadLocal 首先先上一张图吧，这张图来自于这个博客\n上面脑图很好的树立了对应的结构。\n首先 说明ThreaLocal的概念：ThreadLocal 是一个本地线程副本变量工具类。主要用于将私有线程和该线程存放的副本对象做一个映射，各个线程之间的变量互不干扰。\n先看一个对应ThreadLocal的演示代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public class ThreadLocalTest { private List\u0026lt;String\u0026gt; messages = new ArrayList\u0026lt;\u0026gt;(); public static final ThreadLocal\u0026lt;ThreadLocalTest\u0026gt; holder = ThreadLocal.withInitial(ThreadLocalTest::new); public static void add(String message) { holder.get().messages.add(message); } public static List\u0026lt;String\u0026gt; clear() { List\u0026lt;String\u0026gt; messages = holder.get().messages; holder.remove(); System.out.println(\u0026#34;size: \u0026#34; + holder.get().messages.size()); return messages; } public static void main(String[] args) { ThreadLocalTest.add(\u0026#34;test\u0026#34;); System.out.println(holder.get().messages); ThreadLocalTest.clear(); } } 打印的结果为：\n1 2 [test] size: 0 相当于提供线程局部变量，每个线程Thread拥有一份自己的副本变量，多个线程互不干扰。\nok，对其中概念有了一个基本概念，下面分析实现过程。\n# ThreadLocal是如何实现的 # ThreadLocal数据结构 首先还是使用一张图进行表示：\nThread类有一个类型为ThreadLocal.ThreadLocalMap的实例变量threadLocals，也就是说每个线程有一个自己的ThreadLocalMap。\nThreadLocalMap有自己的实现，可以将其理解成将ThreadLocal当作一个key，将代码中放入的值但你工作value。\n注意，实际上key并不是ThredLocal，而是一个弱引用。\n每个线程再往ThreadLocal里放值的时候，都会往自己ThreadLocalMap里存，读也是以ThreadLocal作为引用，在自己的map里找到对应的key，从而实现线程隔离。\nThreadLocalMap的底层结构并没有链表结构，仅仅使用了对应的Entry数组。\n1 2 3 4 5 6 7 8 9 static class Entry extends WeakReference\u0026lt;ThreadLocal\u0026lt;?\u0026gt;\u0026gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal\u0026lt;?\u0026gt; k, Object v) { super(k); value = v; } } 之所以说是弱引用，Entry结构在进行设置的时候是继承于WeakReference，这个就是我们常说的弱引用类型。\n现在已经确定是弱引用了，那么出现了一个问题，在ThreadLocal.get()的时候，发生GC之后，key是否为null？\n# GC回收之后key是否为null? 首先回顾下Java中常见的四种引用：\n**强引用：**直接new出来的对象，只要强引用存在，对象永远不会被回收。 **软引用：**使用SoftReference修饰的对象称为软引用，软引用指向的对象在内存要移除的时候被回收。 **弱引用：**使用WeakReference修饰的对象被称为弱引用，只要发生垃圾回收，若这个对象只被弱引用指向，那么就会被回收 **虚引用：**虚引用是最弱的引用，在 Java 中使用 PhantomReference 进行定义。虚引用中唯一的作用就是用队列接收对象即将死亡的通知 下面回到上面的问题，可以使用反射的方式查看GC后ThreadLocal中数据情况：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 public class ThreadLocalDemo { public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException, InterruptedException { Thread t = new Thread(()-\u0026gt;test(\u0026#34;abc\u0026#34;,false)); t.start(); t.join(); System.out.println(\u0026#34;--gc后--\u0026#34;); Thread t2 = new Thread(() -\u0026gt; test(\u0026#34;def\u0026#34;, true)); t2.start(); t2.join(); } private static void test(String s,boolean isGC) { try { new ThreadLocal\u0026lt;\u0026gt;().set(s); if (isGC) { System.gc(); } Thread t = Thread.currentThread(); Class\u0026lt;? extends Thread\u0026gt; clz = t.getClass(); Field field = clz.getDeclaredField(\u0026#34;threadLocals\u0026#34;); field.setAccessible(true); Object threadLocalMap = field.get(t); Class\u0026lt;?\u0026gt; tlmClass = threadLocalMap.getClass(); Field tableField = tlmClass.getDeclaredField(\u0026#34;table\u0026#34;); tableField.setAccessible(true); Object[] arr = (Object[]) tableField.get(threadLocalMap); for (Object o : arr) { if (o != null) { Class\u0026lt;?\u0026gt; entryClass = o.getClass(); Field valueField = entryClass.getDeclaredField(\u0026#34;value\u0026#34;); Field referenceField = entryClass.getSuperclass().getSuperclass().getDeclaredField(\u0026#34;referent\u0026#34;); valueField.setAccessible(true); referenceField.setAccessible(true); System.out.println(String.format(\u0026#34;弱引用key:%s,值:%s\u0026#34;, referenceField.get(o), valueField.get(o))); } } } catch (Exception e) { e.printStackTrace(); } } } 对应的输出如下：\n1 2 3 4 5 6 弱引用key:java.lang.ThreadLocal@b46dd1a,值:abc 弱引用key:java.lang.ThreadLocal@43173215,值:[Ljava.lang.Object;@6738d522 弱引用key:java.lang.ThreadLocal@1e3d527b,值:java.lang.ref.SoftReference@232ee2ab 弱引用key:java.lang.ThreadLocal@59d3fb41,值:java.lang.ref.SoftReference@7863a49c --gc后-- 弱引用key:null,值:def 在进行垃圾回收的时候，会跳转到下面这部分：\n这时，里面创建的ThreadLocal并没有指向任何值，也就是没有任何引用。\n1 new ThreadLocal\u0026lt;\u0026gt;().set(s); 所以这里在GC之后，key就会被回收，我们看到上面debug中的referent=null, 如果改动一下代码：\n这个问题刚开始看，如果没有过多思考，弱引用，还有垃圾回收，那么肯定会觉得是null。\n其实是不对的，因为题目说的是在做 threadlocal.get() 操作，证明其实还是有强引用存在的，所以 key 并不为 null，如下图所示，ThreadLocal的强引用仍然是存在的。\n如果我们的强引用不存在的话，那么 key 就会被回收，也就是会出现我们 value 没被回收，key 被回收，导致 value 永远存在，出现内存泄漏。\n# ThreadLocal.set()方法源码详解 ThreadLocal中的set方法原理如上图所示，很简单，主要是判断ThreadLocalMap是否存在，然后使用ThreadLocal中的set方法进行数据处理。\n1 2 3 4 5 6 7 8 9 10 11 12 public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue); } 其中核心逻辑是在ThreadLocalMap中的。\n下面就简单看一下ThreadLocalMap的逻辑。\n首先说明里面ThreadLocalMap Hash算法\n# ThreadLocalMap Hash算法 既然是Map结构，那么ThreadLocalMap当然也要实现自己的hash算法来解决散列表数组冲突问题。\n1 int i = key.threadLocalHashCode \u0026amp; (len-1); ThreadLocalMap中hash算法很简单，这里i就是当前key在散列表中对应的数组下标位置。\n这里最关键的就是threadLocalHashCode值的计算，ThreadLocal中有一个属性为HASH_INCREMENT = 0x61c88647\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class ThreadLocal\u0026lt;T\u0026gt; { private final int threadLocalHashCode = nextHashCode(); private static AtomicInteger nextHashCode = new AtomicInteger(); private static final int HASH_INCREMENT = 0x61c88647; private static int nextHashCode() { return nextHashCode.getAndAdd(HASH_INCREMENT); } static class ThreadLocalMap { ThreadLocalMap(ThreadLocal\u0026lt;?\u0026gt; firstKey, Object firstValue) { table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode \u0026amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); } } } 每当创建一个ThreadLocal对象，这个ThreadLocal.nextHashCode这个值就会增长为0x61c88647。\n这个值很特殊，这个是斐波那契数也叫黄金分割数，hash增量为这个数，带来的好处就是hash分布非常均匀。\n# ThreadLocalMap Hash冲突 虽然ThreadLocalMap中使用了黄金分割数来作为hash计算因子，大大减少了Hash冲突的概率，但是仍然会存在冲突。\nHashMap中解决冲突的方法是在数组上构造一个链表结构，冲突的数据挂载到链表上，如果链表长度超过一定数量则会转化成红黑树。\n而ThreadLocalMap中并没有链表结构，所以这里不能适用HashMap解决冲突的方式了。\n如上图所示，如果我们插入一个value=27的数据，通过hash计算后应该落入第4个槽位中，而槽位4已经有了Entry数据。\n此时就会线性向后查找，一直找到Entry为null的槽位才会停止查找，将当前元素放入此槽位中。\n但是当碰到Entry不为null且key值相等的情况，还有Entry中的key值为null的情况怎么处理。\n这里还画了一个Entry中的key为null的数据（Entry=2的灰色块数据），因为key值是弱引用类型，所以会有这种数据存在。在set过程中，如果遇到了key过期的Entry数据，实际上是会进行一轮探测式清理操作的。\n# ThreadLocalMap.set()详解 看完了ThreadLocal hash算法后，我们再来看set是如何实现的。\n往ThreadLocalMap中set数据（新增或者更新数据）分为好几种情况，针对不同的情况我们画图来说说明。\n第一种情况： 通过hash计算后的槽位对应的Entry数据为空：\n这里直接将数据放到该槽位即可。\n第二种情况： 槽位数据不为空，key值与当前ThreadLocal通过hash计算获取的key值一致：\n这里直接更新该槽位的数据。\n**第三种情况：**槽位数据不为空，往后遍历过程中，在找到Entry为null的槽位之前，没有遇到key过期的Entry：\n遍历散列数组，线性往后查找，如果找到Entry为null的槽位，则将数据放入该槽位中，或者往后遍历过程中，遇到了key值相等的数据，直接更新即可。\n第四种情况： 槽位数据不为空，往后遍历过程中，在找到Entry为null的槽位之前，遇到key过期的Entry，如下图，往后遍历过程中，一到了index=7的槽位数据Entry的key=null：\n散列数组下标为7位置对应的Entry数据key为null，表明此数据key值已经被垃圾回收掉了，此时就会执行replaceStaleEntry()方法，该方法含义是替换过期数据的逻辑，以index=7位起点开始遍历，进行探测式数据清理工作。\n初始化探测式清理过期数据扫描的开始位置：slotToExpunge = staleSlot = 7\n以当前staleSlot开始 向前迭代查找，找其他过期的数据，然后更新过期数据起始扫描下标slotToExpunge。for循环迭代，直到碰到Entry为null结束。\n如果找到了过期的数据，继续向前迭代，直到遇到Entry=null的槽位才停止迭代，如下图所示，slotToExpunge被更新为0：\n以当前节点(index=7)向前迭代，检测是否有过期的Entry数据，如果有则更新slotToExpunge值。碰到null则结束探测。以上图为例slotToExpunge被更新为0。\n上面向前迭代的操作是为了更新探测清理过期数据的起始下标slotToExpunge的值，这个值在后面会讲解，它是用来判断当前过期槽位staleSlot之前是否还有过期元素。\n接着开始以staleSlot位置(index=7)向后迭代，如果找到了相同key值的Entry数据：\n从当前节点staleSlot向后查找key值相等的Entry元素，找到后更新Entry的值并交换staleSlot元素的位置(staleSlot位置为过期元素)，更新Entry数据，然后开始进行过期Entry的清理工作，如下图所示\n向后遍历过程中，如果没有找到相同key值的Entry数据：\n从当前节点staleSlot向后查找key值相等的Entry元素，直到Entry为null则停止寻找。通过上图可知，此时table中没有key值相同的Entry。\n创建新的Entry，替换table[stableSlot]位置：\n替换完成后也是进行过期元素清理工作，清理工作主要是有两个方法：expungeStaleEntry()和cleanSomeSlots()。\n接下来查看对应的源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 private void set(ThreadLocal\u0026lt;?\u0026gt; key, Object value) { Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode \u0026amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { ThreadLocal\u0026lt;?\u0026gt; k = e.get(); if (k == key) { e.value = value; return; } if (k == null) { replaceStaleEntry(key, value, i); return; } } tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) \u0026amp;\u0026amp; sz \u0026gt;= threshold) rehash(); } 这里会通过key来计算在散列表中的对应位置，然后以当前key对应的桶的位置向后查找，找到可以使用的桶。\n1 2 3 Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode \u0026amp; (len-1); 什么情况下桶才是可以使用的呢？\nk = key 说明是替换操作，可以使用 碰到一个过期的桶，执行替换逻辑，占用过期桶 查找过程中，碰到桶中Entry=null的情况，直接使用 接着就是执行for循环遍历，向后查找，我们先看下nextIndex()、prevIndex()方法实现：\n1 2 3 4 5 6 7 private static int nextIndex(int i, int len) { return ((i + 1 \u0026lt; len) ? i + 1 : 0); } private static int prevIndex(int i, int len) { return ((i - 1 \u0026gt;= 0) ? i - 1 : len - 1); } 接着看剩下for循环中的逻辑：\n遍历当前key值对应的桶中Entry数据为空，这说明散列数组这里没有数据冲突，跳出for循环，直接set数据到对应的桶中 如果key值对应的桶中Entry数据不为空 如果k = key，说明当前set操作是一个替换操作，做替换逻辑，直接返回 如果key = null，说明当前桶位置的Entry是过期数据，执行replaceStaleEntry()方法(核心方法)，然后返回 for循环执行完毕，继续往下执行说明向后迭代的过程中遇到了entry为null的情况 在Entry为null的桶中创建一个新的Entry对象 执行++size操作 调用cleanSomeSlots()做一次启发式清理工作，清理散列数组中Entry的key过期的数据 4.1 如果清理工作完成后，未清理到任何数据，且size超过了阈值(数组长度的2/3)，进行rehash()操作 4.2 rehash()中会先进行一轮探测式清理，清理过期key，清理完成后如果size \u0026gt;= threshold - threshold / 4，就会执行真正的扩容逻辑(扩容逻辑往后看) 接着重点看下replaceStaleEntry()方法，replaceStaleEntry()方法提供替换过期数据的功能，我们可以对应上面第四种情况的原理图来再回顾下，具体代码如下：\njava.lang.ThreadLocal.ThreadLocalMap.replaceStaleEntry():\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 private void replaceStaleEntry(ThreadLocal\u0026lt;?\u0026gt; key, Object value, int staleSlot) { Entry[] tab = table; int len = tab.length; Entry e; int slotToExpunge = staleSlot; for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) { ThreadLocal\u0026lt;?\u0026gt; k = e.get(); if (k == key) { e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; if (slotToExpunge == staleSlot) slotToExpunge = i; cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; } if (k == null \u0026amp;\u0026amp; slotToExpunge == staleSlot) slotToExpunge = i; } tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); } slotToExpunge表示开始探测式清理过期数据的开始下标，默认从当前的staleSlot开始。以当前的staleSlot开始，向前迭代查找，找到没有过期的数据，for循环一直碰到Entry为null才会结束。如果向前找到了过期数据，更新探测清理过期数据的开始下标为i，即slotToExpunge=i\n1 2 3 4 5 6 7 8 for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)){ if (e.get() == null){ slotToExpunge = i; } } 接着开始从staleSlot向后查找，也是碰到Entry为null的桶结束。 如果迭代过程中，碰到k == key，这说明这里是替换逻辑，替换新数据并且交换当前staleSlot位置。如果slotToExpunge == staleSlot，这说明replaceStaleEntry()一开始向前查找过期数据时并未找到过期的Entry数据，接着向后查找过程中也未发现过期数据，修改开始探测式清理过期数据的下标为当前循环的index，即slotToExpunge = i。最后调用cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);进行启发式过期数据清理。\n1 2 3 4 5 6 7 8 9 10 11 12 if (k == key) { e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; if (slotToExpunge == staleSlot) slotToExpunge = i; cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; } cleanSomeSlots()和expungeStaleEntry()方法后面都会细讲，这两个是和清理相关的方法，一个是过期key相关Entry的启发式清理(Heuristically scan)，另一个是过期key相关Entry的探测式清理。\n如果k != key则会接着往下走，k == null说明当前遍历的Entry是一个过期数据，slotToExpunge == staleSlot说明，一开始的向前查找数据并未找到过期的Entry。如果条件成立，则更新slotToExpunge 为当前位置，这个前提是前驱节点扫描时未发现过期数据。\n1 2 if (k == null \u0026amp;\u0026amp; slotToExpunge == staleSlot) slotToExpunge = i; 往后迭代的过程中如果没有找到k == key的数据，且碰到Entry为null的数据，则结束当前的迭代操作。此时说明这里是一个添加的逻辑，将新的数据添加到table[staleSlot] 对应的slot中。\n1 2 tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); 最后判断除了staleSlot以外，还发现了其他过期的slot数据，就要开启清理数据的逻辑：\n1 2 if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); # ThreadLocalMap过期key的探测式清理流程 上面我们有提及ThreadLocalMap的两种过期key数据清理方式：探测式清理和启发式清理。\n我们先讲下探测式清理，也就是expungeStaleEntry方法，遍历散列数组，从开始位置向后探测清理过期数据，将过期数据的Entry设置为null，沿途中碰到未过期的数据则将此数据rehash后重新在table数组中定位，如果定位的位置已经有了数据，则会将未过期的数据放到最靠近此位置的Entry=null的桶中，使rehash后的Entry数据距离正确的桶的位置更近一些。操作逻辑如下：\n如上图，set(27) 经过hash计算后应该落到index=4的桶中，由于index=4桶已经有了数据，所以往后迭代最终数据放入到index=7的桶中，放入后一段时间后index=5中的Entry数据key变为了null\n如果再有其他数据set到map中，就会触发探测式清理操作。\n如上图，执行探测式清理后，index=5的数据被清理掉，继续往后迭代，到index=7的元素时，经过rehash后发现该元素正确的index=4，而此位置已经已经有了数据，往后查找离index=4最近的Entry=null的节点(刚被探测式清理掉的数据：index=5)，找到后移动index= 7的数据到index=5中，此时桶的位置离正确的位置index=4更近了。\n经过一轮探测式清理后，key过期的数据会被清理掉，没过期的数据经过rehash重定位后所处的桶位置理论上更接近i= key.hashCode \u0026amp; (tab.len - 1)的位置。这种优化会提高整个散列表查询性能。\n接着看下expungeStaleEntry()具体流程，我们还是以先原理图后源码讲解的方式来一步步梳理：\n我们假设expungeStaleEntry(3) 来调用此方法，如上图所示，我们可以看到ThreadLocalMap中table的数据情况，接着执行清理操作：\n第一步是清空当前staleSlot位置的数据，index=3位置的Entry变成了null。然后接着往后探测：\n执行完第二步后，index=4的元素挪到index=3的槽位中。\n继续往后迭代检查，碰到正常数据，计算该数据位置是否偏移，如果被偏移，则重新计算slot位置，目的是让正常数据尽可能存放在正确位置或离正确位置更近的位置\n在往后迭代的过程中碰到空的槽位，终止探测，这样一轮探测式清理工作就完成了，接着我们继续看看具体实现源代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 private int expungeStaleEntry(int staleSlot) { Entry[] tab = table; int len = tab.length; tab[staleSlot].value = null; tab[staleSlot] = null; size--; Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) { ThreadLocal\u0026lt;?\u0026gt; k = e.get(); if (k == null) { e.value = null; tab[i] = null; size--; } else { int h = k.threadLocalHashCode \u0026amp; (len - 1); if (h != i) { tab[i] = null; while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; } } } return i; } 这里我们还是以staleSlot=3 来做示例说明，首先是将tab[staleSlot]槽位的数据清空，然后设置size-- 接着以staleSlot位置往后迭代，如果遇到k==null的过期数据，也是清空该槽位数据，然后size--\n1 2 3 4 5 6 7 ThreadLocal\u0026lt;?\u0026gt; k = e.get(); if (k == null) { e.value = null; tab[i] = null; size--; } 如果key没有过期，重新计算当前key的下标位置是不是当前槽位下标位置，如果不是，那么说明产生了hash冲突，此时以新计算出来正确的槽位位置往后迭代，找到最近一个可以存放entry的位置。\n1 2 3 4 5 6 7 8 9 int h = k.threadLocalHashCode \u0026amp; (len - 1); if (h != i) { tab[i] = null; while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; } 这里是处理正常的产生Hash冲突的数据，经过迭代后，有过Hash冲突数据的Entry位置会更靠近正确位置，这样的话，查询的时候 效率才会更高。\n# ThreadLocalMap扩容机制 在ThreadLocalMap.set()方法的最后，如果执行完启发式清理工作后，未清理到任何数据，且当前散列数组中Entry的数量已经达到了列表的扩容阈值(len*2/3)，就开始执行rehash()逻辑：\n1 2 if (!cleanSomeSlots(i, sz) \u0026amp;\u0026amp; sz \u0026gt;= threshold) rehash(); 接着看下rehash()具体实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 private void rehash() { expungeStaleEntries(); if (size \u0026gt;= threshold - threshold / 4) resize(); } private void expungeStaleEntries() { Entry[] tab = table; int len = tab.length; for (int j = 0; j \u0026lt; len; j++) { Entry e = tab[j]; if (e != null \u0026amp;\u0026amp; e.get() == null) expungeStaleEntry(j); } } 这里首先是会进行探测式清理工作，从table的起始位置往后清理，上面有分析清理的详细流程。清理完成之后，table中可能有一些key为null的Entry数据被清理掉，所以此时通过判断size \u0026gt;= threshold - threshold / 4 也就是size \u0026gt;= threshold* 3/4 来决定是否扩容。\n我们还记得上面进行rehash()的阈值是size \u0026gt;= threshold，所以当面试官套路我们ThreadLocalMap扩容机制的时候 我们一定要说清楚这两个步骤：\n接着看看具体的resize()方法，为了方便演示，我们以oldTab.len=8来举例：\n扩容后的tab的大小为oldLen * 2，然后遍历老的散列表，重新计算hash位置，然后放到新的tab数组中，如果出现hash冲突则往后寻找最近的entry为null的槽位，遍历完成之后，oldTab中所有的entry数据都已经放入到新的tab中了。重新计算tab下次扩容的阈值，具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 private void resize() { Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; for (int j = 0; j \u0026lt; oldLen; ++j) { Entry e = oldTab[j]; if (e != null) { ThreadLocal\u0026lt;?\u0026gt; k = e.get(); if (k == null) { e.value = null; } else { int h = k.threadLocalHashCode \u0026amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; } } } setThreshold(newLen); size = count; table = newTab; } # ThreadLocalMap.get()详解 上面已经看完了set()方法的源码，其中包括set数据、清理数据、优化数据桶的位置等操作，接着看看get()操作的原理。\n# ThreadLocalMap.get()图解 第一种情况： 通过查找key值计算出散列表中slot位置，然后该slot位置中的Entry.key和查找的key一致，则直接返回：\n第二种情况： slot位置中的Entry.key和要查找的key不一致：\n我们以get(ThreadLocal1)为例，通过hash计算后，正确的slot位置应该是4，而index=4的槽位已经有了数据，且key值不等于ThreadLocal1，所以需要继续往后迭代查找。\n迭代到index=5的数据时，此时Entry.key=null，触发一次探测式数据回收操作，执行expungeStaleEntry()方法，执行完后，index 5,8的数据都会被回收，而index 6,7的数据都会前移，此时继续往后迭代，到index = 6的时候即找到了key值相等的Entry数据，如下图所示：\n# ThreadLocalMap.get()源码详解 java.lang.ThreadLocal.ThreadLocalMap.getEntry():\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 java复制代码private Entry getEntry(ThreadLocal\u0026lt;?\u0026gt; key) { int i = key.threadLocalHashCode \u0026amp; (table.length - 1); Entry e = table[i]; if (e != null \u0026amp;\u0026amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e); } private Entry getEntryAfterMiss(ThreadLocal\u0026lt;?\u0026gt; key, int i, Entry e) { Entry[] tab = table; int len = tab.length; while (e != null) { ThreadLocal\u0026lt;?\u0026gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; } return null; } # ThreadLocalMap过期key的启发式清理流程 上面多次提及到ThreadLocalMap过期可以的两种清理方式：探测式清理(expungeStaleEntry())、启发式清理(cleanSomeSlots())\n探测式清理是以当前Entry 往后清理，遇到值为null则结束清理，属于线性探测清理。\n而启发式清理被作者定义为：Heuristically scan some cells looking for stale entries.\n具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 private boolean cleanSomeSlots(int i, int n) { boolean removed = false; Entry[] tab = table; int len = tab.length; do { i = nextIndex(i, len); Entry e = tab[i]; if (e != null \u0026amp;\u0026amp; e.get() == null) { n = len; removed = true; i = expungeStaleEntry(i); } } while ( (n \u0026gt;\u0026gt;\u0026gt;= 1) != 0); return removed; } # InheritableThreadLocal 我们使用ThreadLocal的时候，在异步场景下是无法给子线程共享父线程中创建的线程副本数据的。\n为了解决这个问题，JDK中还有一个InheritableThreadLocal类，我们来看一个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class InheritableThreadLocalDemo { public static void main(String[] args) { ThreadLocal\u0026lt;String\u0026gt; threadLocal = new ThreadLocal\u0026lt;\u0026gt;(); ThreadLocal\u0026lt;String\u0026gt; inheritableThreadLocal = new InheritableThreadLocal\u0026lt;\u0026gt;(); threadLocal.set(\u0026#34;父类数据:threadLocal\u0026#34;); inheritableThreadLocal.set(\u0026#34;父类数据:inheritableThreadLocal\u0026#34;); new Thread(new Runnable() { @Override public void run() { System.out.println(\u0026#34;子线程获取父类threadLocal数据：\u0026#34; + threadLocal.get()); System.out.println(\u0026#34;子线程获取父类inheritableThreadLocal数据：\u0026#34; + inheritableThreadLocal.get()); } }).start(); } } 打印结果：\n1 2 java复制代码子线程获取父类threadLocal数据：null 子线程获取父类inheritableThreadLocal数据：父类数据:inheritableThreadLocal 实现原理是子线程是通过在父线程中通过调用new Thread()方法来创建子线程，Thread#init方法在Thread的构造方法中被调用。在init方法中拷贝父线程数据到子线程中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) { if (name == null) { throw new NullPointerException(\u0026#34;name cannot be null\u0026#34;); } if (inheritThreadLocals \u0026amp;\u0026amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); this.stackSize = stackSize; tid = nextThreadID(); } 但InheritableThreadLocal仍然有缺陷，一般我们做异步化处理都是使用的线程池，而InheritableThreadLocal是在new Thread中的init()方法给赋值的，而线程池是线程复用的逻辑，所以这里会存在问题。\n当然，有问题出现就会有解决问题的方案，阿里巴巴开源了一个TransmittableThreadLocal组件就可以解决这个问题，这里就不再延伸，感兴趣的可自行查阅资料。\n# ThreadLocal项目中使用实战 # ThreadLocal使用场景 我们现在项目中日志记录用的是ELK+Logstash，最后在Kibana中进行展示和检索。\n现在都是分布式系统统一对外提供服务，项目间调用的关系可以通过traceId来关联，但是不同项目之间如何传递traceId呢？\n这里我们使用org.slf4j.MDC来实现此功能，内部就是通过ThreadLocal来实现的，具体实现如下：\n当前端发送请求到服务A时，服务A会生成一个类似UUID的traceId字符串，将此字符串放入当前线程的ThreadLocal中，在调用服务B的时候，将traceId写入到请求的Header中，服务B在接收请求时会先判断请求的Header中是否有traceId，如果存在则写入自己线程的ThreadLocal中。\n图中的requestId即为我们各个系统链路关联的traceId，系统间互相调用，通过这个requestId即可找到对应链路，这里还有会有一些其他场景：\n针对于这些场景，我们都可以有相应的解决方案，如下所示\n# Feign远程调用解决方案 服务发送请求：\n1 2 3 4 5 6 7 8 9 10 11 12 @Component @Slf4j public class FeignInvokeInterceptor implements RequestInterceptor { @Override public void apply(RequestTemplate template) { String requestId = MDC.get(\u0026#34;requestId\u0026#34;); if (StringUtils.isNotBlank(requestId)) { template.header(\u0026#34;requestId\u0026#34;, requestId); } } } 服务接收请求：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @Slf4j @Component public class LogInterceptor extends HandlerInterceptorAdapter { @Override public void afterCompletion(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, Exception arg3) { MDC.remove(\u0026#34;requestId\u0026#34;); } @Override public void postHandle(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, ModelAndView arg3) { } @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { String requestId = request.getHeader(BaseConstant.REQUEST_ID_KEY); if (StringUtils.isBlank(requestId)) { requestId = UUID.randomUUID().toString().replace(\u0026#34;-\u0026#34;, \u0026#34;\u0026#34;); } MDC.put(\u0026#34;requestId\u0026#34;, requestId); return true; } } # 线程池异步调用，requestId传递 因为MDC是基于ThreadLocal去实现的，异步过程中，子线程并没有办法获取到父线程ThreadLocal存储的数据，所以这里可以自定义线程池执行器，修改其中的run()方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class MyThreadPoolTaskExecutor extends ThreadPoolTaskExecutor { @Override public void execute(Runnable runnable) { Map\u0026lt;String, String\u0026gt; context = MDC.getCopyOfContextMap(); super.execute(() -\u0026gt; run(runnable, context)); } @Override private void run(Runnable runnable, Map\u0026lt;String, String\u0026gt; context) { if (context != null) { MDC.setContextMap(context); } try { runnable.run(); } finally { MDC.remove(); } } } # 使用MQ发送消息给第三方系统 在MQ发送的消息体中自定义属性requestId，接收方消费消息后，自己解析requestId使用即可。\n# 总结 这个请看参考 刚开始添加了自己的理解 后面完全懵了 直接抄\n其实谁到底，就是set、get、扩容的设置\nset的四种情况\n从此引出探测是清理\n然后明白如何散列\n然后明白对应的set方法\n然后明白对应的应用\n# 参考 https://juejin.cn/post/6844904151567040519 ","date":"2023-09-26T11:07:07+08:00","permalink":"https://runqizhao.cn/p/threadlocal/","title":"Threadlocal"},{"content":" # 项目介绍 Apache ShenYu 是一个 高性能，多协议，易扩展，响应式的API网关\n兼容各种主流框架体系，支持热插拔，用户可以定制化开发，满足用户各种场景的现状和未来需求，经历过大规模场景的锤炼\nShenYu 官网\nGithub 地址\n# 同步什么信息，有几种方式 在ShenYu网关中，数据同步是指，当在后台管理系统中，数据发送了更新后，如何将更新的数据同步到网关中。Apache ShenYu 网关当前支持ZooKeeper、WebSocket、Http长轮询、Nacos 、etcd 和 Consul 进行数据同步。\n在最初的版本中，配置服务依赖 Zookeeper 实现，管理后台将变更信息 push 给网关。而现在可以支持 WebSocket、Http长轮询、Zookeeper、Nacos、Etcd 和 Consul，通过在配置文件中设置 shenyu.sync.${strategy} 指定对应的同步策略，默认使用 WebSocket 同步策略，可以做到秒级数据同步。但是，有一点需要注意的是，Apache ShenYu网关 和 shenyu-admin 必须使用相同的同步策略。\n如下图所示，shenyu-admin 在用户发生配置变更之后，会通过 EventPublisher 发出配置变更通知，由 EventDispatcher 处理该变更通知，然后根据配置的同步策略(Http、WebSocket、Zookeeper、Nacos、Etcd、Consul)，将配置发送给对应的事件处理器。\n如果是 WebSocket 同步策略，则将变更后的数据主动推送给 shenyu-web，并且在网关层，会有对应的 WebsocketDataHandler 处理器来处理 shenyu-admin 的数据推送。 如果是 Zookeeper 同步策略，将变更数据更新到 Zookeeper，而 ZookeeperSyncCache 会监听到 Zookeeper 的数据变更，并予以处理。 如果是 Http 同步策略，由网关主动发起长轮询请求，默认有 90s 超时时间，如果 shenyu-admin 没有数据变更，则会阻塞 Http 请求，如果有数据发生变更则响应变更的数据信息，如果超过 60s 仍然没有数据变更则响应空数据，网关层接到响应后，继续发起 Http 请求，反复同样的请求。 本文以WebSocket为例，从源码角度出发说明同步的具体过程。\n# 什么是webscoket WebSocket协议诞生于2008年，在2011年成为国际标准。它可以双向通信，服务器可以主动向客户端推送信息，客户端也可以主动向服务器发送信息。WebSocket协议建立在 TCP 协议之上，属于应用层，性能开销小，通信高效，协议标识符是ws。\n# Admin数据同步 通过一个实际案例，说明数据同步的过程：\n# 接收数据 SelectorController.createSelector()\n进入SelectorController类中的createSelector()方法，它负责数据的校验，添加或更新数据，返回结果信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Validated @RestController @RequestMapping(\u0026#34;/selector\u0026#34;) public class SelectorController implements PagedController\u0026lt;SelectorQueryCondition, SelectorVO\u0026gt; { private final SelectorService selectorService; /** * create selector. * * @param selectorDTO selector. * @return {@linkplain ShenyuAdminResult} */ @PostMapping(\u0026#34;\u0026#34;) public ShenyuAdminResult createSelector(@Valid @RequestBody final SelectorDTO selectorDTO) { // 添加或更新数据 Integer createCount = selectorService.createOrUpdate(selectorDTO); // 返回结果信息 return ShenyuAdminResult.success(ShenyuResultMessage.CREATE_SUCCESS, createCount); } } # 处理数据 在SelectorServiceImpl类中通过createOrUpdate()方法完成数据的转换，保存到数据库，发布事件，更新upstream。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 default int createOrUpdate(SelectorDTO selectorDTO) { //条件判断 if (Objects.equals(SelectorTypeEnum.CUSTOM_FLOW.getCode(), selectorDTO.getType())) { Assert.notNull(selectorDTO.getMatchMode(), \u0026#34;if type is custom, matchMode is not null\u0026#34;); Assert.notEmpty(selectorDTO.getSelectorConditions(), \u0026#34;if type is custom, selectorConditions is not empty\u0026#34;); selectorDTO.getSelectorConditions().forEach(selectorConditionDTO -\u0026gt; { Assert.notBlack(selectorConditionDTO.getParamType(), \u0026#34;if type is custom, paramType is not empty\u0026#34;); Assert.notBlack(selectorConditionDTO.getParamName(), \u0026#34;if type is custom, paramName is not empty\u0026#34;); Assert.notBlack(selectorConditionDTO.getParamValue(), \u0026#34;if type is custom, paramValue is not empty\u0026#34;); }); } //判断是否存在这个Selector，存在则进行更新，不存在则创建 return StringUtils.isEmpty(selectorDTO.getId()) ? create(selectorDTO) : update(selectorDTO); } 下面看看对应的create()与update()方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @Override public int create(final SelectorDTO selectorDTO) { // 构建数据 DTO --\u0026gt; DO SelectorDO selectorDO = SelectorDO.buildSelectorDO(selectorDTO); // 插入选择器数据 final int selectorCount = selectorMapper.insertSelective(selectorDO); // 插入选择器中的条件数据 createCondition(selectorDO.getId(), selectorDTO.getSelectorConditions()); // 发布事件 publishEvent(selectorDO, selectorDTO.getSelectorConditions(), Collections.emptyList()); // 更新upstream if (selectorCount \u0026gt; 0) { selectorEventPublisher.onCreated(selectorDO); } return selectorCount; } private void createCondition(final String selectorId, final List\u0026lt;SelectorConditionDTO\u0026gt; selectorConditions) { for (SelectorConditionDTO condition : selectorConditions) { condition.setSelectorId(selectorId); selectorConditionMapper.insertSelective(SelectorConditionDO.buildSelectorConditionDO(condition)); } } @Override public void onCreated(final SelectorDO selector) { publish(new SelectorCreatedEvent(selector, SessionUtil.visitorName())); } public int update(final SelectorDTO selectorDTO) { //构建更新数据 final SelectorDO before = selectorMapper.selectById(selectorDTO.getId()); SelectorDO selectorDO = SelectorDO.buildSelectorDO(selectorDTO); final int selectorCount = selectorMapper.updateSelective(selectorDO); // need old data for cleaning List\u0026lt;SelectorConditionDO\u0026gt; beforeSelectorConditionList = selectorConditionMapper.selectByQuery(new SelectorConditionQuery(selectorDO.getId())); List\u0026lt;RuleConditionDTO\u0026gt; beforeCondition = beforeSelectorConditionList.stream().map(selectorConditionDO -\u0026gt; SelectorConditionDTO.builder() .selectorId(selectorConditionDO.getSelectorId()) .operator(selectorConditionDO.getOperator()) .paramName(selectorConditionDO.getParamName()) .paramType(selectorConditionDO.getParamType()) .paramValue(selectorConditionDO.getParamValue()) .build()).collect(Collectors.toList()); List\u0026lt;RuleConditionDTO\u0026gt; currentCondition = selectorDTO.getSelectorConditions().stream().map(selectorConditionDTO -\u0026gt; SelectorConditionDTO.builder() .selectorId(selectorConditionDTO.getSelectorId()) .operator(selectorConditionDTO.getOperator()) .paramName(selectorConditionDTO.getParamName()) .paramType(selectorConditionDTO.getParamType()) .paramValue(selectorConditionDTO.getParamValue()) .build()).collect(Collectors.toList()); if (CollectionUtils.isEqualCollection(beforeCondition, currentCondition)) { beforeSelectorConditionList = Collections.emptyList(); } //delete rule condition then add // 更新数据，先删除再新增 selectorConditionMapper.deleteByQuery(new SelectorConditionQuery(selectorDO.getId())); createCondition(selectorDO.getId(), selectorDTO.getSelectorConditions()); // 发布事件 publishEvent(selectorDO, selectorDTO.getSelectorConditions(), beforeSelectorConditionList); if (selectorCount \u0026gt; 0) { selectorEventPublisher.onUpdated(selectorDO, before); } return selectorCount; } @Override public void onUpdated(final SelectorDO selector, final SelectorDO before) { publish(new SelectorUpdatedEvent(selector, before, SessionUtil.visitorName())); } publishEvent()方法的逻辑是：找到选择器对应的插件，构建条件数据，发布变更数据。\n1 2 3 4 5 6 7 8 9 10 11 12 13 private void publishEvent(final SelectorDO selectorDO, final List\u0026lt;SelectorConditionDTO\u0026gt; selectorConditions, final List\u0026lt;SelectorConditionDO\u0026gt; beforeSelectorCondition) { // 找到选择器对应的插件 PluginDO pluginDO = pluginMapper.selectById(selectorDO.getPluginId()); // 构建条件数据 List\u0026lt;ConditionData\u0026gt; conditionDataList = ListUtil.map(selectorConditions, ConditionTransfer.INSTANCE::mapToSelectorDTO); List\u0026lt;ConditionData\u0026gt; beforeConditionDataList = ListUtil.map(beforeSelectorCondition, ConditionTransfer.INSTANCE::mapToSelectorDO); // build selector data. SelectorData selectorData = SelectorDO.transFrom(selectorDO, pluginDO.getName(), conditionDataList, beforeConditionDataList); // publish change event. // 发布变更数据 eventPublisher.publishEvent(new DataChangedEvent(ConfigGroupEnum.SELECTOR, DataEventTypeEnum.UPDATE, Collections.singletonList(selectorData))); } 发布变更数据通过eventPublisher.publishEvent()完成，这个eventPublisher对象是一个ApplicationEventPublisher类，这个类的全限定名是org.springframework.context.ApplicationEventPublisher。看到这儿，我们知道了发布数据是通过Spring相关的功能来完成的。\n关于ApplicationEventPublisher：\n当有状态发生变化时，发布者调用 ApplicationEventPublisher 的 publishEvent 方法发布一个事件，Spring容器广播事件给所有观察者，调用观察者的 onApplicationEvent 方法把事件对象传递给观察者。调用 publishEvent方法有两种途径，一种是实现接口由容器注入 ApplicationEventPublisher 对象然后调用其方法，另一种是直接调用容器的方法，两种方法发布事件没有太大区别。\nApplicationEventPublisher：发布事件； ApplicationEvent：Spring 事件，记录事件源、时间和数据； ApplicationListener：事件监听者，观察者。 在Spring的事件发布机制中，有三个对象，\n一个是发布事件的ApplicationEventPublisher，在ShenYu中通过构造器注入了一个eventPublisher。\n另一个对象是ApplicationEvent，在ShenYu中通过DataChangedEvent继承了它，表示事件对象。\n1 2 3 public class DataChangedEvent extends ApplicationEvent { //...... } 最后一个是 ApplicationListener，在ShenYu中通过DataChangedEventDispatcher类实现了该接口，作为事件的监听者，负责处理事件对象。\n1 2 3 4 @Component public class DataChangedEventDispatcher implements ApplicationListener\u0026lt;DataChangedEvent\u0026gt;, InitializingBean { //...... } # 分发数据 DataChangedEventDispatcher.onApplicationEvent()\n当事件发布完成后，会自动进入到DataChangedEventDispatcher类中的onApplicationEvent()方法，进行事件处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @Component public class DataChangedEventDispatcher implements ApplicationListener\u0026lt;DataChangedEvent\u0026gt;, InitializingBean { /** * 有数据变更时，调用此方法 * @param event */ @Override @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public void onApplicationEvent(final DataChangedEvent event) { // 遍历数据变更监听器(一般使用一种数据同步的方式就好了) for (DataChangedListener listener : listeners) { // 哪种数据发生变更 switch (event.getGroupKey()) { case APP_AUTH: // 认证信息 listener.onAppAuthChanged((List\u0026lt;AppAuthData\u0026gt;) event.getSource(), event.getEventType()); break; case PLUGIN: // 插件信息 listener.onPluginChanged((List\u0026lt;PluginData\u0026gt;) event.getSource(), event.getEventType()); break; case RULE: // 规则信息 listener.onRuleChanged((List\u0026lt;RuleData\u0026gt;) event.getSource(), event.getEventType()); break; case SELECTOR: // 选择器信息 listener.onSelectorChanged((List\u0026lt;SelectorData\u0026gt;) event.getSource(), event.getEventType()); break; case META_DATA: // 元数据 listener.onMetaDataChanged((List\u0026lt;MetaData\u0026gt;) event.getSource(), event.getEventType()); break; default: // 其他类型，抛出异常 throw new IllegalStateException(\u0026#34;Unexpected value: \u0026#34; + event.getGroupKey()); } } } } 当有数据变更时，调用onApplicationEvent方法，然后遍历所有数据变更监听器，判断是哪种数据类型，交给相应的数据监听器进行处理。\nShenYu将所有数据进行了分组，一共是五种：认证信息、插件信息、规则信息、选择器信息和元数据。\n这里的数据变更监听器（DataChangedListener），就是数据同步策略的抽象，它的具体实现有：\n这几个实现类就是当前ShenYu支持的同步策略：\nWebsocketDataChangedListener：基于websocket的数据同步； ZookeeperDataChangedListener：基于zookeeper的数据同步； ConsulDataChangedListener：基于consul的数据同步； EtcdDataDataChangedListener：基于etcd的数据同步； HttpLongPollingDataChangedListener：基于http长轮询的数据同步； NacosDataChangedListener：基于nacos的数据同步； 既然有这么多种实现策略，那么如何确定使用哪一种呢？\n因为本文是基于websocket的数据同步源码分析，所以这里以WebsocketDataChangedListener为例，分析它是如何被加载并实现的。\n通过在源码工程中进行全局搜索，可以看到，它的实现是在DataSyncConfiguration类完成的。\n今天先到这 明天继续\n这个系列确实值得好好学习一下 很多细节值得推敲。\n# 总结 本文主要分析了Apache Shenyu的服务调用过程。\n本系列是自己对shenyu进行学习的系列，参考了许多博客以及官网上面的内容，完全是班门弄斧，放在自己的博客上面，如果存在错误或者侵权，请在下面评论。\n# 参考 https://shenyu.apache.org/zh/docs/design/data-sync/ https://shenyu.apache.org/zh/blog/DataSync-SourceCode-Analysis-WebSocket-Data-Sync/#1-%E5%85%B3%E4%BA%8Ewebsocket%E9%80%9A%E4%BF%A1 ","date":"2023-09-23T18:59:19+08:00","image":"https://shenyu.apache.org/zh/img/logo.svg","permalink":"https://runqizhao.cn/p/%E6%9C%8D%E5%8A%A1%E5%90%8C%E6%AD%A5/","title":"服务同步"},{"content":" # 项目介绍 Apache ShenYu 是一个 高性能，多协议，易扩展，响应式的API网关\n兼容各种主流框架体系，支持热插拔，用户可以定制化开发，满足用户各种场景的现状和未来需求，经历过大规模场景的锤炼\nShenYu 官网\nGithub 地址\n# 服务调用 本文仍然采用http插件为例，一个直连请求如下：\n1 2 GET http://localhost:8189/order/findById?id=100 Accept: application/json 经过Shenyu网关之后，请求如下：\n1 2 GET http://localhost:9195/http/order/findById?id=100 Accept: application/json 通过Shenyu网关代理后的服务能够请求到之前的服务，在这里起作用的就是divide插件。类继承关系如下：\nShenyuPlugin：顶层接口，定义接口方法； AbstractShenyuPlugin：抽象类，实现插件共有逻辑； DividePlugin：Divide插件。 # 请求接收 通过Shenyu网关代理后，请求入口是ShenyuWebHandler，它实现了org.springframework.web.server.WebHandler\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 public final class ShenyuWebHandler implements WebHandler, ApplicationListener\u0026lt;SortPluginEvent\u0026gt; { //...... /** * 处理web请求 */ @Override public Mono\u0026lt;Void\u0026gt; handle(@NonNull final ServerWebExchange exchange) { // 执行默认插件链 Mono\u0026lt;Void\u0026gt; execute = new DefaultShenyuPluginChain(plugins).execute(exchange); if (scheduled) { return execute.subscribeOn(scheduler); } return execute; } private static class DefaultShenyuPluginChain implements ShenyuPluginChain { private int index; private final List\u0026lt;ShenyuPlugin\u0026gt; plugins; /** * Instantiates a new Default shenyu plugin chain. * * @param plugins the plugins */ //实例化默认插件链 DefaultShenyuPluginChain(final List\u0026lt;ShenyuPlugin\u0026gt; plugins) { this.plugins = plugins; } /** * Delegate to the next {@code WebFilter} in the chain. * * @param exchange the current server exchange * @return {@code Mono\u0026lt;Void\u0026gt;} to indicate when request handling is complete */ //执行每个插件 @Override public Mono\u0026lt;Void\u0026gt; execute(final ServerWebExchange exchange) { return Mono.defer(() -\u0026gt; { if (this.index \u0026lt; plugins.size()) { //获取当前执行插件 ShenyuPlugin plugin = plugins.get(this.index++); //是否跳过当前插件 boolean skip = plugin.skip(exchange); if (skip) { //如果跳过就执行下一个 return this.execute(exchange); } //执行当前插件 return plugin.execute(exchange, this); } return Mono.empty(); }); } } } 这里顺便说一嘴，shenyu-ingerss-controller的目的就是启用插件，将对应的selectordata、ruledata以及metadata进行传入，直接到达请求接收这里，不需要使用服务注册等内容。\n# 规则匹配 org.apache.shenyu.plugin.base.AbstractShenyuPlugin#execute()\n在execute()方法中执行选择器和规则的匹配逻辑。\n匹配选择器； 匹配规则； 执行插件。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 @Override public Mono\u0026lt;Void\u0026gt; execute(final ServerWebExchange exchange, final ShenyuPluginChain chain) { // 插件名称 String pluginName = named(); // 插件信息 PluginData pluginData = BaseDataCache.getInstance().obtainPluginData(pluginName); if (pluginData != null \u0026amp;\u0026amp; pluginData.getEnabled()) { // 选择器信息 final Collection\u0026lt;SelectorData\u0026gt; selectors = BaseDataCache.getInstance().obtainSelectorData(pluginName); if (CollectionUtils.isEmpty(selectors)) { return handleSelectorIfNull(pluginName, exchange, chain); } // 匹配选择器 SelectorData selectorData = matchSelector(exchange, selectors); if (Objects.isNull(selectorData)) { return handleSelectorIfNull(pluginName, exchange, chain); } selectorLog(selectorData, pluginName); // 规则信息 List\u0026lt;RuleData\u0026gt; rules = BaseDataCache.getInstance().obtainRuleData(selectorData.getId()); if (CollectionUtils.isEmpty(rules)) { return handleRuleIfNull(pluginName, exchange, chain); } // 匹配规则 RuleData rule; if (selectorData.getType() == SelectorTypeEnum.FULL_FLOW.getCode()) { //get last rule = rules.get(rules.size() - 1); } else { rule = matchRule(exchange, rules); } if (Objects.isNull(rule)) { return handleRuleIfNull(pluginName, exchange, chain); } ruleLog(rule, pluginName); // 执行插件 return doExecute(exchange, chain, selectorData, rule); } return chain.execute(exchange); } # 执行divide插件 org.apache.shenyu.plugin.divide.DividePlugin#doExecute()\n在doExecute()方法中执行divide插件的具体逻辑：\n校验header大小； 校验request大小； 获取服务列表； 实现负载均衡； 设置请求url，超时时间，重试策略。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 @Override protected Mono\u0026lt;Void\u0026gt; doExecute(final ServerWebExchange exchange, final ShenyuPluginChain chain, final SelectorData selector, final RuleData rule) { // 获取上下文信息 ShenyuContext shenyuContext = exchange.getAttribute(Constants.CONTEXT); assert shenyuContext != null; // 获取规则的handle属性 DivideRuleHandle ruleHandle = DividePluginDataHandler.CACHED_HANDLE.get().obtainHandle(CacheKeyUtils.INST.getKey(rule)); long headerSize = 0; // 校验header大小 for (List\u0026lt;String\u0026gt; multiHeader : exchange.getRequest().getHeaders().values()) { for (String value : multiHeader) { headerSize += value.getBytes(StandardCharsets.UTF_8).length; } } if (headerSize \u0026gt; ruleHandle.getHeaderMaxSize()) { LOG.error(\u0026#34;request header is too large\u0026#34;); Object error = ShenyuResultWrap.error(exchange, ShenyuResultEnum.REQUEST_HEADER_TOO_LARGE, null); return WebFluxResultUtils.result(exchange, error); } // 校验request大小 if (exchange.getRequest().getHeaders().getContentLength() \u0026gt; ruleHandle.getRequestMaxSize()) { LOG.error(\u0026#34;request entity is too large\u0026#34;); Object error = ShenyuResultWrap.error(exchange, ShenyuResultEnum.REQUEST_ENTITY_TOO_LARGE, null); return WebFluxResultUtils.result(exchange, error); } // 获取服务列表upstreamList List\u0026lt;Upstream\u0026gt; upstreamList = UpstreamCacheManager.getInstance().findUpstreamListBySelectorId(selector.getId()); if (CollectionUtils.isEmpty(upstreamList)) { LOG.error(\u0026#34;divide upstream configuration error： {}\u0026#34;, rule); Object error = ShenyuResultWrap.error(exchange, ShenyuResultEnum.CANNOT_FIND_HEALTHY_UPSTREAM_URL, null); return WebFluxResultUtils.result(exchange, error); } // 请求ip String ip = Objects.requireNonNull(exchange.getRequest().getRemoteAddress()).getAddress().getHostAddress(); // 实现负载均衡 Upstream upstream = LoadBalancerFactory.selector(upstreamList, ruleHandle.getLoadBalance(), ip); if (Objects.isNull(upstream)) { LOG.error(\u0026#34;divide has no upstream\u0026#34;); Object error = ShenyuResultWrap.error(exchange, ShenyuResultEnum.CANNOT_FIND_HEALTHY_UPSTREAM_URL, null); return WebFluxResultUtils.result(exchange, error); } // 设置url String domain = upstream.buildDomain(); exchange.getAttributes().put(Constants.HTTP_DOMAIN, domain); // 设置超时时间 exchange.getAttributes().put(Constants.HTTP_TIME_OUT, ruleHandle.getTimeout()); exchange.getAttributes().put(Constants.HTTP_RETRY, ruleHandle.getRetry()); // 设置重试策略 exchange.getAttributes().put(Constants.RETRY_STRATEGY, ruleHandle.getRetryStrategy()); exchange.getAttributes().put(Constants.LOAD_BALANCE, ruleHandle.getLoadBalance()); exchange.getAttributes().put(Constants.DIVIDE_SELECTOR_ID, selector.getId()); return chain.execute(exchange); } 这里说一句，dubbo插件这个内容一定要进行查看，dubbo插件这里面还是有点东西的，顺便还能学习一下dubbo。\n# 发起请求 默认由WebClientPlugin向http服务发起调用请求，类继承关系如下：\nShenyuPlugin：顶层插件，定义插件方法； AbstractHttpClientPlugin：抽象类，实现请求调用的公共逻辑； WebClientPlugin：通过WebClient发起请求； NettyHttpClientPlugin：通过Netty发起请求。 发起请求调用：\norg.apache.shenyu.plugin.httpclient.AbstractHttpClientPlugin#execute()\n在execute()方法中发起请求调用：\n获取指定的超时时间，重试次数 发起请求 根据指定的重试策略进行失败后重试操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 public abstract class AbstractHttpClientPlugin\u0026lt;R\u0026gt; implements ShenyuPlugin { protected static final Logger LOG = LoggerFactory.getLogger(AbstractHttpClientPlugin.class); @Override public final Mono\u0026lt;Void\u0026gt; execute(final ServerWebExchange exchange, final ShenyuPluginChain chain) { // 获取上下文信息 final ShenyuContext shenyuContext = exchange.getAttribute(Constants.CONTEXT); assert shenyuContext != null; // 获取uri final URI uri = exchange.getAttribute(Constants.HTTP_URI); if (Objects.isNull(uri)) { Object error = ShenyuResultWrap.error(exchange, ShenyuResultEnum.CANNOT_FIND_URL, null); return WebFluxResultUtils.result(exchange, error); } // 获取指定的超时时间 final long timeout = (long) Optional.ofNullable(exchange.getAttribute(Constants.HTTP_TIME_OUT)).orElse(3000L); final Duration duration = Duration.ofMillis(timeout); // 获取指定重试次数 final int retryTimes = (int) Optional.ofNullable(exchange.getAttribute(Constants.HTTP_RETRY)).orElse(0); // 获取指定的重试策略 final String retryStrategy = (String) Optional.ofNullable(exchange.getAttribute(Constants.RETRY_STRATEGY)).orElseGet(RetryEnum.CURRENT::getName); LOG.info(\u0026#34;The request urlPath is {}, retryTimes is {}, retryStrategy is {}\u0026#34;, uri.toASCIIString(), retryTimes, retryStrategy); // 构建header final HttpHeaders httpHeaders = buildHttpHeaders(exchange); // 发起请求 final Mono\u0026lt;R\u0026gt; response = doRequest(exchange, exchange.getRequest().getMethodValue(), uri, httpHeaders, exchange.getRequest().getBody()) .timeout(duration, Mono.error(new TimeoutException(\u0026#34;Response took longer than timeout: \u0026#34; + duration))) .doOnError(e -\u0026gt; LOG.error(e.getMessage(), e)); // 重试策略CURRENT，对当前服务进行重试 if (RetryEnum.CURRENT.getName().equals(retryStrategy)) { //old version of DividePlugin and SpringCloudPlugin will run on this return response.retryWhen(Retry.anyOf(TimeoutException.class, ConnectTimeoutException.class, ReadTimeoutException.class, IllegalStateException.class) .retryMax(retryTimes) .backoff(Backoff.exponential(Duration.ofMillis(200), Duration.ofSeconds(20), 2, true))) .onErrorMap(TimeoutException.class, th -\u0026gt; new ResponseStatusException(HttpStatus.GATEWAY_TIMEOUT, th.getMessage(), th)) .flatMap((Function\u0026lt;Object, Mono\u0026lt;? extends Void\u0026gt;\u0026gt;) o -\u0026gt; chain.execute(exchange)); } // 对其他服务进行重试 // 排除已经调用过的服务 final Set\u0026lt;URI\u0026gt; exclude = Sets.newHashSet(uri); // 请求重试 return resend(response, exchange, duration, httpHeaders, exclude, retryTimes) .onErrorMap(TimeoutException.class, th -\u0026gt; new ResponseStatusException(HttpStatus.GATEWAY_TIMEOUT, th.getMessage(), th)) .flatMap((Function\u0026lt;Object, Mono\u0026lt;? extends Void\u0026gt;\u0026gt;) o -\u0026gt; chain.execute(exchange)); } private Mono\u0026lt;R\u0026gt; resend(final Mono\u0026lt;R\u0026gt; clientResponse, final ServerWebExchange exchange, final Duration duration, final HttpHeaders httpHeaders, final Set\u0026lt;URI\u0026gt; exclude, final int retryTimes) { Mono\u0026lt;R\u0026gt; result = clientResponse; // 根据指定的重试次数进行重试 for (int i = 0; i \u0026lt; retryTimes; i++) { result = resend(result, exchange, duration, httpHeaders, exclude); } return result; } private Mono\u0026lt;R\u0026gt; resend(final Mono\u0026lt;R\u0026gt; response, final ServerWebExchange exchange, final Duration duration, final HttpHeaders httpHeaders, final Set\u0026lt;URI\u0026gt; exclude) { return response.onErrorResume(th -\u0026gt; { final String selectorId = exchange.getAttribute(Constants.DIVIDE_SELECTOR_ID); final String loadBalance = exchange.getAttribute(Constants.LOAD_BALANCE); //查询可用服务 final List\u0026lt;Upstream\u0026gt; upstreamList = UpstreamCacheManager.getInstance().findUpstreamListBySelectorId(selectorId) .stream().filter(data -\u0026gt; { final String trimUri = data.getUrl().trim(); for (URI needToExclude : exclude) { // exclude already called if ((needToExclude.getHost() + \u0026#34;:\u0026#34; + needToExclude.getPort()).equals(trimUri)) { return false; } } return true; }).collect(Collectors.toList()); if (CollectionUtils.isEmpty(upstreamList)) { // no need to retry anymore return Mono.error(new ShenyuException(ShenyuResultEnum.CANNOT_FIND_HEALTHY_UPSTREAM_URL_AFTER_FAILOVER.getMsg())); } // 请求ip final String ip = Objects.requireNonNull(exchange.getRequest().getRemoteAddress()).getAddress().getHostAddress(); // 实现负载均衡 final Upstream upstream = LoadBalancerFactory.selector(upstreamList, loadBalance, ip); if (Objects.isNull(upstream)) { // no need to retry anymore return Mono.error(new ShenyuException(ShenyuResultEnum.CANNOT_FIND_HEALTHY_UPSTREAM_URL_AFTER_FAILOVER.getMsg())); } final URI newUri = RequestUrlUtils.buildRequestUri(exchange, upstream.buildDomain()); // 排除已经调用的uri exclude.add(newUri); // 进行再次调用 return doRequest(exchange, exchange.getRequest().getMethodValue(), newUri, httpHeaders, exchange.getRequest().getBody()) .timeout(duration, Mono.error(new TimeoutException(\u0026#34;Response took longer than timeout: \u0026#34; + duration))) .doOnError(e -\u0026gt; LOG.error(e.getMessage(), e)); }); } //...... } org.apache.shenyu.plugin.httpclient.WebClientPlugin#doRequest()\n在doRequest()方法中通过webClient发起真正的请求调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Override protected Mono\u0026lt;ClientResponse\u0026gt; doRequest(final ServerWebExchange exchange, final String httpMethod, final URI uri, final HttpHeaders httpHeaders, final Flux\u0026lt;DataBuffer\u0026gt; body) { return webClient.method(HttpMethod.valueOf(httpMethod)).uri(uri) //请求uri .headers(headers -\u0026gt; headers.addAll(httpHeaders)) // 请求header .body(BodyInserters.fromDataBuffers(body)) .exchange() // 发起请求 .doOnSuccess(res -\u0026gt; { if (res.statusCode().is2xxSuccessful()) { // 成功 exchange.getAttributes().put(Constants.CLIENT_RESPONSE_RESULT_TYPE, ResultEnum.SUCCESS.getName()); } else { // 失败 exchange.getAttributes().put(Constants.CLIENT_RESPONSE_RESULT_TYPE, ResultEnum.ERROR.getName()); } exchange.getResponse().setStatusCode(res.statusCode()); exchange.getAttributes().put(Constants.CLIENT_RESPONSE_ATTR, res); }); } # 处理相应结果 org.apache.shenyu.plugin.response.ResponsePlugin#execute()\n响应结果由ResponsePlugin插件处理。\n1 2 3 4 5 6 7 @Override public Mono\u0026lt;Void\u0026gt; execute(final ServerWebExchange exchange, final ShenyuPluginChain chain) { ShenyuContext shenyuContext = exchange.getAttribute(Constants.CONTEXT); assert shenyuContext != null; // 根据rpc类型处理结果 return writerMap.get(shenyuContext.getRpcType()).writeWith(exchange, chain); } 处理类型由MessageWriter决定，类继承关系如下：\nMessageWriter：接口，定义消息处理方法； NettyClientMessageWriter：处理Netty调用结果； RPCMessageWriter：处理RPC调用结果； WebClientMessageWriter：处理WebClient调用结果； 默认是通过WebCient发起http请求。\norg.apache.shenyu.plugin.response.strategy.WebClientMessageWriter#writeWith()\n在writeWith()方法中处理响应结果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @Override public Mono\u0026lt;Void\u0026gt; writeWith(final ServerWebExchange exchange, final ShenyuPluginChain chain) { return chain.execute(exchange).then(Mono.defer(() -\u0026gt; { // 获取响应 ServerHttpResponse response = exchange.getResponse(); ClientResponse clientResponse = exchange.getAttribute(Constants.CLIENT_RESPONSE_ATTR); if (Objects.isNull(clientResponse)) { Object error = ShenyuResultWrap.error(exchange, ShenyuResultEnum.SERVICE_RESULT_ERROR, null); return WebFluxResultUtils.result(exchange, error); } //获取cookies和headers response.getCookies().putAll(clientResponse.cookies()); response.getHeaders().putAll(clientResponse.headers().asHttpHeaders()); // image, pdf or stream does not do format processing. // 处理特殊响应类型 if (clientResponse.headers().contentType().isPresent()) { final String media = clientResponse.headers().contentType().get().toString().toLowerCase(); if (media.matches(COMMON_BIN_MEDIA_TYPE_REGEX)) { return response.writeWith(clientResponse.body(BodyExtractors.toDataBuffers())) .doOnCancel(() -\u0026gt; clean(exchange)); } } // 处理一般响应类型 clientResponse = ResponseUtils.buildClientResponse(response, clientResponse.body(BodyExtractors.toDataBuffers())); return clientResponse.bodyToMono(byte[].class) .flatMap(originData -\u0026gt; WebFluxResultUtils.result(exchange, originData)) .doOnCancel(() -\u0026gt; clean(exchange)); })); } 分析至此，关于Divide插件的源码分析就完成了，分析流程图如下：\n# 总结 本文主要分析了Apache Shenyu的服务调用过程。\n本系列是自己对shenyu进行学习的系列，参考了许多博客以及官网上面的内容，完全是班门弄斧，放在自己的博客上面，如果存在错误或者侵权，请在下面评论。\n# 参考 https://shenyu.apache.org/zh/blog/Plugin-SourceCode-Analysis-Divide-Plugin/ https://juejin.cn/post/7103865514258071566 ","date":"2023-09-22T18:59:19+08:00","image":"https://shenyu.apache.org/zh/img/logo.svg","permalink":"https://runqizhao.cn/p/%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8/","title":"服务调用"},{"content":"一些八股\n# redis为什么快 Redis都是基于内存，内存的访问速度是磁盘的千万倍 Redis基于Reactor模式开发一套高效的事件处理模型，主要单线程时间循环和IO多路复用。 Redis内存内置很多优化过后的数据结构实现，性能很高。 # 为什么要用Redis做缓存 高性能 高并发 # 请你简单说说Redis的内存结构 # 基本数据结构 String List Set Hash Zset # String 这种数据结构普是最常见的，用与存储对应的数据比如字符串、整数、浮点数、图片（图片的baser64鞭名马或者解码或者图片的路径）、序列化的对象。\nRedis虽然采用C语言编写，当时Redis再使用String的时候没有使用C语言的String类，而是在及创建了一种简单动态字符串（SDS)。相比于原本的 S提让 结构，获取自负床长度时间复杂度位O(1)。除此之外，Redis的SDS API是安全的，不会造成缓冲区溢出。\n应用场景：\n常规数据（比如session、token、序列化后的对象、图片的路径）的缓存； 计数比如用户单位时间的请求书（简单限流可以用到）、页面单位时间的访问数 分布式锁 # List List（列表），就是采用最基本的链式数据结构进行实现，这个的话采用就是一个单链表，没有什么好讲的。\n# Hash 这个数据结构适用于存储对象，后续操作的时候，可以直接修改这个对象。\n# Set 存储的值都是唯一的，这个适用于实现交集、并集、差集的操作，例如将一个用户所有关注人窜在一个集合中，将其所有粉丝存放在一个结合，这样，Set可以很好的实现共同管、共同粉丝、共同喜功能，这个过程就是再求交集的过程。\n使用场景：\n网站重复UV统计、文章点赞、动态点赞等等 需要获取多个数据交集、丙级和差集的场景：共同好友（交集）、共同关注（交集）、好友推荐（差集）、音乐推荐（差集）、订阅号推荐（差集）等等 需要随机获取数据源中元素的场景：抽奖系统、随机点名。 # Sort Set 相机爱与Set 增加可一个权重参数sorce，是的集合中的元素能够按照score进行有序排列，还可以通过score的范围来获取元素的列表。有点像HashMap与TreeSet的结合体。\n# 特殊数据结构 # Bitmap Bitmap存储的是连续的二进制数字，通过Bitmap，只需要一个bit位来表示某个元素对应的值或者状态，key就是对应元素本身，8bit可以组成一个byte，所以bitmap本身会极大的节省存储空间。\n# HyperLogLog HyperLogLog 是一种有名的基数计数概率算法 ，基于 LogLog Counting(LLC)优化改进得来，并不是 Redis 特有的，Redis 只是实现了这个算法并提供了一些开箱即用的 API。\nRedis 对 HyperLogLog 的存储结构做了优化，采用两种方式计数：\n稀疏矩阵：计数较少的时候，占用空间很小。 稠密矩阵：计数达到某个阈值的时候，占用 12k 的空间。 应用场景：\n数量量巨大（百万、千万级别以上）的计数场景\n举例：热门网站每日/每周/每月访问 ip 数统计、热门帖子 uv 统计、 相关命令：PFADD、PFCOUNT 。 # Geospatial index Geospatial index（地理空间索引，简称 GEO） 主要用于存储地理位置信息，基于 Sorted Set 实现。\n通过 GEO 我们可以轻松实现两个位置距离的计算、获取指定位置附近的元素等功能。\n应用场景：\n需要管理使用地理空间数据的场景\n举例：附近的人。 相关命令: GEOADD、GEORADIUS、GEORADIUSBYMEMBER 。 # String进行存储好还是使用Hash存储好 String存储的是序列的对象，存放的是整个对象。 Hash是对对象的每个字段单独存储，可以获取部分字段的信息，也可以修改或者添加分字段，节省网络流量。如果对象中某些字段需要经常变动或者经常需要淡出查询对象中的个别信息，Hash就非常合适。 String存储相对来说更加节省内存，缓存相同数量的对象数据，String消耗的内存是Hash的一眼，，并且，存储具有多层嵌套的对象也方便很多。如果系统对性能和资源非常敏感的话，String就非常适合。 因此，在绝大部分场景中，使用String来存储对象即可。\n# String的底层是采用什么进行实现的 String底层采用了自己实现的SDS结构进行实现。\nSDS结构体定义如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /* * 保存字符串对象的结构 */ //这个也没错，Redis 3.2 之前就是这样定义的。后来，由于这种方式的定义存在问题， //len 和 free 的定义用了 4 个字节，造成了浪费。 //Redis 3.2 之后，Redis 改进了 SDS 的定义，将其划分为了现在的 5 种类型。 struct sdshdr { // buf 中已占用空间的长度 //记录buf数组中已经使用自己的数量 // 等于SDS所保存字符串的长度 int len; // buf 中剩余可用空间的长度 // 记录buf数组中未使用字节的数量 int free; // 数据空间 // 字节数组，用于保存字符串 char buf[]; }; SDS遵循C字符串以空字符结尾的惯例，保存空字符的1字节空间不计算在SDS的len属性里面，并且为空字符分配额外的1字节空间，以及添加空字符到字符串末尾等操作，都是由SDS函数自动完成的，所以这个空字符对于SDS的使用者来说是完全透明的。遵循空字符结尾这一惯例的好处是，SDS可以直接重用一部分C字符串函数库里面的函数。\n与C的区别：\n主要区别就是在线长度统计，SDS可以常熟复杂度获取字符串长度。\nSDS可以杜绝空间 进行溢出，在进行实现的 时候采用下面的步骤 ：\n首先检查SDS空间是否满足修改 所需的要求，如果不满足的话，API会自动将SDS的空间罗战至执行修改所需的带线啊哦，然后才执行实际的修改操作。 使用sdsact进行拼接操作，扩容出对应的空间 减少内存分配次数：SDS采用空间预分配和惰性空间释放两种优化策略。当SDS需要增加字符串 时，Redis会为SDS分配好内存，并且根据特定算法分配多余的内存，这样可以减少 连续执行字符串增长操作所需的内存分配次数。当减少字符串时，这部分不会劣迹被回收，会被记录下再来，等待后续使用\n进制安全：SDS在使用的收可以直接使用内存，然后就会出现读到\\0的情况。\n# 请你简单说说Redis持久化（重要） 三种持久化方式：\n快照（RDB） 只追加文件（AOF） RDB 和 AOF 的混合持久化(Redis 4.0 新增) # RDB持久化 创建快照来获取存储在内存里面的数据在某个时间点上的副本，Redis创建快照之后，可以对快照进行备份，可以升降快照复制到其他服务器从而创建具有形同数据的服务器副本，还可以将快照留在原地一边重启服务器的时候进行使用。\n快照持久化是 Redis 默认采用的持久化方式\n# RDB创建快照的时候会阻塞主线程吗 Redis提供两个命令生成RDB快照文件：\nsave：同步保存操作，会阻塞Redis主线程 bgsave：fork出一个子进程，子进行执行，不会阻塞Redis主线程，默认此选项。 # AOF持久化 与快照持久化相比，AOF 持久化的实时性更好。\n开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入到 AOF 缓冲区 server.aof_buf 中，然后再写入到 AOF 文件中（此时还在系统内核缓存区未同步到磁盘），最后再根据持久化方式（ fsync策略）的配置来决定何时将系统内核缓存区的数据同步到硬盘中的。\n# AOF工作基本流程 命令追加（append）：所有写明回追较大AOF缓冲区中 命令写入（write）：将AOF缓冲区的数据写入到AOF文件中，这一不需要调用write函数（系统调用），write将数据写入到了系统内核缓冲区之后直接返回（延迟写）。此时没有同步到磁盘。 文件同步（fsync）：AOF缓冲区根据对应的持久化 方式（fsync策略）像磁盘中做同步操作。这异步需要调用 fsync 函数（系统调用）， fsync 针对单个文件操作，对其进行强制硬盘同步，fsync 将阻塞直到写入磁盘完成后返回，保证了数据持久化。 文件重写（rewrite）：随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。 重启加载（load）：当 Redis 重启时，可以加载 AOF 文件进行数据恢复。 # AOF持久化方式 appendfsync always：主线程调用 write 执行写操作后，后台线程（ aof_fsync 线程）立即会调用 fsync 函数同步 AOF 文件（刷盘），fsync 完成后线程返回，这样会严重降低 Redis 的性能（write + fsync）。 appendfsync everysec：主线程调用 write 执行写操作后立即返回，由后台线程（ aof_fsync 线程）每秒钟调用 fsync 函数（系统调用）同步一次 AOF 文件（write+fsync，fsync间隔为 1 秒） appendfsync no：主线程调用 write 执行写操作后立即返回，让操作系统决定何时进行同步，Linux 下一般为 30 秒一次（write但不fsync，fsync 的时机由操作系统决定）。 可以看出：这 3 种持久化方式的主要区别在于 fsync 同步 AOF 文件的时机（刷盘）。\n# AOF为什么是在执行玩命令之后记录日志 关系型数据库（如 MySQL）通常都是执行命令之前记录日志（方便故障恢复），而 Redis AOF 持久化机制是在执行完命令之后再记录日志。\n为什么是在执行完命令之后记录日志呢？\n避免额外的检查开销，AOF 记录日志不会对命令进行语法检查； 在命令执行完之后再记录，不会阻塞当前的命令执行。 这样也带来了风险（我在前面介绍 AOF 持久化的时候也提到过）：\n如果刚执行完命令 Redis 就宕机会导致对应的修改丢失； 可能会阻塞后续其他命令的执行（AOF 记录日志是在 Redis 主线程中进行的）。 # AOF重写 AOF 重写（rewrite） 是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有 AOF 文件进行任何读入、分析或者写入操作。\nAOF 文件重写期间，Redis 还会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新的 AOF 文件保存的数据库状态与现有的数据库状态一致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作。\n开启 AOF 重写功能，可以调用 BGREWRITEAOF 命令手动执行，也可以设置下面两个配置项，让程序自动决定触发时机：\nauto-aof-rewrite-min-size：如果 AOF 文件大小小于该值，则不会触发 AOF 重写。默认值为 64 MB; auto-aof-rewrite-percentage：执行 AOF 重写时，当前 AOF 大小（aof_current_size）和上一次重写时 AOF 大小（aof_base_size）的比值。如果当前 AOF 文件大小增加了这个百分比值，将触发 AOF 重写。将此值设置为 0 将禁用自动 AOF 重写。默认值为 100。 # AOF校验机制 AOF 校验机制是 Redis 在启动时对 AOF 文件进行检查，以判断文件是否完整，是否有损坏或者丢失的数据。这个机制的原理其实非常简单，就是通过使用一种叫做 校验和（checksum） 的数字来验证 AOF 文件。这个校验和是通过对整个 AOF 文件内容进行 CRC64 算法计算得出的数字。如果文件内容发生了变化，那么校验和也会随之改变。\n# 如何选择RDB和AOF Redis 保存的数据丢失一些也没什么影响的话，可以选择使用 RDB。\n不建议单独使用 AOF，因为时不时地创建一个 RDB 快照可以进行数据库备份、更快的重启以及解决 AOF 引擎错误。\n如果保存的数据要求安全性比较高的话，建议同时开启 RDB 和 AOF 持久化或者开启 RDB 和 AOF 混合持久化。\n# Redis线程模型（shenyu也是用这个 Netty也是用这个 这个搞懂） Redis基于Reactor模式设计开发一套搞笑的时间处理模型。这个时间处理模型对应的是Redis中的文件事件处理器。由于文件时间处理器（file event handler）是单线程方式运行的，所以我们一般都说Redis是单线程模型。\nReactor单线程模型采用的是下面这种方式：\n1、Reactor对象通过select监听客户端请求事件，收到事件后，通过dispatch进行分发。\n2、如果建立连接请求，则Acceptor通过accept处理连接请求，然后创建一个Handler对象处理完成连接后的各种事件。\n3、如果不是连接请求，则由reactor分发调用连接对应的handler来处理。\n4、handler只负责相应事件，不做具体的业务处理，通过read读取数据后，会分发给后面的worker线程池的某个线程处理业务。\n5、worker线程池会分配独立线程完成真正的业务，并将结果返回给handler。\n6、handler收到响应后，通过send分发将结果返回给client。\n虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。\n# 既然是单线程，那怎么监听大量的客户端连接呢？ Redis 通过 IO 多路复用程序 来监听来自客户端的大量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型（读、写）注册到内核中并监听每个事件是否发生。\n这样的好处非常明显：I/O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗（和 NIO 中的 Selector 组件很像）。\n文件事件处理器（file event handler）主要是包含 4 个部分：\n多个 socket（客户端连接） IO 多路复用程序（支持多个客户端连接的关键） 文件事件分派器（将 socket 关联到相应的事件处理器） 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） # Redis事务 Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。\nRedis 事务实际开发中使用的非常少，功能比较鸡肋，不要将其和我们平时理解的关系型数据库的事务混淆了。\n除了不满足原子性和持久性之外，事务中的每条命令都会与 Redis 服务器进行网络交互，这是比较浪费资源的行为。明明一次批量执行多个命令就可以了，这种操作实在是看不懂。\n因此，Redis 事务是不建议在日常开发中使用的。\nRedis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，Redis 事务是不支持回滚（roll back）操作的。因此，Redis 事务其实是不满足原子性的。\n，Redis 支持持久化，而且支持 3 种持久化方式:\n快照（snapshotting，RDB） 只追加文件（append-only file, AOF） RDB 和 AOF 的混合持久化(Redis 4.0 新增) # Redis性能优化 # 使用批量操作减少网络传输 发送命令 命令排队 命令执行 返回结果 # pipeline # Lua 脚本 # 大量 key 集中过期问题 对于过期 key，Redis 采用的是 定期删除+惰性/懒汉式删除 策略。\n定期删除执行过程中，如果突然遇到大量过期 key 的话，客户端请求必须等待定期清理过期 key 任务线程执行完成，因为这个这个定期任务线程是在 Redis 主线程中执行的。这就导致客户端请求没办法被及时处理，响应速度会比较慢。\n如何解决呢？ 下面是两种常见的方法：\n给 key 设置随机过期时间。 开启 lazy-free（惰性删除/延迟释放） 。lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。 个人建议不管是否开启 lazy-free，我们都尽量给 key 设置随机过期时间\n# Redis bigkey（大 Key） 即为key对应value占用空间很大。\nbigkey 除了会消耗更多的内存空间和带宽，还会对性能造成比较大的影响。因此，我们应该尽量避免 Redis 中存在 bigkey。\n# Redis hotkey（热 Key） 访问次数多于其他。那这个 key 就可以看作是 hotkey。\nhotkey 出现的原因主要是某个热点数据访问量暴增，如重大的热搜事件、参与秒杀的商品。\n处理 hotkey 会占用大量的 CPU 和带宽，可能会影响 Redis 实例对其他请求的正常处理。此外，如果突然访问 hotkey 的请求超出了 Redis 的处理能力，Redis 就会直接宕机。这种情况下，大量请求将落到后面的数据库上，可能会导致数据库崩溃。\n读写分离：主节点处理写请求，从节点处理读请求。\n使用 Redis Cluster：将热点数据分散存储在多个 Redis 节点上。\n二级缓存：hotkey 采用二级缓存的方式进行处理，将 hotkey 存放一份到 JVM 本地内存中（可以用 Caffeine）。\n# 慢查询 执行时间很长的语句。\n# Redis内存碎片 产生内存碎片的原因：\n1、Redis 存储存储数据的时候向操作系统申请的内存空间可能会大于数据实际需要的存储空间。\n2、频繁修改 Redis 中的数据也会产生内存碎片。\n清理内存碎片：\n直接通过 config set 命令将 activedefrag 配置项设置为 yes 即可。 通过 Redis 自动内存碎片清理机制可能会对 Redis 的性能产生影响，我们可以通过下面两个参数来减少对 Redis 性能的影响： 1 2 3 4 # 内存碎片清理所占用 CPU 时间的比例不低于 20% config set active-defrag-cycle-min 20 # 内存碎片清理所占用 CPU 时间的比例不高于 50% config set active-defrag-cycle-max 50 重启节点可以做到内存碎片重新整理。 # 缓存穿透 简单说，就是大量的key同时进行访问，这个时候直接没有经过redis，直接访问对应的数据库，造成数据库访问压力。\n如何解决？\n缓存无效 key 如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下：SET key value EX 10086 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。 布隆过滤器 把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。 布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。\n# 缓存击穿 缓存击穿就是同一时刻一个热点key进行访问的时候，此时这个key失效，直接访问对应的数据库。\n解决办法：\n设置热点数据永不过期或者过期时间比较长。 针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。 请求数据库写数据到缓存之前，先获取互斥锁，保证只有一个请求会落到数据库上，减少数据库的压力。 缓存穿透中，请求的 key 既不存在于缓存中，也不存在于数据库中。\n缓存击穿中，请求的 key 对应的是 热点数据 ，该数据 存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期） 。\n# 缓存雪崩 缓存在同一时间大面积的失效，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力。\n针对 Redis 服务不可用的情况：\n采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。 限流，避免同时处理大量的请求。 针对热点缓存失效的情况：\n设置不同的失效时间比如随机设置缓存的失效时间。 缓存永不失效（不太推荐，实用性太差）。 设置二级缓存。 缓存雪崩和缓存击穿比较像，但缓存雪崩导致的原因是缓存中的大量或者所有数据失效，缓存击穿导致的原因主要是某个热点数据不存在与缓存中（通常是因为缓存中的那份数据已经过期）。\n# 如何保证缓存和数据库数据的一致性？ 缓存失效时间变短（不推荐，治标不治本）：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。\n增加 cache 更新重试机制（常用）：如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可。\n其实这个和shenyu中二级缓存有点相似。\n# Redis如何实现限流算法 # 用redis令牌桶算法进行限流 系统以恒定的速率产⽣令牌，然后将令牌放⼊令牌桶中。\n令牌桶有⼀个容量，当令牌桶满了的时候，再向其中放⼊的令牌就会被丢弃。\n每次⼀个请求过来，需要从令牌桶中获取⼀个令牌，如果有令牌，则提供服务；如果没有令牌，则拒绝服务。\n流程图：\n# 采用redis漏桶算法进行限流 ⽔（请求）先进⼊到漏桶⾥，漏桶以⼀定的速度出⽔，当⽔流⼊速度过⼤会直接溢出（拒绝服务）\n流程图： # 基于redis实现的滑动窗口算法 滑动时间窗口通过维护⼀个单位时间内的计数值，每当⼀个请求通过时，就将计数值加1，当计数值超过预先设定的阈值时，就拒绝单位时间内的其他请求。如果单位时间已经结束，则将计数器清零，开启下⼀轮的计数。\n算法图：\n程图： ","date":"2023-09-22T18:53:45+08:00","permalink":"https://runqizhao.cn/p/redis%E5%85%AB%E8%82%A1/","title":"Redis八股"},{"content":"这篇将会逐步调用SpringBoot，直到读到对应的yaml文档或者是配置文件。\n将从下面三个部分进行展示：\nspringboot监听器初始化 springboot事件发布器初始化 springboot监听器工作原理 这里使用shenyu-examples-http为例\n# SpringBoot监听器初始化 下面是SpringBoot主类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package org.apache.shenyu.examples.http; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; /** * ShenyuTestHttpApplication. */ @SpringBootApplication public class ShenyuTestHttpApplication { /** * main. * * @param args args */ public static void main(final String[] args) { SpringApplication.run(ShenyuTestHttpApplication.class, args); } } 在run方法中隐藏着启动细节,进入run方法真实逻辑为创建SpringApplication对象并调用该对象的run方法\n这里面使用了反射机制。按下不表，来个TODO\n1 2 3 4 5 6 7 8 9 10 /** * Static helper that can be used to run a {@link SpringApplication} from the * specified source using default settings. * @param primarySource the primary source to load * @param args the application arguments (usually passed from a Java main method) * @return the running {@link ApplicationContext} */ public static ConfigurableApplicationContext run(Class\u0026lt;?\u0026gt; primarySource, String... args) { return run(new Class\u0026lt;?\u0026gt;[] { primarySource }, args); } 首先分析SpringApplication构造函数，其功能就是初始化包括如下内容\n资源加载器初始化 设置启动主类为primarySources 判断当前应用是否是web应用 设置初始化器 设置监听器 （本文重点分析此处逻辑） 设置主类 1 2 3 4 5 6 7 8 9 public SpringApplication(ResourceLoader resourceLoader, Class\u0026lt;?\u0026gt;... primarySources) { this.resourceLoader = resourceLoader; Assert.notNull(primarySources, \u0026#34;PrimarySources must not be null\u0026#34;); this.primarySources = new LinkedHashSet\u0026lt;\u0026gt;(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); } 此处重点分析setListeners方法，此方法比较简单代码如下\n1 2 3 4 private List\u0026lt;ApplicationListener\u0026lt;?\u0026gt;\u0026gt; listeners; public void setListeners(Collection\u0026lt;? extends ApplicationListener\u0026lt;?\u0026gt;\u0026gt; listeners) { this.listeners = new ArrayList\u0026lt;\u0026gt;(listeners); } ApplicationListener是基于JDK观察者模式设计的接口 类图如下 ApplicationEvent,EventListener均为JDK中默认接口\n查看完setListeners方法，继续分析该方法入参调用函数getSpringFactoriesInstances,该方法加载type类型的所有class全限定名并进行初始化\nSpringFactoriesLoader.loadFactoryNames(type, classLoader) 此方法加载所有jar包中META-INF/spring.factories文件 1 2 3 4 5 6 7 8 private \u0026lt;T\u0026gt; Collection\u0026lt;T\u0026gt; getSpringFactoriesInstances(Class\u0026lt;T\u0026gt; type, Class\u0026lt;?\u0026gt;[] parameterTypes, Object... args) { ClassLoader classLoader = getClassLoader(); // Use names and ensure unique to protect against duplicates Set\u0026lt;String\u0026gt; names = new LinkedHashSet\u0026lt;\u0026gt;(SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List\u0026lt;T\u0026gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances; } 通过springboot的源码中发现ApplicationListener类在下图中有10个其中打购类为配置文件解析监听器,这些类通过反射创建完成后传入setListeners完成赋值操作\n到此SpringApplication对象的创建工作结束了，接下来分析run方法中逻辑，由于run方法逻辑比较复杂本文只分析与配置文件加载相关代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public ConfigurableApplicationContext run(String... args) { StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection\u0026lt;SpringBootExceptionReporter\u0026gt; exceptionReporters = new ArrayList\u0026lt;\u0026gt;(); configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try { ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class,new Class[] { ConfigurableApplicationContext.class }, context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); .....省略代码..... try { listeners.running(context); } catch (Throwable ex) { handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); } return context; } 主要实现以下两种功能：\n获取springboot 事件发布器 发布springboot 容器启动事件 SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting();\nEventPublishingRunListener 中持有SpringApplication对象，该对象持有所有ApplicationListener对象因此可以实现发布事件到所有监听器\nEventPublishingRunListener starting()方法就是对所有监听器发布容器启动事件，该事件会被独有监听器接受并判断是否处理，处理配置文件的监听器ConfigFileApplicationListener也会收到该事件\n1 2 3 public void starting() { this.initialMulticaster.multicastEvent(new ApplicationStartingEvent(this.application, this.args)); } ConfigFileApplicationListener处理的事件类型为ApplicationEnvironmentPreparedEvent，ApplicationPreparedEvent，因此ApplicationStartingEvent并不会处理\n往下继续查看run方法中代码会发现prepareEnvironment方法会创建ConfigurableEnvironment类此类是springboot中存储所有配置的类\n1 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); 进入该方法发现事件发布器向所有坚挺着发布一个环境准备完毕的事件此事件正式上文提到的ApplicationEnvironmentPreparedEvent因此会触发ConfigFileApplicationListener处理，但是此时必须已经创建ConfigurableEnvironment类。\nConfigFileApplicationListener监听到ApplicationEnvironmentPreparedEvent事件处理以下几件事情\n加载后置处理器 对后置处理器优先级进行排序 调用后置处理器处理逻辑 后置处理器是所有EnvironmentPostProcessor实现类加载方式与监听器一样可参考上文，ConfigFileApplicationListener同样实现了EnvironmentPostProcessor后置处理器接口因此postProcessors.add(this); 是将自己注册到所有处理器中实现处理逻辑\n1 2 3 loadPostProcessors() { return SpringFactoriesLoader.loadFactories(EnvironmentPostProcessor.class,getClass().getClassLoader()); } 这里特此声明真正实现配置文件加载的逻辑开始 postProcessEnvironment调用addPropertySources调用Loader(environment, resourceLoader).load()，所有的逻辑处理都是通过Loader 这个内部类来完成的，此处的处理方式跟SpringApplication(primarySources).run(args) 是不是极为相似\n最后分析下Loader类的逻辑首先初始化完成\nspringboot环境类用于存放所有配置文件中的key=value 变量占位符解析类 资源加载器 配置文件解析加载器,处理 properties,yml,yaml文件的加载 PropertySourceLoader实现类为下图中两个，因此配置文件的加载会根据文件扩展名不同使用不用类来处理\n重要的逻辑终于出来了，此处重点逻辑分为\n处理spring.profiles.active，spring.profiles.include配置 加载配置文件并与profile绑定 将配置文件与springboot Environment 绑定 激活对应的profile load方法首先会在几个默认路径下尝试加载,默认路径如下\nDEFAULT_SEARCH_LOCATIONS = “classpath:/,classpath:/config/,file:./,file:./config/*/,file:./config/”;\ngetSearchNames()方法返回配置文件名字默认名字为:application\n此处特别说明下如果启动方式为 java -jar xxx.jar -Dspring.config.name=xx.properties 则不会加载默认名字的配置文件，网上很多关于spring.config.name使用这里通过源码分析说明了使用方式\n接下来是load方法因为name非空则直接进入红框逻辑，通过扩展名来处理不同类型配置文件\n如果没有配置spring.profile.active直接进入红框逻辑 通过resourceLoader加载路径下配置文件通过合法行校验后加载对应配置文件等待下一步解析\n配置文件加载完毕后进行解析此处consumer lambda方法为addToLoaded并将其与 Map\u0026lt;Profile, MutablePropertySources\u0026gt; loaded 绑定\n最后是将配置与enviroment 绑定\n","date":"2023-09-20T22:38:59+08:00","permalink":"https://runqizhao.cn/p/springboot%E6%98%AF%E5%A6%82%E4%BD%95%E8%AF%BB%E5%88%B0yaml%E6%96%87%E6%A1%A3%E7%9A%84/","title":"SpringBoot是如何读到yaml文档的"},{"content":" # 项目介绍 Apache ShenYu 是一个 高性能，多协议，易扩展，响应式的API网关\n兼容各种主流框架体系，支持热插拔，用户可以定制化开发，满足用户各种场景的现状和未来需求，经历过大规模场景的锤炼\nShenYu 官网\nGithub 地址\n# 服务注册 # 声明注册接口 这里还是以shenyu-examples-http为例，查看流程：\n在对应shenyu-examples-http中，我们可以看到引入下面依赖：\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shenyu\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;shenyu-spring-boot-starter-client-springmvc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${project.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以看到，在引用时，引用了对应的client包。\n接着看对应服务在进行注册时如何进行调用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @RestController @RequestMapping(\u0026#34;/order\u0026#34;) @ShenyuSpringMvcClient(\u0026#34;/order\u0026#34;) @ApiModule(value = \u0026#34;order\u0026#34;) public class OrderController { /** * Save order dto. * * @param orderDTO the order dto * @return the order dto */ @PostMapping(\u0026#34;/save\u0026#34;) @ShenyuSpringMvcClient(\u0026#34;/save\u0026#34;) @ApiDoc(desc = \u0026#34;save\u0026#34;) public OrderDTO save(@RequestBody final OrderDTO orderDTO) { orderDTO.setName(\u0026#34;hello world save order\u0026#34;); return orderDTO; } 可以看使用ShenyuSpringMvcClient注解，这个是即是使用对应的客户端。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.TYPE, ElementType.METHOD}) public @interface ShenyuSpringMvcClient { /** * Path string. * * @return the string */ @AliasFor(attribute = \u0026#34;path\u0026#34;) String value() default \u0026#34;\u0026#34;; /** * Path string. * * @return the string */ @AliasFor(attribute = \u0026#34;value\u0026#34;) String path() default \u0026#34;\u0026#34;; /** * Rule name string. * * @return the string */ String ruleName() default \u0026#34;\u0026#34;; /** * Desc string. * * @return String string */ String desc() default \u0026#34;\u0026#34;; /** * Enabled boolean. * * @return the boolean */ boolean enabled() default true; /** * Register meta data boolean. * * @return the boolean */ boolean registerMetaData() default true; } # 扫描注解信息 先备注一下：很多文章（甚至包包括官网）中都说再扫描注解信息时使用了SpringMvcClientBeanPostProcessor，这个类在#3484中已经被更改，里面的逻辑没有变换。但是很多代码位置进行了改变。\n注解扫描通过ShenyuClientRegisterEventPublisher完成，在构造器例化的过程中：\n读取属性配置 添加注解，读取path信息 启动注册中心，向shenyu-admin注册 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public SpringMvcClientEventListener(final PropertiesConfig clientConfig, final ShenyuClientRegisterRepository shenyuClientRegisterRepository) { super(clientConfig, shenyuClientRegisterRepository); //1.读取属性配置 Properties props = clientConfig.getProps(); this.isFull = Boolean.parseBoolean(props.getProperty(ShenyuClientConstants.IS_FULL, Boolean.FALSE.toString())); this.protocol = props.getProperty(ShenyuClientConstants.PROTOCOL, ShenyuClientConstants.HTTP); this.addPrefixed = Boolean.parseBoolean(props.getProperty(ShenyuClientConstants.ADD_PREFIXED, Boolean.FALSE.toString())); //2，添加注解 mappingAnnotation.add(ShenyuSpringMvcClient.class); mappingAnnotation.add(RequestMapping.class); } //下面时super(clientConfig, shenyuClientRegisterRepository); public AbstractContextRefreshedEventListener(final PropertiesConfig clientConfig, final ShenyuClientRegisterRepository shenyuClientRegisterRepository) { //1. 读取属性配置，这些字段是所有插件中应该包含的 Properties props = clientConfig.getProps(); this.appName = props.getProperty(ShenyuClientConstants.APP_NAME); this.contextPath = Optional.ofNullable(props.getProperty(ShenyuClientConstants.CONTEXT_PATH)).map(UriUtils::repairData).orElse(\u0026#34;\u0026#34;); if (StringUtils.isBlank(appName) \u0026amp;\u0026amp; StringUtils.isBlank(contextPath)) { String errorMsg = \u0026#34;client register param must config the appName or contextPath\u0026#34;; LOG.error(errorMsg); throw new ShenyuClientIllegalArgumentException(errorMsg); } this.ipAndPort = props.getProperty(ShenyuClientConstants.IP_PORT); this.host = props.getProperty(ShenyuClientConstants.HOST); this.port = props.getProperty(ShenyuClientConstants.PORT); //3.启动注册中心 publisher.start(shenyuClientRegisterRepository); } 在此类初始化完成之后，会读取注解信息，构建元数据对象和URI对象，并向shenyu-admin注册。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 //对应父类方法 protected void handle(final String beanName, final T bean) { // Class\u0026lt;?\u0026gt; clazz = getCorrectedClass(bean); final A beanShenyuClient = AnnotatedElementUtils.findMergedAnnotation(clazz, getAnnotationType()); final String superPath = buildApiSuperPath(clazz, beanShenyuClient); // Compatible with previous versions if (Objects.nonNull(beanShenyuClient) \u0026amp;\u0026amp; superPath.contains(\u0026#34;*\u0026#34;)) { handleClass(clazz, bean, beanShenyuClient, superPath); return; } final Method[] methods = ReflectionUtils.getUniqueDeclaredMethods(clazz); for (Method method : methods) { handleMethod(bean, clazz, beanShenyuClient, method, superPath); } } 因为所有插件都是实现对应流程，只是具体插件流程不太一样，因此将其中公共部分进行抽象出来，写道对应的父类之中，下面一个一个方法进行查看，一句一句进行分析：\n1 2 3 4 5 6 7 protected Class\u0026lt;?\u0026gt; getCorrectedClass(final T bean) { Class\u0026lt;?\u0026gt; clazz = bean.getClass(); if (AopUtils.isAopProxy(bean)) { clazz = AopUtils.getTargetClass(bean); } return clazz; } 这的函数的作用是将拿到类对应的反射，而不是类本身\n这里利用一个TODO：反射的好处是什么，为什么不直接使用对应的对象。\n提高代码的复用率，外部调用方便\n再看下面：\n1 2 3 4 5 6 7 8 9 10 11 //这个作用时读取上面反射过来类上的注解，此处是ShenyuClientMvcClient。 final A beanShenyuClient = AnnotatedElementUtils.findMergedAnnotation(clazz, getAnnotationType()); //构建superPath final String superPath = buildApiSuperPath(clazz, beanShenyuClient); // Compatible with previous versions //是否注册整个方法 if (Objects.nonNull(beanShenyuClient) \u0026amp;\u0026amp; superPath.contains(\u0026#34;*\u0026#34;)) { //构建元数据对象，然后向shenyu-admin注册 handleClass(clazz, bean, beanShenyuClient, superPath); return; } handlerClass中方法如下：\n1 2 3 4 5 6 protected void handleClass(final Class\u0026lt;?\u0026gt; clazz, final T bean, @NonNull final A beanShenyuClient, final String superPath) { publisher.publishEvent(buildMetaDataDTO(bean, beanShenyuClient, pathJoin(contextPath, superPath), clazz, null)); } 在进行superPath构建的时候 ，上面 使用了buildApiSuperPath方法，这个方法需要 着重查看一下：\n这里的话查看对应SpringMvcClient的逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 //先从类上的注解ShenyuSpringMvcClient取path属性，如果没有，就从当前类的RequestMapping注解中取path信息。 @Override protected String buildApiSuperPath(final Class\u0026lt;?\u0026gt; clazz, @Nullable final ShenyuSpringMvcClient beanShenyuClient) { //先从类上的注解shenyuSpringMvcClient取path属性 if (Objects.nonNull(beanShenyuClient) \u0026amp;\u0026amp; StringUtils.isNotBlank(beanShenyuClient.path())) { return beanShenyuClient.path(); } //从当前类中的RequestMapping注解中取path信息 RequestMapping requestMapping = AnnotationUtils.findAnnotation(clazz, RequestMapping.class); // Only the first path is supported temporarily if (Objects.nonNull(requestMapping) \u0026amp;\u0026amp; ArrayUtils.isNotEmpty(requestMapping.path()) \u0026amp;\u0026amp; StringUtils.isNotBlank(requestMapping.path()[0])) { return requestMapping.path()[0]; } return \u0026#34;\u0026#34;; } 继续看下面的方法：\n1 2 3 4 5 6 //读取所有方法 final Method[] methods = ReflectionUtils.getUniqueDeclaredMethods(clazz); //根据 具体类实现 其中具体逻辑 for (Method method : methods) { handleMethod(bean, clazz, beanShenyuClient, method, superPath); } 下面查看http使用handleMethod方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Override protected void handleMethod(final Object bean, final Class\u0026lt;?\u0026gt; clazz, @Nullable final ShenyuSpringMvcClient beanShenyuClient, final Method method, final String superPath) { // 在element上查询RequestMapping类型注解 // 将查询出的多个RequestMapping类型注解属性合并到查询的第一个注解中 // 多个相同注解合并 final RequestMapping requestMapping = AnnotatedElementUtils.findMergedAnnotation(method, RequestMapping.class); //获取对应ShenyuSpringMvcClient注解，查询出多个RequestMapping类型注解属性合并到查询的第一个注解中，多个形同的属性进行合并 ShenyuSpringMvcClient methodShenyuClient = AnnotatedElementUtils.findMergedAnnotation(method, ShenyuSpringMvcClient.class); //判定对应的ShenyuSpringMvcClient是否存在 ，如果不存在，则使用类上面的注解 methodShenyuClient = Objects.isNull(methodShenyuClient) ? beanShenyuClient : methodShenyuClient; // the result of ReflectionUtils#getUniqueDeclaredMethods contains method such as hashCode, wait, toSting // add Objects.nonNull(requestMapping) to make sure not register wrong method if (Objects.nonNull(methodShenyuClient) \u0026amp;\u0026amp; Objects.nonNull(requestMapping)) { //构建path信息，构建元数据对象，向shenyu-admin进行注册 final MetaDataRegisterDTO metaData = buildMetaDataDTO(bean, methodShenyuClient, buildApiPath(method, superPath, methodShenyuClient), clazz, method); getPublisher().publishEvent(metaData); getMetaDataMap().put(method, metaData); } } 这里面需要注意的方法是buildApiPath,先读取方法上的注解ShenyuSpringMvcClient，如果存在就构建；否则从方法的其他注解上获取path信息；完整的path = contextPath(上下文信息)+superPath(类信息)+methodPath(方法信息)。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Override protected String buildApiPath(final Method method, final String superPath, @NonNull final ShenyuSpringMvcClient methodShenyuClient) { //1.获取对应的Contextpath String contextPath = getContextPath(); //如果存在path，就构建 if (StringUtils.isNotBlank(methodShenyuClient.path())) { //完整path=ContextPath+superPath+methodPath return pathJoin(contextPath, superPath, methodShenyuClient.path()); } //2.从方法的其他注解上面获取path信息 final String path = getPathByMethod(method); if (StringUtils.isNotBlank(path)) { //完整的path=contextPath+superPath+methodPath return pathJoin(contextPath, superPath, path); } return pathJoin(contextPath, superPath); } 看一下getPathByMethod方法：\n1 2 3 4 5 6 7 8 9 private String getPathByMethod(@NonNull final Method method) { for (Class\u0026lt;? extends Annotation\u0026gt; mapping : mappingAnnotation) { final String pathByAnnotation = getPathByAnnotation(AnnotatedElementUtils.findMergedAnnotation(method, mapping)); if (StringUtils.isNotBlank(pathByAnnotation)) { return pathByAnnotation; } } return null; } 这个方法是从其他注解上获取 path信息，可以看看getPathByAnnotation:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 private String getPathByAnnotation(@Nullable final Annotation annotation) { if (Objects.isNull(annotation)) { return null; } final Object value = AnnotationUtils.getValue(annotation, \u0026#34;value\u0026#34;); if (value instanceof String \u0026amp;\u0026amp; StringUtils.isNotBlank((String) value)) { return (String) value; } // Only the first path is supported temporarily if (value instanceof String[] \u0026amp;\u0026amp; ArrayUtils.isNotEmpty((String[]) value) \u0026amp;\u0026amp; StringUtils.isNotBlank(((String[]) value)[0])) { return ((String[]) value)[0]; } return null; } 其他注解包括 在对应的annotation包下面：\nShenyuSpringMvcClient PostMapping GetMapping DeleteMapping PutMapping RequestMapping 扫描注解完成后，构建元数据对象，然后将该对象发送到shenyu-admin，即可完成注册。\n再看buildMetaDataDTO：\n1 2 3 4 5 6 7 8 9 10 11 12 private MetaDataRegisterDTO buildMetaDataDTO(@NonNull final ShenyuSpringMvcClient shenyuSpringMvcClient, final String path) { return MetaDataRegisterDTO.builder() .contextPath(contextPath) // contextPath .appName(appName) // appName .path(path) // 注册路径，在网关规则匹配时使用 .pathDesc(shenyuSpringMvcClient.desc()) // 描述信息 .rpcType(RpcTypeEnum.HTTP.getName()) // divide插件，默认时http类型 .enabled(shenyuSpringMvcClient.enabled()) // 是否启用规则 .ruleName(StringUtils.defaultIfBlank(shenyuSpringMvcClient.ruleName(), path))//规则名称 .registerMetaData(shenyuSpringMvcClient.registerMetaData()) //是否注册元数据信息 .build(); } 此方法就是构建对应的元数据对象，包括当前注册的规则信息。\n# 注册URI信息 当扫描完成对应的注解信息之后，需要注册对应URI信息。最新版本中仍然是使用SpringMvcClientEventListener方法进行实现的。\n首先还是说明初始化，在上面接口扫描中已经说明了对应的初始化，对应的语句是下面几句：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 this.appName = props.getProperty(ShenyuClientConstants.APP_NAME); this.contextPath = Optional.ofNullable(props.getProperty(ShenyuClientConstants.CONTEXT_PATH)).map(UriUtils::repairData).orElse(\u0026#34;\u0026#34;); if (StringUtils.isBlank(appName) \u0026amp;\u0026amp; StringUtils.isBlank(contextPath)) { String errorMsg = \u0026#34;client register param must config the appName or contextPath\u0026#34;; LOG.error(errorMsg); throw new ShenyuClientIllegalArgumentException(errorMsg); } this.ipAndPort = props.getProperty(ShenyuClientConstants.IP_PORT); this.host = props.getProperty(ShenyuClientConstants.HOST); this.port = props.getProperty(ShenyuClientConstants.PORT); ----- this.isFull = Boolean.parseBoolean(props.getProperty(ShenyuClientConstants.IS_FULL, Boolean.FALSE.toString())); this.protocol = props.getProperty(ShenyuClientConstants.PROTOCOL, ShenyuClientConstants.HTTP); this.addPrefixed = Boolean.parseBoolean(props.getProperty(ShenyuClientConstants.ADD_PREFIXED, Boolean.FALSE.toString())); 上面是在两个类中进行拿去，其实这里做的事情仍然是读取属性配置。\n接下来来到注册URI的逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Override public void onApplicationEvent(@NonNull final ContextRefreshedEvent event) { //获取对应的ApplicationContext context = event.getApplicationContext(); //从context获取对应的bean Map\u0026lt;String, T\u0026gt; beans = getBeans(context); //如果说没有注册对应的URI，返回null if (MapUtils.isEmpty(beans)) { return; } //保证该方法执行一次 if (!registered.compareAndSet(false, true)) { return; } //构建URI数据，并进行注册 publisher.publishEvent(buildURIRegisterDTO(context, beans)); //遍历每一个元数据 beans.forEach(this::handle); //获得ApiMoudle注解 Map\u0026lt;String, Object\u0026gt; apiModules = context.getBeansWithAnnotation(ApiModule.class); //处理ApiDoc注解 apiModules.forEach((k, v) -\u0026gt; handleApiDoc(v, beans)); } 可以查看对应的buildURIRegisterDTO方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Override protected URIRegisterDTO buildURIRegisterDTO(final ApplicationContext context, final Map\u0026lt;String, Object\u0026gt; beans) { try { return URIRegisterDTO.builder() .contextPath(getContextPath()) // contextPath .appName(getAppName())// appName .protocol(protocol)// 服务使用的协议 .host(super.getHost())//主机 .port(Integer.valueOf(getPort())) // 端口 .rpcType(RpcTypeEnum.HTTP.getName())// divide插件，默认注册http类型 .eventType(EventType.REGISTER) .build(); } catch (ShenyuException e) { throw new ShenyuException(e.getMessage() + \u0026#34;please config ${shenyu.client.http.props.port} in xml/yml !\u0026#34;); } } # 处理注册流程 客户端通过注册中心注册的元数据和URI数据，在shenyu-admin进行处理，负责存储到数据库和同步给shenyu网关。Divide插件的客户端注册处理逻辑在ShenyuClientRegisterDivideServiceImpl中。继承关系如下：\nShenyuClientRegisterService：客户端注册服务，顶层接口； FallbackShenyuClientRegisterService：注册失败，提供重试操作； AbstractShenyuClientRegisterServiceImpl：抽象类，实现部分公共注册逻辑； AbstractContextPathRegisterService：抽象类，负责注册ContextPath； ShenyuClientRegisterDivideServiceImpl：实现Divide插件的注册； # 注册服务 org.apache.shenyu.admin.service.register.AbstractShenyuClientRegisterServiceImpl#register()\n客户端通过注册中心注册的元数据MetaDataRegisterDTO对象在shenyu-admin的register()方法被接送到。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Override public String register(final MetaDataRegisterDTO dto) { //handler plugin selector //1.注册选择器 String selectorHandler = selectorHandler(dto); String selectorId = selectorService.registerDefault(dto, PluginNameAdapter.rpcTypeAdapter(rpcType()), selectorHandler); //handler selector rule //2.注册规则 String ruleHandler = ruleHandler(); RuleDTO ruleDTO = buildRpcDefaultRuleDTO(selectorId, dto, ruleHandler); ruleService.registerDefault(ruleDTO); //handler register metadata //3.注册元数据 registerMetadata(dto); //handler context path //4.注册ContextPath String contextPath = dto.getContextPath(); if (StringUtils.isNotEmpty(contextPath)) { registerContextPath(dto); } return ShenyuResultMessage.SUCCESS; } # 注册选择器 org.apache.shenyu.admin.service.impl.SelectorServiceImpl#registerDefault()\n构建contextPath，查找选择器信息是否存在，如果存在就返回id；不存在就创建默认的选择器信息。\n1 2 3 4 5 6 7 8 9 10 11 12 @Override public String registerDefault(final MetaDataRegisterDTO dto, final String pluginName, final String selectorHandler) { // 构建contextPath String contextPath = ContextPathUtils.buildContextPath(dto.getContextPath(), dto.getAppName()); // 通过名称查找选择器信息是否存在 SelectorDO selectorDO = findByNameAndPluginName(contextPath, pluginName); if (Objects.isNull(selectorDO)) { // 不存在就创建默认的选择器信息 return registerSelector(contextPath, pluginName, selectorHandler); } return selectorDO.getId(); } 默认选择器信息\n在这里构建默认选择器信息及其条件属性。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //注册选择器 private String registerSelector(final String contextPath, final String pluginName, final String selectorHandler) { //构建选择器 SelectorDTO selectorDTO = buildSelectorDTO(contextPath, pluginMapper.selectByName(pluginName).getId()); selectorDTO.setHandle(selectorHandler); //注册默认选择器 return registerDefault(selectorDTO); } //构建选择器 private SelectorDTO buildSelectorDTO(final String contextPath, final String pluginId) { //构建默认选择器 SelectorDTO selectorDTO = buildDefaultSelectorDTO(contextPath); selectorDTO.setPluginId(pluginId); //构建默认选择器的条件属性 selectorDTO.setSelectorConditions(buildDefaultSelectorConditionDTO(contextPath)); return selectorDTO; } 构建默认选择器\n1 2 3 4 5 6 7 8 9 10 11 private SelectorDTO buildDefaultSelectorDTO(final String name) { return SelectorDTO.builder() .name(name) // 名称 .type(SelectorTypeEnum.CUSTOM_FLOW.getCode()) // 默认类型自定义 .matchMode(MatchModeEnum.AND.getCode()) //默认匹配方式 and .enabled(Boolean.TRUE) //默认启开启 .loged(Boolean.TRUE) //默认记录日志 .continued(Boolean.TRUE) //默认继续后续选择器 .sort(1) //默认顺序1 .build(); } 构建默认选择器条件属性\n1 2 3 4 5 6 7 8 private List\u0026lt;SelectorConditionDTO\u0026gt; buildDefaultSelectorConditionDTO(final String contextPath) { SelectorConditionDTO selectorConditionDTO = new SelectorConditionDTO(); selectorConditionDTO.setParamType(ParamTypeEnum.URI.getName()); // 默认参数类型URI selectorConditionDTO.setParamName(\u0026#34;/\u0026#34;); selectorConditionDTO.setOperator(OperatorEnum.MATCH.getAlias()); // 默认匹配策略 match selectorConditionDTO.setParamValue(contextPath + AdminConstants.URI_SUFFIX); // 默认值 /contextPath/** return Collections.singletonList(selectorConditionDTO); } 注册默认选择器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Override public String registerDefault(final SelectorDTO selectorDTO) { //选择器信息 SelectorDO selectorDO = SelectorDO.buildSelectorDO(selectorDTO); //选择器条件属性 List\u0026lt;SelectorConditionDTO\u0026gt; selectorConditionDTOs = selectorDTO.getSelectorConditions(); if (StringUtils.isEmpty(selectorDTO.getId())) { // 向数据库插入选择器信息 selectorMapper.insertSelective(selectorDO); // 向数据库插入选择器条件属性 selectorConditionDTOs.forEach(selectorConditionDTO -\u0026gt; { selectorConditionDTO.setSelectorId(selectorDO.getId()); selectorConditionMapper.insertSelective(SelectorConditionDO.buildSelectorConditionDO(selectorConditionDTO)); }); } // 发布同步事件，向网关同步选择信息及其条件属性 publishEvent(selectorDO, selectorConditionDTOs); return selectorDO.getId(); } # 注册规则 在注册服务的第二步中，开始构建默认规则，然后注册规则。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Override public String register(final MetaDataRegisterDTO dto) { //1. 注册选择器 //...... //2. 注册规则 // 默认规则处理属性 String ruleHandler = ruleHandler(); // 构建默认规则信息 RuleDTO ruleDTO = buildRpcDefaultRuleDTO(selectorId, dto, ruleHandler); // 注册规则 ruleService.registerDefault(ruleDTO); //3. 注册元数据 //...... //4. 注册ContextPath //...... return ShenyuResultMessage.SUCCESS; } 默认规则处理属性\n1 2 3 4 5 @Override protected String ruleHandler() { // 默认规则处理属性 return new DivideRuleHandle().toJson(); } Divide插件默认规则处理属性\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public class DivideRuleHandle implements RuleHandle { /** * 负载均衡：默认随机 */ private String loadBalance = LoadBalanceEnum.RANDOM.getName(); /** * 重试策略：默认重试当前服务 */ private String retryStrategy = RetryEnum.CURRENT.getName(); /** * 重试次数：默认3次 */ private int retry = 3; /** * 调用超时：默认 3000 */ private long timeout = Constants.TIME_OUT; /** * header最大值：10240 byte */ private long headerMaxSize = Constants.HEADER_MAX_SIZE; /** * request最大值：102400 byte */ private long requestMaxSize = Constants.REQUEST_MAX_SIZE; } 构建默认规则信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // 构建默认规则信息 private RuleDTO buildRpcDefaultRuleDTO(final String selectorId, final MetaDataRegisterDTO metaDataDTO, final String ruleHandler) { return buildRuleDTO(selectorId, ruleHandler, metaDataDTO.getRuleName(), metaDataDTO.getPath()); } // 构建默认规则信息 private RuleDTO buildRuleDTO(final String selectorId, final String ruleHandler, final String ruleName, final String path) { RuleDTO ruleDTO = RuleDTO.builder() .selectorId(selectorId) //关联的选择器id .name(ruleName) //规则名称 .matchMode(MatchModeEnum.AND.getCode()) // 默认匹配模式 and .enabled(Boolean.TRUE) // 默认开启 .loged(Boolean.TRUE) //默认记录日志 .sort(1) //默认顺序 1 .handle(ruleHandler) .build(); RuleConditionDTO ruleConditionDTO = RuleConditionDTO.builder() .paramType(ParamTypeEnum.URI.getName()) // 默认参数类型URI .paramName(\u0026#34;/\u0026#34;) .paramValue(path) //参数值path .build(); if (path.indexOf(\u0026#34;*\u0026#34;) \u0026gt; 1) { ruleConditionDTO.setOperator(OperatorEnum.MATCH.getAlias()); //如果path中有*，操作类型则默认为 match } else { ruleConditionDTO.setOperator(OperatorEnum.EQ.getAlias()); // 否则，默认操作类型 = } ruleDTO.setRuleConditions(Collections.singletonList(ruleConditionDTO)); return ruleDTO; } org.apache.shenyu.admin.service.impl.RuleServiceImpl#registerDefault()\n注册规则：向数据库插入记录，并向网关发布事件，进行数据同步。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Override public String registerDefault(final RuleDTO ruleDTO) { RuleDO exist = ruleMapper.findBySelectorIdAndName(ruleDTO.getSelectorId(), ruleDTO.getName()); if (Objects.nonNull(exist)) { return \u0026#34;\u0026#34;; } RuleDO ruleDO = RuleDO.buildRuleDO(ruleDTO); List\u0026lt;RuleConditionDTO\u0026gt; ruleConditions = ruleDTO.getRuleConditions(); if (StringUtils.isEmpty(ruleDTO.getId())) { // 向数据库插入规则信息 ruleMapper.insertSelective(ruleDO); //向数据库插入规则体条件属性 ruleConditions.forEach(ruleConditionDTO -\u0026gt; { ruleConditionDTO.setRuleId(ruleDO.getId()); ruleConditionMapper.insertSelective(RuleConditionDO.buildRuleConditionDO(ruleConditionDTO)); }); } // 向网关发布事件，进行数据同步 publishEvent(ruleDO, ruleConditions); return ruleDO.getId(); } # 注册元数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Override public String register(final MetaDataRegisterDTO dto) { //1. 注册选择器 //...... //2. 注册规则 //...... //3. 注册元数据 registerMetadata(dto); //4. 注册ContextPath //...... return ShenyuResultMessage.SUCCESS; } org.apache.shenyu.admin.service.register.ShenyuClientRegisterDivideServiceImpl#registerMetadata()\n插入或更新元数据，然后发布同步事件到网关。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @Override protected void registerMetadata(final MetaDataRegisterDTO dto) { if (dto.isRegisterMetaData()) { // 如果注册元数据 // 获取metaDataService MetaDataService metaDataService = getMetaDataService(); // 元数据是否存在 MetaDataDO exist = metaDataService.findByPath(dto.getPath()); // 插入或更新元数据 metaDataService.saveOrUpdateMetaData(exist, dto); } } @Override public void saveOrUpdateMetaData(final MetaDataDO exist, final MetaDataRegisterDTO metaDataDTO) { DataEventTypeEnum eventType; // 数据类型转换 DTO-\u0026gt;DO MetaDataDO metaDataDO = MetaDataTransfer.INSTANCE.mapRegisterDTOToEntity(metaDataDTO); // 插入数据 if (Objects.isNull(exist)) { Timestamp currentTime = new Timestamp(System.currentTimeMillis()); metaDataDO.setId(UUIDUtils.getInstance().generateShortUuid()); metaDataDO.setDateCreated(currentTime); metaDataDO.setDateUpdated(currentTime); metaDataMapper.insert(metaDataDO); eventType = DataEventTypeEnum.CREATE; } else { // 更新数据 metaDataDO.setId(exist.getId()); metaDataMapper.update(metaDataDO); eventType = DataEventTypeEnum.UPDATE; } // 发布同步事件到网关 eventPublisher.publishEvent(new DataChangedEvent(ConfigGroupEnum.META_DATA, eventType, Collections.singletonList(MetaDataTransfer.INSTANCE.mapToData(metaDataDO)))); } # 注册ContextPath 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Override public String register(final MetaDataRegisterDTO dto) { //1. 注册选择器 //...... //2. 注册规则 //...... //3. 注册元数据 //...... //4. 注册ContextPath String contextPath = dto.getContextPath(); if (StringUtils.isNotEmpty(contextPath)) { registerContextPath(dto); } return ShenyuResultMessage.SUCCESS; } org.apache.shenyu.admin.service.register.AbstractContextPathRegisterService#registerContextPath()\n1 2 3 4 5 6 7 8 9 @Override public void registerContextPath(final MetaDataRegisterDTO dto) { // 设置选择器的contextPath String contextPathSelectorId = getSelectorService().registerDefault(dto, PluginEnum.CONTEXT_PATH.getName(), \u0026#34;\u0026#34;); ContextMappingRuleHandle handle = new ContextMappingRuleHandle(); handle.setContextPath(PathUtils.decoratorContextPath(dto.getContextPath())); // 设置规则的contextPath getRuleService().registerDefault(buildContextPathDefaultRuleDTO(contextPathSelectorId, dto, handle.toJson())); } # 注册URI org.apache.shenyu.admin.service.register.FallbackShenyuClientRegisterService#registerURI()\n服务端收到客户端注册的URI信息后，进行处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Override public String registerURI(final String selectorName, final List\u0026lt;URIRegisterDTO\u0026gt; uriList) { String result; String key = key(selectorName); try { this.removeFallBack(key); // 注册URI result = this.doRegisterURI(selectorName, uriList); logger.info(\u0026#34;Register success: {},{}\u0026#34;, selectorName, uriList); } catch (Exception ex) { logger.warn(\u0026#34;Register exception: cause:{}\u0026#34;, ex.getMessage()); result = \u0026#34;\u0026#34;; // 注册失败后，进行重试 this.addFallback(key, new FallbackHolder(selectorName, uriList)); } return result; } org.apache.shenyu.admin.service.register.AbstractShenyuClientRegisterServiceImpl#doRegisterURI()\n从客户端注册的URI中获取有效的URI，更新对应的选择器handle属性，向网关发送选择器更新事件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Override public String doRegisterURI(final String selectorName, final List\u0026lt;URIRegisterDTO\u0026gt; uriList) { //参数检查 if (CollectionUtils.isEmpty(uriList)) { return \u0026#34;\u0026#34;; } //获取选择器信息 SelectorDO selectorDO = selectorService.findByNameAndPluginName(selectorName, PluginNameAdapter.rpcTypeAdapter(rpcType())); if (Objects.isNull(selectorDO)) { throw new ShenyuException(\u0026#34;doRegister Failed to execute,wait to retry.\u0026#34;); } // 获取有效的URI List\u0026lt;URIRegisterDTO\u0026gt; validUriList = uriList.stream().filter(dto -\u0026gt; Objects.nonNull(dto.getPort()) \u0026amp;\u0026amp; StringUtils.isNotBlank(dto.getHost())).collect(Collectors.toList()); // 构建选择器的handle属性 String handler = buildHandle(validUriList, selectorDO); if (handler != null) { selectorDO.setHandle(handler); SelectorData selectorData = selectorService.buildByName(selectorName, PluginNameAdapter.rpcTypeAdapter(rpcType())); selectorData.setHandle(handler); // 向数据库更新选择器的handle属性 selectorService.updateSelective(selectorDO); // 向网关发送选择器更新事件 eventPublisher.publishEvent(new DataChangedEvent(ConfigGroupEnum.SELECTOR, DataEventTypeEnum.UPDATE, Collections.singletonList(selectorData))); } return ShenyuResultMessage.SUCCESS; } 引用官网上面一张图，总结整个流程（注意，因为类的变换，读取接口信息构造元数据以及读取配置信息，构造URI数据都在一个类中），但是具体的流程没有改变。\n当然，这个图片中少了一个很重要的内容，网关中的数据如何同步到本地缓存中。这个需要专门写一篇文章。\n下面在使用一个博客中的内容作为整个过程的总结：\nTODO：重新画这个图，这个图中存在一些问题，因为部分的类更改了，上文中进行了具体的分析。\n# 总结 本文主要是说明了服务注册的过程，但是里面还有很多问题没有进行具体说明：\n服务是如何进行同步的 服务在进行调用的时候流程是什么 本系列是自己对shenyu进行学习的系列，参考了许多博客以及官网上面的内容，完全是班门弄斧，放在自己的博客上面，如果存在错误或者侵权，请在下面评论。\n# 参考 https://shenyu.apache.org/zh/blog/Plugin-SourceCode-Analysis-Divide-Plugin/ https://juejin.cn/post/7103865514258071566 ","date":"2023-09-20T17:50:53+08:00","image":"https://shenyu.apache.org/zh/img/logo.svg","permalink":"https://runqizhao.cn/p/apache-shenyu%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C/","title":"Apache Shenyu服务注册"},{"content":"近期压力值爆满，哎\u0026hellip;.\n我是一个不喜欢将自己状态进行公开分享的人，最近一段时间经历了大起大落，想要用公开的方式记录一下自己的心境，也想让未来的自己看看现在的想法。\n# 起因：科研热情的破灭 我在学历方面可以说是很差了，自己本科三本，研究生一本，一直以来都因为这个抬不起头，可能这就是我考研的原因之一吧，考研其实也是失败告终，调剂到了现在的学校。\n机器学习我最开还有点兴趣。由于大三在学习西瓜书的时候，某位电科大的老师（KZ）上课直接推公式，根本听不懂，心态直接崩。而且当初20年，图像处理刚刚起步，特别流行，自己当初虽然有想过搞这些，但是自己手写一个cnn就费劲，而且当初班里面的大部分人都是在搞后端，自己也想抱团，也毅然决然的学习后端。\n机缘巧合之下，我在本科毕业设计接到了一个机器学习的课题，当时题目起得太有迷惑性了，自己以为是一个系统的设计，结果没有注意审题，其实是一个彻头彻尾的机器学习项目，当时根本就是一窍不通，自己也在考研，就随便做了一个demo了事，现在这个demo还在GitHub上面：\nhttps://github.com/runqi-zhao/vue-flask-ocr\n然后，最关键部分来了，当初做完项目，剩下的时间已经不多了，得赶紧写论文了，但是当初带我的导师觉得我没有达到对应题目的要求，并且没有创新（我笑了，本科创新），说想让我认认真真的继续做，我说老师，我们这些交流的不跟本部一起，我们得提前，我得赶紧写论文了。他还是说不急\u0026hellip;现在我才想明白，这个所谓教授的为难，只有一个对应的标准，没有什么的针对，只是自己认为是本科毕设，没有用心搞，才有了这个结果。当时就当纯觉得自己为什么要花那么大力气去搞一个自己不感兴趣的事情（这个思想一致伴随着我，直到现在）。现在复盘，其实哪有什么感不感兴趣，知识潜意识里面总是觉得这个东西没有用，就是不相干，总是拖着。\n顺便这里还是感谢一下成电的老师，虽然自己做的不怎么地，但是这个老师还是很贴心带了我一个专利。\n# 读研：导师的选择 调剂的时候，一般都是先联系导师，然后再说学校。当时整个人没有了主心骨，总是想着能上个学校就行了。自己当初也没有想过自己想要做什么，想要大大哪个层次，也为后面埋下了祸根。\n中间调剂的过程不说了，这里还是很感谢我的家人，当初帮我看着调剂，跟我一起努力，最后让我来到了这个学校。\n联系导师的时候，我看过研究方向，当时包括现在，我都是对云计算有兴趣的，对于机器学习，第一是觉得这个太难了，第二是自己当初没有从本科得到正反馈，自己内心深处觉得自己不是干这块的料，就不想走这个方面。\n来到了研究生，自己选到了某位老师的名下，当时这个老师在读博，需要一个能够写出for循环的人进行批量处理，很荣幸，自己因为有本科毕设的一点基础，会一点，被选了进去。\n但是这个也是我噩梦的开始，并不是导师的问题，是我自己不能够协调好。\n# 矛盾点：不放实习 研究方向兜兜转转，还是到了机器学习，中间曲折的过程不想说了。\n接下来就是最关键的点，不妨实习。记得倒是双选会的时候，我是导师的第二届学生。我问了师兄，是否放实习，师兄说应该可以的。当初我信以为真。\n研一研二不细说，中间也经历了一些波折，到现在的话导师带我一篇sci4区的文章，这里恒感谢我的导师，没有ta，我现在肯定更糟糕。\n当时考研失败之后，我就想找一个好工作证明自己，证明自己照样不差，因此从读研开始，自己完全没有把科研当回事，直接导致了研三实验没做完，小论文没有改完的境地。\n再说回实习，自己研二上学期，尝试找了日常实习，当时很幸运，拿到了美团，百度还在走流程。\n最终，拿到offer之后，跟导师商量，当时导师严厉批评了我，说我连课题还没定，就想着跑，当时我也是不懂事，其实ta也对，我也对，只是关注点不太一样而已。\n最终，自己拒绝了这次机会，想着专心搞实验，但是上面已经说了，自己心思从来就不在科研上面，就想找工作，在实验室每天也是看八股，论文就应付一下。\n到了暑期实习，自己还是按耐不住躁动的心，继续投了转正实习。这次解决没有日常实习那么顺利，好在最后拿到了滴滴：\n自己这次没有跟导师明说，只是跟ta交心，说了一下对应的心路历程，但是还是没有成果，明确说明了我要是走了大论文自己搞，我确实没有办法，只好放弃。\n# 秋招：惨淡开局，惨淡中场 秋招开始了，自己心思又到了这个上面，自己一门心思的扑向秋招，但是到现在还是0offer。自己确实没有太大的优势。\n近期也是天天熬夜，晚上1点睡，早上7点半起来，白天说是写论文，也会忍不住焦虑。\n这部分还没结束，如果拿到offer了再细说。\n还有就是自己不能只焦虑，还是要把秋招当回事，背八股必不可少的。\n# 总结：没有一开始像明白想要啥 因为自己没有一开始想明白自己想要的，才导致这个状态。\n无论如何，都是经历，自己慢慢的来，才能走的更远。\n","date":"2023-09-16T10:22:08+08:00","permalink":"https://runqizhao.cn/p/%E8%BF%91%E6%9C%9F%E5%8F%8D%E6%80%9D/","title":"近期反思"},{"content":"一些问题的复盘 ，想想自己为什么会被挂\n这个面试时纯八股，因此相当于考验自己八股背的熟不熟。\n# 请你介绍一下synchronized关键字 这个当时回答的话逻辑存在些问题，当时在介绍的时候逻辑如下：\n这个关键字的作用是什么 为什么会产生这个问题 使用这个关键字的流程。 下面将重新系统梳理整体逻辑，包括与Lock的比较。\n# synchronized是什么？有什么用？ synchronized时Java中的一个关机簪子，翻译中文就是同步的意思。主要解决的就是多个线程之间访问资源的同步性，可以保证被它修饰的方法或者代码块在任意时刻只有一个线程执行。\n在Java早期版本中，synchronized关键字属于重量级锁。效率低下。这是因为监视器所时要来与底层操作修通的Mutex Lock实现的，Java的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对较长的时间，时间成本相对较高。\n但是在Java6之后，synchronized引入了大量优化如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。这使得synchronized效率得到了提升。\n以上就是一些基本概念，在了解了这些基本概念之后，下面需要介绍如何使用synchronized的使用\n# 如何使用synchronized？ 修饰实例方法 修饰静态方法 修饰代码块 # 修饰实例方法 给当前对象示例加锁，进入同步代码前要获得当前对象实例的锁。\n# 修饰静态方法 给当前类加锁，作用域类的多有对象实例，进入同步代码块前要获得当前class锁。\n# 修饰代码块（锁定当前类） 给当前类进行加锁，会作用域类的所有对象示例，进入统合部代码前要获得当前class锁。\n# 修饰代码块（锁指定对象/类） 对括号里面指定的对象/类加锁：\nsynchronized(object)标识进入同步代码库要获得给定对象的锁。 synchronized(类.class) 表示进入同步代码前要获得 给定 Class 的锁。 # 总结 synchronized 关键字加到 static 静态方法和 synchronized(class) 代码块上都是是给 Class 类上锁；\nsynchronized 关键字加到实例方法上是给对象实例上锁；\n尽量不要使用 synchronized(String a) 因为 JVM 中，字符串常量池具有缓存功能。\n# 构造方法可以用synchronized修饰吗 先说结论：构造方法不能使用 synchronized 关键字修饰。\n构造方法本身就属于线程安全的，不存在同步的构造方法一说。\n重头戏是下面这块\n# synchronized底层原理了解吗 synchronized 关键字底层原理属于 JVM 层面的东西。\n# synchronized 同步语句块的情况 1 2 3 4 5 6 7 public class SynchronizedDemo { public void method() { synchronized (this) { System.out.println(\u0026#34;synchronized 代码块\u0026#34;); } } } 通过 JDK 自带的 javap 命令查看 SynchronizedDemo 类的相关字节码信息：首先切换到类的对应目录执行 javac SynchronizedDemo.java 命令生成编译后的 .class 文件，然后执行javap -c -s -v -l SynchronizedDemo.class。\n从上面我们可以看出：synchronized同步语句块的实现使用的是monitorenter和monitorexit指令，其中monitorenter 指令指向同步代码块的开始位置，monitorexit` 指令则指明同步代码块的结束位置。\n上面的字节码中包含一个 monitorenter 指令以及两个 monitorexit 指令，这是为了保证锁在同步代码块代码正常执行以及出现异常的这两种情况下都能被正确释放。\n当执行 monitorenter 指令时，线程试图获取锁也就是获取 对象监视器 monitor 的持有权。\n在 Java 虚拟机(HotSpot)中，Monitor 是基于 C++实现的，由ObjectMonitoropen in new window实现的。每个对象中都内置了一个 ObjectMonitor对象。\n另外，wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。\n在执行monitorenter时，会尝试获取对象的锁，如果锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器设为 1 也就是加 1。\n对象锁的的拥有者线程才可以执行 monitorexit 指令来释放锁。在执行 monitorexit 指令后，将锁计数器设为 0，表明锁被释放，其他线程可以尝试获取锁。\n如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。\n# synchronized 修饰方法的的情况 1 2 3 4 5 public class SynchronizedDemo2 { public synchronized void method() { System.out.println(\u0026#34;synchronized 方法\u0026#34;); } } synchronized修饰的方法并没有使用mintorenter指令和mintorexit指令。取而代之的却是ACC_SYNCHONIZED访问表示来判别一个方法是否声明为同步方法，从而执行响应的同步调用。\n如果是实例方法，JVM 会尝试获取实例对象的锁。如果是静态方法，JVM 会尝试获取当前 class 的锁。\n# 总结 synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。\nsynchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。\n不过两者的本质都是对对象监视器 monitor 的获取。\n以上是参考JavaGuide进行编写的，但是这部分感觉并不是很深入，因此下面从我自己原本的笔记上面进行提炼总结。（主要是从深入理解JVM上面进行总结，因为上面知识简单说明了对应指令的使用，并没有说明）\n# Moniterenter、Moniterexit 这两个是JVM指令，主要是基于Mask word和Object monitor来实现显得。\n在JVM中，对象在内存中分为三个区域：\n对象头 示例数据 字节对齐 下面主要介绍对象头。\n# 对象头 synchronized用的锁是存在Java对象头里的。如果对象是数组类型，则虚拟机用3个字宽（Word）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，1字宽等于4字节，即32bit，如下表所示\n长度 内容 说明 32/64bit Mark word 存储对象的hashCode或锁信息等 32/64bit Class Metadata Address 存储对象类型数据的指针 32/64bit Array length 数组的长度（如果当前对象是数组） Java对象头里的Mark Word里默认存储对象的HashCode、分代年龄和锁标记位。32位JVM的Mark Word的默认存储结构如下表：\n锁状态 25bit 4bit 1bit是否是偏向锁 2bit锁标志 无状态锁 对象的hashCode 对象分代年龄 0 01 在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据，如下表所示：\n在64位虚拟机下，Mark Word是64bit大小的，其存储结构如下表所示：\n其实这个的重点就是锁升级与锁对比。\n下面将针对这部分内容进行总结。\n# 锁升级与对比 上面已经说过，从Java6开始，所功能进行升级，将锁划分成了四种状态：\n无锁装填 偏向锁装填 轻量级锁状态 重量级状态。 先说明几个简单的概念：\n锁可以升级但是是不可以降级。 目的是为了条噶获得锁和释放锁的效率。 # 偏向锁 大多数情况下在多线程中，使用锁不存在竞争，并且总是有一个线程进行获得，因此出现了对应的偏向锁。\n偏向锁在进行使用的时候流程如下：\n首先当一个线程访问所记录里存储偏向的线程ID。 第二次进入同步块时不需要进行CAS操作和加锁以及解锁操作。只需要要简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。 如果说指向当前对象，则证明已经拿到偏向锁，进行操作。 如果说没有指向当前对象，那么需要测试一个Mark Word中偏向锁的标识是否视之为1 如果没有设置，则使用CAS竞争锁。 如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 在上面一系列操作之后，需要将偏向锁进行撤销，撤销条件：当其他线程尝试竞争偏向锁是，持有偏向锁的线程才会释放锁。 撤销步骤如下： 需要等待全局安全点（这个时间点上没有正在执行的字节码） 首先暂停又有偏向锁的线程 检查持有偏向锁是否还活着 如果当前线程不属于活动状态，则将当前对象头设置为无所状态。 如果线程仍然活着，拥有偏向锁的栈将会执行，遍历偏向对象的锁记录， 栈中锁记录和对象头的Mark Word要么重新偏向于其他线程 要么恢复到无锁或者标价对象不适合作为偏向锁。 最后唤醒线程。 偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟：-XX:BiasedLockingStartupDelay=0。如果你确定应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，那么程序默认会进入轻量级锁状态。 # 轻量级锁 # 轻量级锁加锁 线程执行同步块之前，\nJVM会先再当前线程的栈帧中创建用于存储锁记录的空间。 将对象头中的Mark Word复制到锁记录中，官方称之为Displaced Mark Word。 线程尝试使用CAS将对象头中Mark Word替换为指向锁记录的指针。 如果成功，当前线程获得锁。 如果失败，表示其他线程竞争所，当前西安测绘给你边长是使用自旋来获取锁。 # 轻量级锁解锁 使用原子CAS操作将Displaced Mark Word替换回到对象头。 如果成功，则表示没有竞争发生。 如果失败，表示当前锁存在竞争，锁就会膨胀为重量级锁。 因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。\n锁 优点 缺点 适用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法相比仅存在纳秒级的差距 如果线程间存在锁竞争会带来额外的锁撒销的消耗 适用于只有一个线程访问同步块场景 轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度 如果始终得不到锁竞争的线程，使用自旋会消耗CPU 追求响应时间 同步块执行速度非常快 重量级锁 县城竞争不使用自旋，不会消耗CPU 线程阻塞，响应时间缓慢 追求吞吐量 同步块执行速度较长 OK，这个问题会带结束，顺带将第二个问题进行回答了，“你知道锁升级的过程吗”\n# 你知道锁升级的过程吗 见上\n# 对于CurrentHashMap你是怎么理解的 这个话自己的回答算是70分，说出了锁分段，put和set的过程，这个具体的看笔记，这个记得比较清楚。\n# 场景题 核心线程池为4，最大线程数位10，队列大小为10，同时启动6个任务，每个任务10秒，执行多少时间，这个线程池会启动多少个线程来处理任务。\n这个题目就是对线程池的考虑，我回答20秒。\n有一篇很好的文章：https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html 这个文章看懂了这一类问题就没问题了。\n# 对于ThreadLocal的理解 这个不是很熟悉。\nTODO：专门写一篇笔记加深印象。\nhttps://javaguide.cn/java/concurrent/java-concurrent-questions-03.html\n# JVM垃圾回收处理器 这个是必须会背的。\n# MySQL数据库innodedb的存储结构，为社么使用这种结构 个人认为70分。\n# MySQL中的MVCC 0分，感觉这个就是挂了我的主要原因，这个是必会的确回答的细碎。\n这个需要重点复习总结\nhttps://javaguide.cn/database/mysql/innodb-implementation-of-mvcc.html\n# Redis中用到的数据结构 这个必会，每个细节都需要会。\n75分。\n其中zset的运用原理回答的不是很好！！！\n# Redis当中持久化方式 70分\n# Netty的IO方式 0分\n# TCP粘包问题如何解决 0分\n这个当时忘了，其实根本不知道\u0026hellip;.\n有空看看https://segmentfault.com/a/1190000039691657\n# Netty默认启动多少个线程 0分\n# Spring当中数据注入的方式 100分\n# Spring当中是线程安全的吗 70分\n# 分布式锁与线程锁的区别 20分。。。\n结束\n# 总结 到后面Netty开始全盘崩。\n对于Redis 常见的背会。\nNetty也需要背会。\nSpring中一些常见的需要背会。\n这一面有点类似于kpi面。。。。但是可能确实是后面崩了。。。。\n","date":"2023-09-07T15:52:00+08:00","permalink":"https://runqizhao.cn/p/%E6%B1%87%E5%B7%9D%E4%B8%80%E9%9D%A2/","title":"汇川一面"},{"content":"最近开学了，折磨的机器学习回来了，讲道理，自己接这个任务时间点太不对了，自己都忙成狗了，还没有提前做完，最近还卡住了，但是无论如何，加油吧。\n接着上一讲，在我们知道了shenyu的基本架构之后，分别启动shenyu-admin与shenyu-bootstrap。\n下面将结合shenyu-examples-divide进行断点调试，试图找到shenyu插件请求处理的流程。\n首先先来到shenyu-examples/shenyu-examples-divide下面，运行已经写好的divide插件，对应的日志如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 2023-08-29 09:00:57.321 INFO 3136 --- [ main] o.a.s.e.http.ShenyuTestHttpApplication : Starting ShenyuTestHttpApplication using Java 1.8.0_333 on DESKTOP-M708U6C with PID 3136 (E:\\shenyu\\shenyu-examples\\shenyu-examples-http\\target\\classes started by root in E:\\shenyu) 2023-08-29 09:00:57.327 INFO 3136 --- [ main] o.a.s.e.http.ShenyuTestHttpApplication : No active profile set, falling back to 1 default profile: \u0026#34;default\u0026#34; 2023-08-29 09:00:59.179 INFO 3136 --- [ main] o.s.b.a.e.web.EndpointLinksResolver : Exposing 1 endpoint(s) beneath base path \u0026#39;/actuator\u0026#39; 2023-08-29 09:00:59.280 INFO 3136 --- [ main] o.a.s.c.c.s.ShenyuClientShutdownHook : Add hook ShenyuClientShutdownHook-1 2023-08-29 09:00:59.982 INFO 3136 --- [ main] o.s.b.web.embedded.netty.NettyWebServer : Netty started on port 8189 2023-08-29 09:01:00.335 INFO 3136 --- [ Thread-12] o.a.s.c.c.s.ShenyuClientShutdownHook : hook Thread-7 will sleep 3000ms when it start 2023-08-29 09:01:00.335 INFO 3136 --- [ Thread-12] o.a.s.c.c.s.ShenyuClientShutdownHook : hook Thread-0 will sleep 3000ms when it start 2023-08-29 09:01:00.335 INFO 3136 --- [ Thread-12] o.a.s.c.c.s.ShenyuClientShutdownHook : hook SpringApplicationShutdownHook will sleep 3000ms when it start 2023-08-29 09:01:01.407 INFO 3136 --- [or_consumer_-42] o.a.s.r.client.http.utils.RegisterUtils : login success: {\u0026#34;id\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;userName\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;role\u0026#34;:1,\u0026#34;enabled\u0026#34;:true,\u0026#34;dateCreated\u0026#34;:\u0026#34;2023-08-29 08:58:47\u0026#34;,\u0026#34;dateUpdated\u0026#34;:\u0026#34;2023-08-29 08:58:47\u0026#34;,\u0026#34;token\u0026#34;:\u0026#34;eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyTmFtZSI6ImFkbWluIiwiZXhwIjoxNjkzMzU3MjYxfQ.O2GeU9KyasKCqKNgLzCMqjSlbfp1GfuYG9vrsWW7npQ\u0026#34;,\u0026#34;expiredTime\u0026#34;:86400000} 2023-08-29 09:01:01.436 INFO 3136 --- [or_consumer_-34] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/test/**\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.HttpTestController\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/test/**\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860328,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.436 INFO 3136 --- [or_consumer_-46] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/post/hi\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;spring annotation register\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\u0026#34;,\u0026#34;methodName\u0026#34;:\u0026#34;post\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/post/hi\u0026#34;,\u0026#34;parameterTypes\u0026#34;:\u0026#34;java.lang.String\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860334,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.436 INFO 3136 --- [or_consumer_-38] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/order/path/**/name\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.OrderController\u0026#34;,\u0026#34;methodName\u0026#34;:\u0026#34;testRestFul\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/order/path/**/name\u0026#34;,\u0026#34;parameterTypes\u0026#34;:\u0026#34;java.lang.String\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860331,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.436 INFO 3136 --- [or_consumer_-56] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/oauth/authorize\u0026#34;,\u0026#34;httpMethod\u0026#34;:0,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.OauthController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;testCode\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;authorize\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/oauth/authorize\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/oauth/authorize\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/oauth/authorize] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:01.436 INFO 3136 --- [or_consumer_-37] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/order/oauth2/test\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.OrderController\u0026#34;,\u0026#34;methodName\u0026#34;:\u0026#34;testRestFul\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/order/oauth2/test\u0026#34;,\u0026#34;parameterTypes\u0026#34;:\u0026#34;org.springframework.http.server.reactive.ServerHttpRequest\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860330,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.436 INFO 3136 --- [or_consumer_-49] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/upload/**\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.UploadController\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/upload/**\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860335,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.436 INFO 3136 --- [or_consumer_-44] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/shenyu/client/hello\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.ShenyuClientPathController\u0026#34;,\u0026#34;methodName\u0026#34;:\u0026#34;hello\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/shenyu/client/hello\u0026#34;,\u0026#34;parameterTypes\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860333,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.436 INFO 3136 --- [or_consumer_-53] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/test/path/{id}/name\u0026#34;,\u0026#34;httpMethod\u0026#34;:0,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;path/{id}/name\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/test/path/{id}/name\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;id\\\u0026#34;,\\\u0026#34;in\\\u0026#34;:\\\u0026#34;path\\\u0026#34;,\\\u0026#34;required\\\u0026#34;:true,\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/test/path/{id}/name\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/test/path/{id}/name] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:01.438 INFO 3136 --- [or_consumer_-45] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/shenyu/client/hi\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.ShenyuClientPathController\u0026#34;,\u0026#34;methodName\u0026#34;:\u0026#34;hello\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/shenyu/client/hi\u0026#34;,\u0026#34;parameterTypes\u0026#34;:\u0026#34;java.lang.String\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860333,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.438 INFO 3136 --- [or_consumer_-54] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/test/findByPage\u0026#34;,\u0026#34;httpMethod\u0026#34;:0,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;findByPage\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/test/findByPage\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/test/findByPage\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/test/findByPage] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:01.440 INFO 3136 --- [or_consumer_-50] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/test/payment\u0026#34;,\u0026#34;httpMethod\u0026#34;:2,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;payment\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/test/payment\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/test/payment\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/test/payment] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:01.440 INFO 3136 --- [or_consumer_-55] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/test/path/{id}\u0026#34;,\u0026#34;httpMethod\u0026#34;:0,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;path/{id}\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/test/path/{id}\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;id\\\u0026#34;,\\\u0026#34;in\\\u0026#34;:\\\u0026#34;path\\\u0026#34;,\\\u0026#34;required\\\u0026#34;:true,\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/test/path/{id}\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/test/path/{id}] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:01.440 INFO 3136 --- [or_consumer_-35] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/oauth/oauth\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.OauthController\u0026#34;,\u0026#34;methodName\u0026#34;:\u0026#34;testCode\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/oauth/oauth\u0026#34;,\u0026#34;parameterTypes\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860329,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.441 INFO 3136 --- [or_consumer_-47] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/hello\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;spring annotation register\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\u0026#34;,\u0026#34;methodName\u0026#34;:\u0026#34;hello\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/hello\u0026#34;,\u0026#34;parameterTypes\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860334,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.444 INFO 3136 --- [or_consumer_-48] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/hi\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;spring annotation register\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\u0026#34;,\u0026#34;methodName\u0026#34;:\u0026#34;hello\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/hi\u0026#34;,\u0026#34;parameterTypes\u0026#34;:\u0026#34;java.lang.String\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860334,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.444 INFO 3136 --- [or_consumer_-51] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/test/findByUserId\u0026#34;,\u0026#34;httpMethod\u0026#34;:0,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;findByUserId\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/test/findByUserId\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;userId\\\u0026#34;,\\\u0026#34;in\\\u0026#34;:\\\u0026#34;query\\\u0026#34;,\\\u0026#34;required\\\u0026#34;:true,\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/test/findByUserId\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/test/findByUserId] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:01.444 INFO 3136 --- [or_consumer_-52] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/test/findByUserIdName\u0026#34;,\u0026#34;httpMethod\u0026#34;:0,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;findByUserIdName\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/test/findByUserIdName\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;userId\\\u0026#34;,\\\u0026#34;in\\\u0026#34;:\\\u0026#34;query\\\u0026#34;,\\\u0026#34;required\\\u0026#34;:true,\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}},{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;name\\\u0026#34;,\\\u0026#34;in\\\u0026#34;:\\\u0026#34;query\\\u0026#34;,\\\u0026#34;required\\\u0026#34;:true,\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/test/findByUserIdName\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/test/findByUserIdName] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:01.445 INFO 3136 --- [or_consumer_-40] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/request/**\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.RequestController\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/request/**\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860331,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.445 INFO 3136 --- [or_consumer_-36] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/order/save\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.OrderController\u0026#34;,\u0026#34;methodName\u0026#34;:\u0026#34;save\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/order/save\u0026#34;,\u0026#34;parameterTypes\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.dto.OrderDTO\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860330,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.445 INFO 3136 --- [or_consumer_-39] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/order/path/**\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.OrderController\u0026#34;,\u0026#34;methodName\u0026#34;:\u0026#34;getPathVariable\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/order/path/**\u0026#34;,\u0026#34;parameterTypes\u0026#34;:\u0026#34;java.lang.String,java.lang.String\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860331,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.447 INFO 3136 --- [or_consumer_-42] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/shenyu/client/timeout\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.ShenyuClientPathController\u0026#34;,\u0026#34;methodName\u0026#34;:\u0026#34;timeout\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/shenyu/client/timeout\u0026#34;,\u0026#34;parameterTypes\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860332,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.447 INFO 3136 --- [or_consumer_-41] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/order/findById\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.OrderController\u0026#34;,\u0026#34;methodName\u0026#34;:\u0026#34;findById\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/order/findById\u0026#34;,\u0026#34;parameterTypes\u0026#34;:\u0026#34;java.lang.String\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860331,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.447 INFO 3136 --- [or_consumer_-43] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/shenyu/client/post/hi\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;shenyu client annotation register\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.ShenyuClientPathController\u0026#34;,\u0026#34;methodName\u0026#34;:\u0026#34;post\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/shenyu/client/post/hi\u0026#34;,\u0026#34;parameterTypes\u0026#34;:\u0026#34;java.lang.String\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860333,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.447 INFO 3136 --- [or_consumer_-57] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/order/save\u0026#34;,\u0026#34;httpMethod\u0026#34;:2,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.OrderController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;save\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.dto.OrderDTO\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;save\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/order/save\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/order/save\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/order/save] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:01.448 INFO 3136 --- [or_consumer_-33] o.a.s.r.client.http.utils.RegisterUtils : uri client register success: {\u0026#34;protocol\u0026#34;:\u0026#34;http://\u0026#34;,\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;192.168.186.1\u0026#34;,\u0026#34;port\u0026#34;:8189,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;} 2023-08-29 09:01:01.641 INFO 3136 --- [or_consumer_-58] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/order/oauth2/test\u0026#34;,\u0026#34;httpMethod\u0026#34;:0,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.OrderController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;testRestFul\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;org.springframework.http.server.reactive.ServerHttpRequest\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;oauth2/test\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/order/oauth2/test\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/order/oauth2/test\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/order/oauth2/test] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:02.040 INFO 3136 --- [or_consumer_-59] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/order/path/{id}/name\u0026#34;,\u0026#34;httpMethod\u0026#34;:0,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.OrderController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;testRestFul\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;java.lang.String\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;path/**/name\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/order/path/{id}/name\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;id\\\u0026#34;,\\\u0026#34;in\\\u0026#34;:\\\u0026#34;path\\\u0026#34;,\\\u0026#34;required\\\u0026#34;:true,\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/order/path/{id}/name\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/order/path/{id}/name] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:02.369 INFO 3136 --- [or_consumer_-60] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/order/path/{id}/{name}\u0026#34;,\u0026#34;httpMethod\u0026#34;:0,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.OrderController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;getPathVariable\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;java.lang.String,java.lang.String\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;path/**\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/order/path/{id}/{name}\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;id\\\u0026#34;,\\\u0026#34;in\\\u0026#34;:\\\u0026#34;path\\\u0026#34;,\\\u0026#34;required\\\u0026#34;:true,\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}},{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;name\\\u0026#34;,\\\u0026#34;in\\\u0026#34;:\\\u0026#34;path\\\u0026#34;,\\\u0026#34;required\\\u0026#34;:true,\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/order/path/{id}/{name}\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/order/path/{id}/{name}] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:02.667 INFO 3136 --- [or_consumer_-61] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/order/findById\u0026#34;,\u0026#34;httpMethod\u0026#34;:0,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.OrderController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;findById\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;java.lang.String\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;findById\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/order/findById\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;id\\\u0026#34;,\\\u0026#34;in\\\u0026#34;:\\\u0026#34;query\\\u0026#34;,\\\u0026#34;required\\\u0026#34;:true,\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/order/findById\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/order/findById] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:02.995 INFO 3136 --- [or_consumer_-62] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/post/hi\u0026#34;,\u0026#34;httpMethod\u0026#34;:2,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;post\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;java.lang.String\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;post/hi\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/post/hi\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/post/hi\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/post/hi] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:06.461 INFO 3136 --- [or_consumer_-34] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/hello\u0026#34;,\u0026#34;httpMethod\u0026#34;:1,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;hello\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;hello\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/hello\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/hello\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/hello] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:06.461 INFO 3136 --- [or_consumer_-37] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/hello\u0026#34;,\u0026#34;httpMethod\u0026#34;:4,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;hello\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;hello\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/hello\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/hello\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/hello] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:06.461 INFO 3136 --- [or_consumer_-56] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/hello\u0026#34;,\u0026#34;httpMethod\u0026#34;:2,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;hello\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;hello\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/hello\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/hello\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/hello] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:06.461 INFO 3136 --- [or_consumer_-46] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/hello\u0026#34;,\u0026#34;httpMethod\u0026#34;:0,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;hello\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;hello\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/hello\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/hello\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/hello] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:06.461 INFO 3136 --- [or_consumer_-49] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/hello\u0026#34;,\u0026#34;httpMethod\u0026#34;:7,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;hello\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;hello\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/hello\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/hello\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/hello] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:06.462 INFO 3136 --- [or_consumer_-64] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/hello\u0026#34;,\u0026#34;httpMethod\u0026#34;:5,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;hello\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;hello\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/hello\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/hello\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/hello] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:06.462 INFO 3136 --- [or_consumer_-63] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/hello\u0026#34;,\u0026#34;httpMethod\u0026#34;:6,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;hello\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;hello\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/hello\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/hello\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/hello] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:06.463 INFO 3136 --- [or_consumer_-38] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/hello\u0026#34;,\u0026#34;httpMethod\u0026#34;:3,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;hello\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;hello\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/hello\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/hello\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/hello] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:09.793 INFO 3136 --- [or_consumer_-35] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/hi\u0026#34;,\u0026#34;httpMethod\u0026#34;:5,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;hello\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;java.lang.String\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;hi\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/hi\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/hi\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/hi] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:09.793 INFO 3136 --- [or_consumer_-50] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/hi\u0026#34;,\u0026#34;httpMethod\u0026#34;:3,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;hello\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;java.lang.String\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;hi\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/hi\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/hi\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/hi] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:09.793 INFO 3136 --- [or_consumer_-44] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/hi\u0026#34;,\u0026#34;httpMethod\u0026#34;:6,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;hello\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;java.lang.String\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;hi\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/hi\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/hi\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/hi] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:09.793 INFO 3136 --- [or_consumer_-54] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/hi\u0026#34;,\u0026#34;httpMethod\u0026#34;:2,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;hello\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;java.lang.String\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;hi\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/hi\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/hi\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/hi] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:09.794 INFO 3136 --- [or_consumer_-45] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/hi\u0026#34;,\u0026#34;httpMethod\u0026#34;:7,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;hello\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;java.lang.String\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;hi\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/hi\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/hi\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/hi] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:09.795 INFO 3136 --- [or_consumer_-53] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/hi\u0026#34;,\u0026#34;httpMethod\u0026#34;:4,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;hello\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;java.lang.String\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;hi\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/hi\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/hi\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/hi] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:09.796 INFO 3136 --- [or_consumer_-48] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/upload/webFluxFiles\u0026#34;,\u0026#34;httpMethod\u0026#34;:2,\u0026#34;consume\u0026#34;:\u0026#34;multipart/form-data,text/plain\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;webFluxFiles\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/upload/webFluxFiles\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;files\\\u0026#34;,\\\u0026#34;in\\\u0026#34;:\\\u0026#34;query\\\u0026#34;,\\\u0026#34;required\\\u0026#34;:false,\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/upload/webFluxFiles\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/upload/webFluxFiles] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:09.798 INFO 3136 --- [or_consumer_-55] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/hi\u0026#34;,\u0026#34;httpMethod\u0026#34;:1,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;hello\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;java.lang.String\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;hi\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/hi\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/hi\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/hi] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:09.799 INFO 3136 --- [or_consumer_-35] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/upload/webFluxSingle\u0026#34;,\u0026#34;httpMethod\u0026#34;:2,\u0026#34;consume\u0026#34;:\u0026#34;multipart/form-data,text/plain\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;webFluxSingle\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/upload/webFluxSingle\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;file\\\u0026#34;,\\\u0026#34;in\\\u0026#34;:\\\u0026#34;query\\\u0026#34;,\\\u0026#34;required\\\u0026#34;:true,\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/upload/webFluxSingle\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/upload/webFluxSingle] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:09.799 INFO 3136 --- [or_consumer_-47] o.a.s.r.client.http.utils.RegisterUtils : apiDoc client register success: {\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;apiPath\u0026#34;:\u0026#34;/http/hi\u0026#34;,\u0026#34;httpMethod\u0026#34;:0,\u0026#34;consume\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;produce\u0026#34;:\u0026#34;*/*\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;v0.01\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;state\u0026#34;:0,\u0026#34;ext\u0026#34;:\u0026#34;{\\\u0026#34;protocol\\\u0026#34;:\\\u0026#34;http://\\\u0026#34;,\\\u0026#34;host\\\u0026#34;:\\\u0026#34;192.168.186.1\\\u0026#34;,\\\u0026#34;port\\\u0026#34;:8189,\\\u0026#34;addPrefixed\\\u0026#34;:false,\\\u0026#34;serviceName\\\u0026#34;:\\\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\\\u0026#34;,\\\u0026#34;methodName\\\u0026#34;:\\\u0026#34;hello\\\u0026#34;,\\\u0026#34;parameterTypes\\\u0026#34;:\\\u0026#34;java.lang.String\\\u0026#34;}\u0026#34;,\u0026#34;apiOwner\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;apiDesc\u0026#34;:\u0026#34;hi\u0026#34;,\u0026#34;apiSource\u0026#34;:1,\u0026#34;document\u0026#34;:\u0026#34;{\\\u0026#34;tags\\\u0026#34;:[],\\\u0026#34;operationId\\\u0026#34;:\\\u0026#34;/http/hi\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:[],\\\u0026#34;responses\\\u0026#34;:{\\\u0026#34;200\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;/http/hi\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;404\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;the path [/http/hi] not found\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}},\\\u0026#34;409\\\u0026#34;:{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;conflict\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:{\\\u0026#34;*/*\\\u0026#34;:{\\\u0026#34;schema\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;string\\\u0026#34;}}}}}}\u0026#34;,\u0026#34;eventType\u0026#34;:\u0026#34;REGISTER\u0026#34;,\u0026#34;tags\u0026#34;:[]} 2023-08-29 09:01:09.804 INFO 3136 --- [ main] o.a.s.e.http.ShenyuTestHttpApplication : Started ShenyuTestHttpApplication in 13.143 seconds (JVM running for 14.434) 从日志上面分析，判断注入到网关上面需要经历的过程：\n# 服务注册 首先先看第一句：\n1 2023-08-29 09:01:01.407 INFO 3136 --- [or_consumer_-42] o.a.s.r.client.http.utils.RegisterUtils : login success: {\u0026#34;id\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;userName\u0026#34;:\u0026#34;admin\u0026#34;,\u0026#34;role\u0026#34;:1,\u0026#34;enabled\u0026#34;:true,\u0026#34;dateCreated\u0026#34;:\u0026#34;2023-08-29 08:58:47\u0026#34;,\u0026#34;dateUpdated\u0026#34;:\u0026#34;2023-08-29 08:58:47\u0026#34;,\u0026#34;token\u0026#34;:\u0026#34;eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyTmFtZSI6ImFkbWluIiwiZXhwIjoxNjkzMzU3MjYxfQ.O2GeU9KyasKCqKNgLzCMqjSlbfp1GfuYG9vrsWW7npQ\u0026#34;,\u0026#34;expiredTime\u0026#34;:86400000} 这个其实就是首先登录与shenyu-admin进行连接，这个在yaml文档中有配置：\n1 2 3 4 5 6 7 shenyu: register: registerType: http #zookeeper #etcd #nacos #consul serverLists: http://localhost:9095 #localhost:2181 #http://localhost:2379 #localhost:8848 props: username: admin password: 123456 shenyu.register.registerType代表类型，包括http,zk,nacos等。\nshenyu.register.serverListsd代表shenyu-admin的地址或者是其他服务的地址，根据对应的地址注入对应的形式。\nshenyu.register.props标识需要输入的用户名以及密码。\n然后是怎么进行连接的，这里直接使用admin接口进行同步。\n这里直接看shenyu-register-http(application中可以进行映射，先将文件中的配置进行读入，TODO搞清楚为什么能够来到这个类)\n这里的话应该涉及到数据同步的内容吧，这里先按下不表。\n这里其实可以看到是道道HttpClientRegisterRepository中，这里肯定直接调用了对应的内容。\n然后找到下面这个类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public final class RegisterUtils { /** * Do register. * * @param json the json * @param url the url * @param type the type * @throws IOException the io exception */ public static void doRegister(final String json, final String url, final String type) throws IOException { String result = OkHttpTools.getInstance().post(url, json); if (Objects.equals(SUCCESS, result)) { LOGGER.info(\u0026#34;{} client register success: {} \u0026#34;, type, json); } else { LOGGER.error(\u0026#34;{} client register error: {} \u0026#34;, type, json); } } 这个可以知道对应这里，但是怎么讲数据传输过来，虽然找到了部分源码，但是应该与spring也有关系，这里来个TODO。\n这部分使用的到的是服务注册中的内容，可以看服务注册的那篇文章。\nok，这一句的作用讲解完毕，看下面的日志：\n1 2 3 4 2023-08-29 09:01:01.436 INFO 3136 --- [or_consumer_-34] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/test/**\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.HttpTestController\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/test/**\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860328,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.436 INFO 3136 --- [or_consumer_-34] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/test/**\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.HttpTestController\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/test/**\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860328,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.436 INFO 3136 --- [or_consumer_-46] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/post/hi\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;spring annotation register\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.SpringMvcMappingPathController\u0026#34;,\u0026#34;methodName\u0026#34;:\u0026#34;post\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/post/hi\u0026#34;,\u0026#34;parameterTypes\u0026#34;:\u0026#34;java.lang.String\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860334,\u0026#34;addPrefixed\u0026#34;:false} 2023-08-29 09:01:01.436 INFO 3136 --- [or_consumer_-38] o.a.s.r.client.http.utils.RegisterUtils : metadata client register success: {\u0026#34;appName\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;contextPath\u0026#34;:\u0026#34;/http\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/http/order/path/**/name\u0026#34;,\u0026#34;pathDesc\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;rpcType\u0026#34;:\u0026#34;http\u0026#34;,\u0026#34;serviceName\u0026#34;:\u0026#34;org.apache.shenyu.examples.http.controller.OrderController\u0026#34;,\u0026#34;methodName\u0026#34;:\u0026#34;testRestFul\u0026#34;,\u0026#34;ruleName\u0026#34;:\u0026#34;/http/order/path/**/name\u0026#34;,\u0026#34;parameterTypes\u0026#34;:\u0026#34;java.lang.String\u0026#34;,\u0026#34;enabled\u0026#34;:true,\u0026#34;pluginNames\u0026#34;:[],\u0026#34;registerMetaData\u0026#34;:true,\u0026#34;timeMillis\u0026#34;:1693270860331,\u0026#34;addPrefixed\u0026#34;:false} 这个就是将客户端的内容注册到网关之中，如下：\n1 2 3 4 5 6 client: http: props: contextPath: /http appName: http # port: 8189 这里最近在编写自己的插件时，产生了一些疑问：\n按照shenyu的架构，在这里编写的client应该会跳转到shenyu-client下面进行调用。\n首先先看上面的日志，最开始第一句，用户仍然会调用到RegisterUtils中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 public final class RegisterUtils { private static final Logger LOGGER = LoggerFactory.getLogger(RegisterUtils.class); private RegisterUtils() { } /** * Do register. * * @param json the json * @param url the url * @param type the type * @param accessToken the token * @throws IOException the io exception */ public static void doRegister(final String json, final String url, final String type, final String accessToken) throws IOException { if (StringUtils.isBlank(accessToken)) { LOGGER.error(\u0026#34;{} client register error accessToken is null, please check the config : {} \u0026#34;, type, json); return; } Headers headers = new Headers.Builder().add(Constants.X_ACCESS_TOKEN, accessToken).build(); String result = OkHttpTools.getInstance().post(url, json, headers); if (Objects.equals(SUCCESS, result)) { LOGGER.info(\u0026#34;{} client register success: {} \u0026#34;, type, json); } else { LOGGER.error(\u0026#34;{} client register error: {} \u0026#34;, type, json); } } /** * Do register. * * @param json the json * @param url the url * @param type the type * @throws IOException the io exception */ public static void doRegister(final String json, final String url, final String type) throws IOException { String result = OkHttpTools.getInstance().post(url, json); if (Objects.equals(SUCCESS, result)) { LOGGER.info(\u0026#34;{} client register success: {} \u0026#34;, type, json); } else { LOGGER.error(\u0026#34;{} client register error: {} \u0026#34;, type, json); } } 这里不妨使用断点进行跳转，直接运行起来，在这个位置打上断点。\n打上断点直接到达这里，这里应该是使用spring boot中的内容，这里值得好好研究一番。\n这一个也是服务注册的内容，也可以看服务注册的文章。\n# 服务调用 当我们请求服务时，会经过什么过程，这个请看服务调用的文章。\n# 服务同步 此处如何进行服务同步，请看服务同步的那篇文章。\n","date":"2023-08-29T08:43:31+08:00","image":"https://shenyu.apache.org/zh/img/logo.svg","permalink":"https://runqizhao.cn/p/%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B/","title":"请求处理流程"},{"content":"最近在做开源之夏的项目，使用shenyu-k8s-ingress增强项目，自己是在太菜了，导致PMC都无话可说了，加上自己没有时间，但是既然接手了，一定要做到最好，因此，这个系列的目的就是记录shenyu插件的运行流程，同时说明shenyu-k8s-ingress中的注入流程。\n之所以把这个系列写在博客上面而不是写在自己的笔记上面，算是对自己的监督吧。也是把自己放在耻辱柱一回，去年开源之夏太简单了，导致自己过于大意，这个开源之夏其实一点都不难，就是自己对于基础知识不熟悉以及shenyu插件不熟悉（双重bug叠满了），导致自己进度缓慢，尤其是今天开发websocket，对于websocket运行流程一无所知，实在是太离谱了\u0026hellip;\n下面进入正题，将从shenyu的启动，shenyu-websocket插件运行流程进行讲解说明。\n# 本地化启动shenyu 首先本地化启动是一个傻瓜式教程，这里的话根据最近的理解，简单说一下shenyu的架构吧。\n上图算是shenyu官网的总体架构，其中算是很详细的说明了：\nshenyu的优点。 与其他网关插件比较。 特点 解决的问题 核心架构 这里还是说一下与其他查网关插件比较吧：\n# 与Spring Cloud进行比较 其实最主要的，就是shenyu足够简单，不需要用户自己在进行过多的设置，能够做到开箱即用。\n前面的话可以参考官网，但是最核心的第5点，下面详细说明第5点。\n# 核心架构 核心架构主要包含了shenyu-admin与shenyu-bootstrap两个方面的内容。这里还是分开进行讲解。\n这两部分将会从源码运行开始讲起，首先采用官网上面的示例运行起来，然后逐步debug。判断里面的逻辑。\n","date":"2023-08-28T19:19:24+08:00","image":"https://shenyu.apache.org/zh/img/logo.svg","permalink":"https://runqizhao.cn/p/shenyu-%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90/","title":"shenyu 架构分析"},{"content":" # 什么是网关 微服务背景下，一个系统被拆分多个服务，但是像安全认证，流量控制，日志，监控等功能是每个服务都需要的，那么每个服务都需要进行单独实现，这使得我们做了很多重复的内容，没有一个全局的视图。\n因此，出现了网管这个概念，这里借用JavaGuide画的图进行展示：\n一般情况下， 网关可以为我们提供请求转发、安全认证 （身份/权限认证）、流量控制、负载均衡、降级绒杜纳、日志、监控、参数检验、协议转换等功能。\n总的来说，网关就实现了两件事：请求转发+请求过滤。\n当热按，咱们就是说网管在进行部署的时候可以进行负载均衡，以保证达到高可用，避免单点的风险。\n# 网关的功能 绝大多数网关可以做到一下几种功能：\n请求转发：将强求转发到目标为服务上面 负载均衡：根据各个微服务示例的负载均衡情况或者具体的复杂均衡策略对请求实现动态的负载均衡。 安全认证：对用户请求进行身份验证并且仅允许可信客户端访问API，并且还能狗使用类似RBAC等方式来进行授权。 参数校验：支持参数映射与检验逻辑。 日志记录：方便用户进行排查。 监控警告：从业务指标、机器指标、JVM指标等方面进行监控并提供配套的告警机制。 熔断降级：试试监控请求的统计信息，达到配置的失败阈值后，自动熔断，返回默认值。 响应缓存：当用户请求获取的是一些静态的或更新不频繁的数据时，一段时间内多次请求获取到的数据很可能是一样的。对于这种情况可以将响应缓存起来。这样用户请求可以直接在网关层得到响应数据，无需再去访问业务服务，减轻业务服务的负担。 响应聚合：某些情况下用户请求要获取的响应内容可能会来自于多个业务服务。网关作为业务服务的调用方，可以把多个服务的响应整合起来，再一并返回给用户。 灰度发布：将请求动态分流到不同的服务版本（最基本的一种灰度发布）。 异常处理：对于业务服务返回的异常响应，可以在网关层在返回给用户之前做转换处理。这样可以把一些业务侧返回的异常细节隐藏，转换成用户友好的错误提示返回。 API 文档： 如果计划将 API 暴露给组织以外的开发人员，那么必须考虑使用 API 文档，例如 Swagger 或 OpenAPI。 协议转换：通过协议转换整合后台基于 REST、AMQP、Dubbo 等不同风格和实现技术的微服务，面向 Web Mobile、开放平台等特定客户端提供统一服务。 # 本系列主角 本次主要是在oosp与glcc参与到Apache Shenyu里面为契机，对Apache Shenyu进行系统性的学习，对于里面的内容进行整理，同时对里面插件进行学习，直接记录到个人博客上面，希望自己日后能够发现最开始看的不足。\n在介绍主角之前， 肯定要对常见的网关插件有一定的了解，即常听说的Spring Cloud与 Netflix Zuul。\n# Netflix Zuul Zuul 是 Netflix 开发的一款提供动态路由、监控、弹性、安全的网关服务，基于 Java 技术栈开发，可以和 Eureka、Ribbon、Hystrix 等组件配合使用。\nZuul 核心架构如下：\nZuul 主要通过过滤器（类似于 AOP）来过滤请求，从而实现网关必备的各种功能。\n我们可以自定义过滤器来处理请求，并且，Zuul 生态本身就有很多现成的过滤器供我们使用。\n# Spring Cloud SpringCloud Gateway 属于 Spring Cloud 生态系统中的网关，其诞生的目标是为了替代老牌网关 Zuul。准确点来说，应该是 Zuul 1.x。SpringCloud Gateway 起步要比 Zuul 2.x 更早。\n为了提升网关的性能，SpringCloud Gateway 基于 Spring WebFlux 。Spring WebFlux 使用 Reactor 库来实现响应式编程模型，底层基于 Netty 实现同步非阻塞的 I/O。\nSpring Cloud Gateway 不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控/指标，限流。\nSpring Cloud Gateway 和 Zuul 2.x 的差别不大，也是通过过滤器来处理请求。不过，目前更加推荐使用 Spring Cloud Gateway 而非 Zuul，Spring Cloud 生态对其支持更加友好。\n# Spring Cloud Gateway 的工作流程？ Spring Cloud Gateway 的工作流程如下图所示：\n具体流程如下：\n路由断言：客户端的请求到达网关后，先经过Gateway Handler Mapping处理，这里会做断言（Predicate）判断，看下符合哪个路径规则，这个路由映射后端的某个服务。 请求过滤：然后请求到达 Gateway Web Handler，这里面有很多过滤器，组成过滤器链（Filter Chain），这些过滤器可以对请求进行拦截和修改，比如添加请求头、参数校验等等，有点像净化污水。然后将请求转发到实际的后端服务。这些过滤器逻辑上可以称作 Pre-Filters，Pre 可以理解为“在\u0026hellip;之前”。 服务处理：后端服务会对请求进行处理。 响应过滤：后端处理完结果后，返回给 Gateway 的过滤器再次做处理，逻辑上可以称作 Post-Filters，Post 可以理解为“在\u0026hellip;之后”。 响应返回：响应经过过滤处理后，返回给客户端。 总结：客户端的请求先通过匹配规则找到合适的路由，就能映射到具体的服务。然后请求经过过滤器处理后转发给具体的服务，服务处理后，再次经过过滤器处理，最后返回给客户端。\n# Spring Cloud Gateway 的断言是什么？ 断言（Predicate）这个词听起来极其深奥，它是一种编程术语，我们生活中根本就不会用它。说白了它就是对一个表达式进行 if 判断，结果为真或假，如果为真则做这件事，否则做那件事。\n在 Gateway 中，如果客户端发送的请求满足了断言的条件，则映射到指定的路由器，就能转发到指定的服务上进行处理。\n断言配置的示例如下，配置了两个路由规则，有一个 predicates 断言配置，当请求 url 中包含 api/thirdparty，就匹配到了第一个路由 route_thirdparty。\n常见的断言规则如下：\n# Spring Cloud Gateway 的路由和断言是什么关系？ Route 路由和 Predicate 断言的对应关系如下：\n一对多：一个路由规则可以包含多个断言。如上图中路由 Route1 配置了三个断言 Predicate。\n同时满足：如果一个路由规则中有多个断言，则需要同时满足才能匹配。如上图中路由 Route2 配置了两个断言，客户端发送的请求必须同时满足这两个断言，才能匹配路由 Route2。\n第一个匹配成功：如果一个请求可以匹配多个路由，则映射第一个匹配成功的路由。如上图所示，客户端发送的请求满足 Route3 和 Route4 的断言，但是 Route3 的配置在配置文件中靠前，所以只会匹配 Route3。\n# Spring Cloud Gateway 如何实现动态路由？ 在使用 Spring Cloud Gateway 的时候，官方文档提供的方案总是基于配置文件或代码配置的方式。\nSpring Cloud Gateway 作为微服务的入口，需要尽量避免重启，而现在配置更改需要重启服务不能满足实际生产过程中的动态刷新、实时变更的业务需求，所以我们需要在 Spring Cloud Gateway 运行时动态配置网关。\n实现动态路由的方式有很多种，其中一种推荐的方式是基于 Nacos 注册中心来做。 Spring Cloud Gateway可以从注册中心获取服务的元数据（例如服务名称、路径等），然后根据这些信息自动生成路由规则。这样，当你添加、移除或更新服务实例时，网关会自动感知并相应地调整路由规则，无需手动维护路由配置。\n其实这些复杂的步骤并不需要我们手动实现，通过 Nacos Server 和 Spring Cloud Alibaba Nacos Config 即可实现配置的动态变更，[官方文档地址][https://github.com/alibaba/spring-cloud-alibaba/wiki/Nacos-config]\n当然，在shenyu种，我们可以自己进行选择：选择Eureka或者Nacos。\n这个具体远离暂时不细究，标记TODO点。\n# Spring Cloud Gateway 的过滤器有哪些？ 过滤器 Filter 按照请求和响应可以分为两种：\nPre 类型：在请求被转发到微服务之前，对请求进行拦截和修改，例如参数校验、权限校验、流量监控、日志输出以及协议转换等操作。 Post 类型：微服务处理完请求后，返回响应给网关，网关可以再次进行处理，例如修改响应内容或响应头、日志输出、流量监控等。 另外一种分类是按照过滤器 Filter 作用的范围进行划分：\nGatewayFilter：局部过滤器，应用在单个路由或一组路由上的过滤器。标红色表示比较常用的过滤器。 GlobalFilter：全局过滤器，应用在所有路由上的过滤器。 # 局部过滤器 常见的局部过滤器如下图所示：\n具体怎么用呢？这里有个示例，如果 URL 匹配成功，则去掉 URL 中的 “api”。\n1 2 filters: #过滤器 - RewritePath=/api/(?\u0026lt;segment\u0026gt;.*),/$\\{segment} # 将跳转路径中包含的 “api” 替换成空 # 全局过滤器 常见的全局过滤器如下图所示：\n全局过滤器最常见的用法是进行负载均衡。配置如下所示：\n1 2 3 4 5 6 7 8 9 10 spring: cloud: gateway: routes: - id: route_member # 第三方微服务路由规则 uri: lb://passjava-member # 负载均衡，将请求转发到注册中心注册的 passjava-member 服务 predicates: # 断言 - Path=/api/member/** # 如果前端请求路径包含 api/member，则应用这条路由规则 filters: #过滤器 - RewritePath=/api/(?\u0026lt;segment\u0026gt;.*),/$\\{segment} # 将跳转路径中包含的api替换成空 这里有个关键字 lb，用到了全局过滤器 LoadBalancerClientFilter，当匹配到这个路由后，会将请求转发到 passjava-member 服务，且支持负载均衡转发，也就是先将 passjava-member 解析成实际的微服务的 host 和 port，然后再转发给实际的微服务。\n# 支持限流 Spring Cloud Gateway 自带了限流过滤器，对应的接口是 RateLimiter，RateLimiter 接口只有一个实现类 RedisRateLimiter （基于 Redis + Lua 实现的限流），提供的限流功能比较简易且不易使用。\n# 全局异常处理 在 SpringBoot 项目中，我们捕获全局异常只需要在项目中配置 @RestControllerAdvice和 @ExceptionHandler就可以了。不过，这种方式在 Spring Cloud Gateway 下不适用。\nSpring Cloud Gateway 提供了多种全局处理的方式，比较常用的一种是实现ErrorWebExceptionHandler并重写其中的handle方法。\n1 2 3 4 5 6 7 8 9 10 11 @Order(-1) @Component @RequiredArgsConstructor public class GlobalErrorWebExceptionHandler implements ErrorWebExceptionHandler { private final ObjectMapper objectMapper; @Override public Mono\u0026lt;Void\u0026gt; handle(ServerWebExchange exchange, Throwable ex) { // ... } } # 参考 https://javaguide.cn/distributed-system/spring-cloud-gateway-questions.html#spring-cloud-gateway-%E6%94%AF%E6%8C%81%E9%99%90%E6%B5%81%E5%90%97 https://cloud.spring.io/spring-cloud-gateway/reference/html/ https://spring.io/blog/2022/08/26/creating-a-custom-spring-cloud-gateway-filter https://zhuanlan.zhihu.com/p/347028665 ","date":"2023-08-20T16:55:17+08:00","image":"https://shenyu.apache.org/zh/img/logo.svg","permalink":"https://runqizhao.cn/p/api%E7%BD%91%E5%85%B3%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/","title":"API网关基本概念"}]